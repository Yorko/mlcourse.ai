{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../../img/ods_stickers.jpg\">\n",
    "## Открытый курс по машинному обучению. Сессия № 3\n",
    "Автор материала: Павел Нестеров (@mephistopheies). Материал распространяется на условиях лицензии [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/). Можно использовать в любых целях (редактировать, поправлять и брать за основу), кроме коммерческих, но с обязательным упоминанием автора материала."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Домашняя работа №4\n",
    "## <center> Логистическая регрессия в задаче тегирования вопросов StackOverflow\n",
    "\n",
    "**Надо вывести формулы, где это просится (да, ручка и бумажка), заполнить код в клетках и выбрать ответы в [веб-форме](https://docs.google.com/forms/d/100c3Ek94UL-VRwXrN4lxCSnGjfJrl6Gc96G21DNCh4w).**\n",
    "\n",
    "## 0. Описание задачи\n",
    "\n",
    "В этой домашней работе мы с вами изучим и запрограммируем модель для прогнозирования тегов по тексту вопроса на базе многоклассовой логистической регрессии. В отличие от обычной постановки задачи классификации (multiclass), в данном случае один пример может принадлежать одновременно к нескольким классам (multilabel). Мы будем реализовывать онлайн-версию алгоритма multilabel-классификации.\n",
    "\n",
    "Мы будем использовать небольшую выборку из протеггированных вопросов с сайта StackOverflow размером в 125 тысяч примеров (около 150 Мб, скачайте по [этой](https://drive.google.com/open?id=0B4bl7YMqDnViYVo0V2FubFVhMFE) ссылке).\n",
    "\n",
    "PS: Можно показать, что такая реализация совсем не эффективная и проще было бы использовать векторизированные вычисления. Для данного датасета так и есть. Но на самом деле подобные реализации используются в жизни, но естественно, написаны они не на Python. Например, в онлайн-моделях прогнозирования [CTR](https://en.wikipedia.org/wiki/Click-through_rate) юзеру показывается баннер, затем в зависимости от наличия клика происходит обновление параметров модели. В реальной жизни параметров модели может быть несколько сотен миллионов, а у юзера из этих ста миллионов от силы сто или тысяча параметров отличны от нуля, векторизировать такие вычисления не очень эффективно. Обычно все это хранится в огромных кластерах в in-memory базах данных, а обработка пользователей происходит распределенно.\n",
    "\n",
    "PS2:\n",
    "- в процессе решения домашней работы вам придется работать с текстом, и у вас может возникнуть желание сделать очевидный препроцессинг, например привести все слова в нижний регистр, в-общем **этого делать не нужно, если не оговорено заранее в задании**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The watermark extension is already loaded. To reload it, use:\n",
      "  %reload_ext watermark\n"
     ]
    }
   ],
   "source": [
    "#!pip install watermark\n",
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем версии используемых библиотек. Совпадут ли ответы в случае других версий - не гарантируется."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPython 3.6.3\n",
      "IPython 6.1.0\n",
      "\n",
      "numpy 1.13.3\n",
      "scipy 0.19.1\n",
      "pandas 0.20.3\n",
      "matplotlib 2.1.0\n",
      "sklearn 0.19.1\n",
      "\n",
      "compiler   : GCC 7.2.0\n",
      "system     : Linux\n",
      "release    : 4.13.0-1011-gcp\n",
      "machine    : x86_64\n",
      "processor  : x86_64\n",
      "CPU cores  : 8\n",
      "interpreter: 64bit\n",
      "Git hash   : 2a020a559578444040250c1174e3e2175b962da8\n"
     ]
    }
   ],
   "source": [
    "%watermark -v -m -p numpy,scipy,pandas,matplotlib,sklearn -g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"dark\")\n",
    "plt.rcParams['figure.figsize'] = 16, 12\n",
    "from tqdm import tqdm_notebook\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# поменяйте на свой путь\n",
    "DS_FILE_NAME = '../../../mlco_data/stackoverflow_sample_125k.tsv'\n",
    "TAGS_FILE_NAME = '../../../mlco_data/top10_tags.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'jquery', 'php', 'android', 'ios', 'javascript', 'c#', 'html', 'python', 'c++', 'java'}\n"
     ]
    }
   ],
   "source": [
    "top_tags = []\n",
    "with open(TAGS_FILE_NAME, 'r') as f:\n",
    "    for line in f:\n",
    "        top_tags.append(line.strip())\n",
    "top_tags = set(top_tags)\n",
    "print(top_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Многоклассовая логистическая регрессия\n",
    "\n",
    "Вспомним, как получается логистическая регрессия для двух классов $\\left\\{0, 1\\right\\}$, вероятность принадлежности объекта к классу $1$ выписывается по теореме Байеса:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "p\\left(c = 1 \\mid \\vec{x}\\right) &=& \\dfrac{p\\left(\\vec{x} \\mid c = 1\\right)p\\left(c = 1\\right)}{p\\left(\\vec{x} \\mid c = 1\\right)p\\left(c = 1\\right) + p\\left(\\vec{x} \\mid c = 0\\right)p\\left(c = 0\\right)} \\\\\n",
    "&=& \\dfrac{1}{1 + e^{-a}} \\\\\n",
    "&=& \\sigma\\left(a\\right)\n",
    "\\end{array}$$\n",
    "где:\n",
    "- $\\vec{x}$ – вектор признаков объекта\n",
    "- $\\sigma$ – обозначение функции логистического сигмоида при скалярном аргументе\n",
    "- $a = \\log \\frac{p\\left(\\vec{x} \\mid c = 1\\right)p\\left(c = 1\\right)}{p\\left(\\vec{x} \\mid c = 0\\right)p\\left(c = 0\\right)} = \\sum_{i=0}^M w_i x_i$ – это отношение мы моделируем линейной функцией от признаков объекта и параметров модели\n",
    "\n",
    "Данное выражение легко обобщить до множества из $K$ классов, изменится только знаменатель в формуле Байеса. Запишем вероятность принадлежности объекта к классу $k$:\n",
    "$$\\large \\begin{array}{rcl}\n",
    "p\\left(c = k \\mid \\vec{x}\\right) &=& \\dfrac{p\\left(\\vec{x} \\mid c = k\\right)p\\left(c = k\\right)}{\\sum_{i=1}^K p\\left(\\vec{x} \\mid c = i\\right)p\\left(c = i\\right)} \\\\\n",
    "&=& \\dfrac{e^{z_k}}{\\sum_{i=1}^{K}e^{z_i}} \\\\\n",
    "&=& \\sigma_k\\left(\\vec{z}\\right)\n",
    "\\end{array}$$\n",
    "где:\n",
    "- $\\sigma_k$ – обозначение функции softmax при векторном аргументе\n",
    "- $z_k = \\log p\\left(\\vec{x} \\mid c = k\\right)p\\left(c = k\\right) = \\sum_{i=0}^M w_{ki} x_i$ – это выражение моделируется линейной функцией от признаков объекта и параметров модели для класса $k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для моделирования полного правдоподобия примера мы используем [категориальное распределение](https://en.wikipedia.org/wiki/Categorical_distribution), а лучше его логарифм (для удобства):\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "\\mathcal{L} = \\log p\\left({\\vec{x}}\\right) &=& \\log \\prod_{i=1}^K \\sigma_i\\left(\\vec{z}\\right)^{y_i} \\\\\n",
    "&=& \\sum_{i=1}^K y_i \\log \\sigma_i\\left(\\vec{z}\\right)\n",
    "\\end{array}$$\n",
    "\n",
    "Получается хорошо знакомая нам функция [cross entropy](https://en.wikipedia.org/wiki/Cross_entropy) (если домножить на $-1$). Правдоподобие нужно максимизировать, а, соответственно, перекрестную энтропию нужно минимизировать. Продифференцировав по параметрам модели, мы _легко_ получим правила обновления весов для градиентного спуска, **проделайте этот вывод, если вы его не делали** (если вы вдруг сдались, то на [этом](https://www.youtube.com/watch?v=-WiR16raQf4) видео есть разбор вывода, понимание этого вам понадобится для дальнейшего выполнения задания; если предпочитаете текст, то и он есть [тут](https://www.ics.uci.edu/~pjsadows/notes.pdf) и [тут](https://eli.thegreenplace.net/2016/the-softmax-function-and-its-derivative/)):\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} &=& x_m \\left(y_k - \\sigma_k\\left(\\vec{z}\\right)\\right)\n",
    "\\end{array}$$\n",
    "\n",
    "В стандартной формулировке получается, что вектор $\\left(\\sigma_1, \\sigma_2, \\ldots, \\sigma_K\\right)$ образует дискретное вероятностное распределение, т.е. $\\sum_{i=1}^K \\sigma_i = 1$. Но в нашей постановке задачи каждый пример может иметь несколько тегов или одновременно принадлежать к нескольким классам. Для этого мы немного изменим модель:\n",
    "- будем считать, что все теги независимы друг от друга, т.е. каждый исход – это логистическая регрессия на два класса (либо есть тег, либо его нет), тогда вероятность наличия тега у примера запишется следующим образом (каждый тег/класс как и в многоклассовой логрегрессии имеет свой набор параметров):\n",
    "$$\\large p\\left(\\text{tag}_k \\mid \\vec{x}\\right) = \\sigma\\left(z_k\\right) = \\sigma\\left(\\sum_{i=1}^M w_{ki} x^i \\right)$$\n",
    "- наличие каждого тега мы будем моделировать с помощью <a href=\"https://en.wikipedia.org/wiki/Bernoulli_distribution\">распределения Бернулли</a>\n",
    "\n",
    "<font color=\"red\">Вопрос 1.</font> Ваше первое задание –  записать упрощенное выражение логарифма правдоподобия примера с признаками $\\vec{x}$. Как правило, многие алгоритмы оптимизации имеют интерфейс для минимизации функции, мы последуем этой же традиции и домножим полученное выражение на $-1$, а во второй части выведем формулы для минимизации полученного выражения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. <font color=\"red\">$\\large -\\mathcal{L} = -\\sum_{i=1}^M y_i \\log \\sigma\\left(z_i\\right) + \\left(1 - y_i\\right) \\log \\left(1 - \\sigma\\left(z_i\\right)\\right)$</font>\n",
    "2. $\\large -\\mathcal{L} = -\\sum_{i=1}^K y_i \\log \\sigma\\left(z_i\\right) + \\left(1 - y_i\\right) \\log \\left(1 - \\sigma\\left(z_i\\right)\\right)$\n",
    "3. $\\large -\\mathcal{L} = -\\sum_{i=1}^K z_i \\log \\sigma\\left(y_i\\right) + \\left(1 - z_i\\right) \\log \\left(1 - \\sigma\\left(y_i\\right)\\right)$\n",
    "4. $\\large -\\mathcal{L} = -\\sum_{i=1}^M z_i \\log \\sigma\\left(y_i\\right) + \\left(1 - z_i\\right) \\log \\left(1 - \\sigma\\left(y_i\\right)\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Вывод формулы обновления весов\n",
    "\n",
    "<font color=\"red\">Вопрос 2.</font>В качестве второго задания вам предоставляется возможность вывести формулу градиента для $-\\mathcal{L}$. Какой вид она будет иметь?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"red\">Варианты ответа:</font>:\n",
    "1. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = -x_m \\left(\\sigma\\left(z_k\\right) - y_k\\right)$\n",
    "2. <font color=\"red\">$\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = -x_m \\left(y_k - \\sigma\\left(z_k\\right)\\right)$</font>\n",
    "3. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = \\left(\\sigma\\left(z_k\\right)x_m - y_k\\right)$\n",
    "4. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = \\left(y_k - \\sigma\\left(z_k\\right)x_m\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Реализация базовой модели\n",
    "\n",
    "Вам предлагается каркас класса модели, разберите его внимательно, обращайте внимание на комментарии. Затем заполните пропуски, запустите полученную модель и ответьте на проверочный вопрос.\n",
    "\n",
    "Как вы могли уже заметить, при обновлении веса $w_{km}$ используется значение признака $x_m$, который равен $0$, если слова с индексом $m$ нет в предложении, и больше нуля, если такое слово есть. В нашем случае, чтобы не пересчитывать [bag-of-words](https://en.wikipedia.org/wiki/Bag-of-words_model) самим или с помощью [sklearn.feature_extraction.text.CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer), мы будем идти по словам предложения в порядке их следования. Если какое-то слово встречается несколько раз, то мы добавляем его в аккумулятор со своим весом. В итоге получится то же самое, как если сначала посчитать количество одинаковых слов и домножить на соответствующий вес. Соответственно, при вычислении линейной комбинации $z$ весов модели и признаков примера необходимо учитывать только ненулевые признаки объекта.\n",
    "\n",
    "Подсказка:\n",
    "- если реализовывать вычисление сигмоида так же, как в формуле, то при большом отрицательном значении $z$ вычисление $e^{-z}$ превратится в очень большое число, которое вылетит за допустимые пределы\n",
    "- в то же время $e^{-z}$ от большого положительного $z$ будет нулем\n",
    "- воспользуйтесь свойствами функции $\\sigma$ для того, чтобы пофиксить эту ошибку и реализовать $\\sigma$ без риска overflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.special import expit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LogRegressor():\n",
    "    \n",
    "    \"\"\"Конструктор\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    tags : list of string, default=top_tags\n",
    "        список тегов\n",
    "    \"\"\"\n",
    "    def __init__(self, tags=top_tags):      \n",
    "        # словарь который содержит мапинг слов предложений и тегов в индексы (для экономии памяти)\n",
    "        # пример: self._vocab['exception'] = 17 означает что у слова exception индекс равен 17\n",
    "        self._vocab = {}\n",
    "        \n",
    "        # параметры модели: веса\n",
    "        # для каждого класса/тега нам необходимо хранить собственный вектор весов\n",
    "        # по умолчанию у нас все веса будут равны нулю\n",
    "        # мы заранее не знаем сколько весов нам понадобится\n",
    "        # поэтому для каждого класса мы сосздаем словарь изменяемого размера со значением по умолчанию 0\n",
    "        # пример: self._w['java'][self._vocab['exception']]  содержит вес для слова exception тега java\n",
    "        self._w = dict([(t, defaultdict(int)) for t in tags])\n",
    "        \n",
    "        # параметры модели: смещения или вес w_0\n",
    "        self._b = dict([(t, 0) for t in tags])\n",
    "        \n",
    "        self._tags = set(tags)\n",
    "    \n",
    "    \"\"\"Один прогон по датасету\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    fname : string, default=DS_FILE_NAME\n",
    "        имя файла с данными\n",
    "        \n",
    "    top_n_train : int\n",
    "        первые top_n_train строк будут использоваться для обучения, остальные для тестирования\n",
    "        \n",
    "    total : int, default=10000000\n",
    "        информация о количестве строк в файле для вывода прогресс бара\n",
    "    \n",
    "    learning_rate : float, default=0.1\n",
    "        скорость обучения для градиентного спуска\n",
    "        \n",
    "    tolerance : float, default=1e-16\n",
    "        используем для ограничения значений аргумента логарифмов\n",
    "    \"\"\"\n",
    "    def iterate_file(self, \n",
    "                     fname=DS_FILE_NAME, \n",
    "                     top_n_train=100000, \n",
    "                     total=125000,\n",
    "                     learning_rate=0.1,\n",
    "                     tolerance=1e-16):\n",
    "        \n",
    "        self._loss = []\n",
    "        n = 0\n",
    "        \n",
    "        # откроем файл\n",
    "        with open(fname, 'r') as f:            \n",
    "            \n",
    "            # прогуляемся по строкам файла\n",
    "            for line in tqdm_notebook(f, total=total, mininterval=1):\n",
    "                pair = line.strip().split('\\t')\n",
    "                if len(pair) != 2:\n",
    "                    continue                \n",
    "                sentence, tags = pair\n",
    "                # слова вопроса, это как раз признаки x\n",
    "                sentence = sentence.split(' ')\n",
    "                # теги вопроса, это y\n",
    "                tags = set(tags.split(' '))\n",
    "                \n",
    "                # значение функции потерь для текущего примера\n",
    "                sample_loss = 0\n",
    "\n",
    "                # прокидываем градиенты для каждого тега\n",
    "                for tag in self._tags:\n",
    "                    # целевая переменная равна 1 если текущий тег есть у текущего примера\n",
    "                    y = int(tag in tags)\n",
    "                    \n",
    "                    # расчитываем значение линейной комбинации весов и признаков объекта\n",
    "                    # инициализируем z\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    z = self._b[tag]\n",
    "   \n",
    "                    for word in sentence:\n",
    "                        # если в режиме тестирования появляется слово которого нет в словаре, то мы его игнорируем\n",
    "                        if n >= top_n_train and word not in self._vocab:\n",
    "                            continue\n",
    "                        if word not in self._vocab:\n",
    "                            self._vocab[word] = len(self._vocab)\n",
    "                        z += self._w[tag][self._vocab[word]]\n",
    "    \n",
    "                    # вычисляем вероятность наличия тега\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    sigma = expit(z)\n",
    "                    #sigma = 1.0/(1.0 + np.exp(-z)) if z >= 0 else np.exp(z)/(1.0 + np.exp(z))\n",
    "    \n",
    "                    \n",
    "                    # обновляем значение функции потерь для текущего примера\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    sample_loss += - y * np.log(sigma + tolerance) - (1 - y) * np.log((1 - sigma + tolerance))\n",
    "                 \n",
    "                    \n",
    "                    # если мы все еще в тренировочной части, то обновим параметры\n",
    "                    if n < top_n_train:\n",
    "                        # вычисляем производную логарифмического правдоподобия по весу\n",
    "                        # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                        dLdw = y - sigma\n",
    "\n",
    "                        # делаем градиентный шаг\n",
    "                        # мы минимизируем отрицательное логарифмическое правдоподобие (второй знак минус)\n",
    "                        # поэтому мы идем в обратную сторону градиента для минимизации (первый знак минус)\n",
    "                        for word in sentence:                        \n",
    "                            self._w[tag][self._vocab[word]] -= -learning_rate*dLdw\n",
    "                        self._b[tag] -= -learning_rate*dLdw\n",
    "                    \n",
    "                n += 1\n",
    "                        \n",
    "                self._loss.append(sample_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eb93d21fad242f5a9d9cc82fd90dc03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# создадим эксемпляр модели и пройдемся по датасету\n",
    "model = LogRegressor()\n",
    "model.iterate_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, действительно ли значение отрицательного логарифмического правдоподобия уменьшалось. Так как мы используем стохастический градентный спуск, не стоит ожидать плавного падения функции ошибки. Мы воспользуемся скользящим средним с окном в 10 тысяч примеров, чтобы хоть как-то сгладить график."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA5sAAAKoCAYAAAD58uunAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAXvf/N7VnTfIdfXEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6c2e5da748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of the loss function on the last 10k train samples: 19.41\n"
     ]
    }
   ],
   "source": [
    "print('Mean of the loss function on the last 10k train samples: %0.2f' % np.mean(model._loss[-35000:-25000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Вопрос 3.</font>\n",
    "Вычислите среднее значение функции стоимости на последних 10 000 примеров тренировочного набора, к какому из значений ваш ответ ближе всего?\n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 17.54\n",
    "2. 18.64\n",
    "3. <font color='red'><b>19.74</b></font>\n",
    "4. 20.84"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4. Тестирование модели\n",
    "\n",
    "В базовой модели первые 100 000 строк используются для обучения, а оставшиеся – для тестирования. Как вы можете заметить, значение отрицательного логарифмического правдоподобия не очень информативно, хоть и позволяет сравнивать разные модели. В качестве четвертого задания вам необходимо модифицировать базовую модель таким образом, чтобы метод `iterate_file` возвращал значение _точности_ на тестовой части набора данных. \n",
    "\n",
    "Точность определим следующим образом:\n",
    "- считаем, что тег у вопроса присутствует, если спрогнозированная вероятность тега больше 0.9\n",
    "- точность одного примера расчитывается как [коэффициент Жаккара](https://ru.wikipedia.org/wiki/Коэффициент_Жаккара) между множеством настоящих тегов и предсказанных моделью\n",
    "  - например, если у примера настоящие теги ['html', 'jquery'], а по версии модели ['ios', 'html', 'java'], то коэффициент Жаккара будет равен |['html', 'jquery'] $\\cap$ ['ios', 'html', 'java']| / |['html', 'jquery'] $\\cup$ ['ios', 'html', 'java']| = |['html']| / |['jquery', 'ios', 'html', 'java']| = 1/4\n",
    "- метод `iterate_file` возвращает **среднюю** точность на тестовом наборе данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "class LogRegressor():\n",
    "    \n",
    "    \"\"\"Конструктор\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    tags : list of string, default=top_tags\n",
    "        список тегов\n",
    "    \"\"\"\n",
    "    def __init__(self, tags=top_tags):      \n",
    "        # словарь который содержит мапинг слов предложений и тегов в индексы (для экономии памяти)\n",
    "        # пример: self._vocab['exception'] = 17 означает что у слова exception индекс равен 17\n",
    "        self._vocab = {}\n",
    "        \n",
    "        # параметры модели: веса\n",
    "        # для каждого класса/тега нам необходимо хранить собственный вектор весов\n",
    "        # по умолчанию у нас все веса будут равны нулю\n",
    "        # мы заранее не знаем сколько весов нам понадобится\n",
    "        # поэтому для каждого класса мы сосздаем словарь изменяемого размера со значением по умолчанию 0\n",
    "        # пример: self._w['java'][self._vocab['exception']]  содержит вес для слова exception тега java\n",
    "        self._w = dict([(t, defaultdict(int)) for t in tags])\n",
    "        \n",
    "        # параметры модели: смещения или вес w_0\n",
    "        self._b = dict([(t, 0) for t in tags])\n",
    "        \n",
    "        self._tags = set(tags)\n",
    "    \n",
    "    \"\"\"Один прогон по датасету\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    fname : string, default=DS_FILE_NAME\n",
    "        имя файла с данными\n",
    "        \n",
    "    top_n_train : int\n",
    "        первые top_n_train строк будут использоваться для обучения, остальные для тестирования\n",
    "        \n",
    "    total : int, default=10000000\n",
    "        информация о количестве строк в файле для вывода прогресс бара\n",
    "    \n",
    "    learning_rate : float, default=0.1\n",
    "        скорость обучения для градиентного спуска\n",
    "        \n",
    "    tolerance : float, default=1e-16\n",
    "        используем для ограничения значений аргумента логарифмов\n",
    "    \"\"\"\n",
    "    def iterate_file(self, \n",
    "                     fname=DS_FILE_NAME, \n",
    "                     top_n_train=100000, \n",
    "                     total=125000,\n",
    "                     learning_rate=0.1,\n",
    "                     tolerance=1e-16):\n",
    "        \n",
    "        # Жаккард?\n",
    "        self._jaccard = []\n",
    "        n = 0\n",
    "        \n",
    "        # откроем файл\n",
    "        with open(fname, 'r') as f:            \n",
    "            \n",
    "            # прогуляемся по строкам файла\n",
    "            for line in tqdm_notebook(f, total=total, mininterval=1):\n",
    "                pair = line.strip().split('\\t')\n",
    "                if len(pair) != 2:\n",
    "                    continue                \n",
    "                sentence, tags = pair\n",
    "                # слова вопроса, это как раз признаки x\n",
    "                sentence = sentence.split(' ')\n",
    "                # теги вопроса, это y\n",
    "                tags = set(tags.split(' '))\n",
    "                predicted_tags = []\n",
    "                sample_jaccard = 0\n",
    "                \n",
    "                # прокидываем градиенты для каждого тега\n",
    "                for tag in self._tags:\n",
    "                    # целевая переменная равна 1 если текущий тег есть у текущего примера\n",
    "                    y = int(tag in tags)\n",
    "                    \n",
    "                    # расчитываем значение линейной комбинации весов и признаков объекта\n",
    "                    # инициализируем z\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    z = self._b[tag]\n",
    "   \n",
    "                    for word in sentence:\n",
    "                        # если в режиме тестирования появляется слово которого нет в словаре, то мы его игнорируем\n",
    "                        if n >= top_n_train and word not in self._vocab:\n",
    "                            continue\n",
    "                        if word not in self._vocab:\n",
    "                            self._vocab[word] = len(self._vocab)\n",
    "                        z += self._w[tag][self._vocab[word]]\n",
    "    \n",
    "                    # вычисляем вероятность наличия тега\n",
    "                    #sigma = 1.0/(1.0 + np.exp(-z)) if z >= 0 else np.exp(z)/(1.0 + np.exp(z))\n",
    "                    sigma = expit(z)\n",
    "                    \n",
    "                    # если мы все еще в тренировочной части, то обновим параметры\n",
    "                    if n < top_n_train:\n",
    "                        # вычисляем производную логарифмического правдоподобия по весу\n",
    "                        dLdw = y - sigma\n",
    "\n",
    "                        # делаем градиентный шаг\n",
    "                        # мы минимизируем отрицательное логарифмическое правдоподобие (второй знак минус)\n",
    "                        # поэтому мы идем в обратную сторону градиента для минимизации (первый знак минус)\n",
    "                        for word in sentence:                        \n",
    "                            self._w[tag][self._vocab[word]] -= -learning_rate*dLdw\n",
    "                        self._b[tag] -= -learning_rate*dLdw\n",
    "                    \n",
    "                    if n >= top_n_train and sigma > 0.9:\n",
    "                        predicted_tags.append(tag)\n",
    "                        \n",
    "                if n >= top_n_train:\n",
    "                    sample_jaccard = len(set(predicted_tags).intersection(tags))/(len(predicted_tags) + len(tags)-len(set(predicted_tags).intersection(tags)))\n",
    "                    self._jaccard.append(sample_jaccard)\n",
    "                \n",
    "                n += 1\n",
    "            \n",
    "            return np.mean(self._jaccard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.58\n"
     ]
    }
   ],
   "source": [
    "accc = np.mean(model._jaccard)\n",
    "print('%0.2f' % accc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ad0d019e88e4710b5e3774c4365c2b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "must be real number, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-151-fff48cca6e9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterate_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# выведем полученное значение с точностью до двух знаков\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%0.2f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: must be real number, not NoneType"
     ]
    }
   ],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file()\n",
    "# выведем полученное значение с точностью до двух знаков\n",
    "print('%0.2f' % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"red\">Вопрос 4.</font> К какому значению ближе всего полученное значение точности?\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 0.39\n",
    "2. 0.49\n",
    "3. 0.59\n",
    "4. 0.69"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 5. $L_2$-регуляризация\n",
    "\n",
    "В качестве пятого задания вам необходимо добавить в класс `LogRegressor` поддержку $L_2$-регуляризации. В методе `iterate_file` должен появиться параметр `lmbda=0.01` со значением по умолчанию. С учетом регуляризации новая функция стоимости примет вид:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "L &=& -\\mathcal{L} + \\frac{\\lambda}{2} R\\left(W\\right) \\\\\n",
    "&=& -\\mathcal{L} + \\frac{\\lambda}{2} \\sum_{k=1}^K\\sum_{i=1}^M w_{ki}^2\n",
    "\\end{array}$$\n",
    "\n",
    "Градиент первого члена суммы мы уже вывели, а для второго он имеет вид:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "\\frac{\\partial}{\\partial w_{ki}} \\frac{\\lambda}{2} R\\left(W\\right) &=& \\lambda w_{ki}\n",
    "\\end{array}$$\n",
    "\n",
    "Если мы на каждом примере будем делать честное обновление всех весов, то все очень замедлится, ведь нам придется на каждой итерации пробегать по всем словам словаря. В ущерб теоретической корректности мы используем грязный трюк: будем регуляризировать только те слова, которые присутствуют в текущем предложении. Не забывайте, что смещение (bias) не регуляризируется. `sample_loss` тоже должен остаться без изменений.\n",
    "\n",
    "Замечание:\n",
    "- не забудьте, что нужно учитывать регуляризацию слова в градиентном шаге только один раз\n",
    "- условимся, что учитываем регуляризацию только при первой встрече слова\n",
    "- если бы мы считали сначала bag-of-words, то мы бы в цикле шли по уникальным словам, но т.к. мы этого не делаем, приходится выкручиваться (еще одна жертва богу online-моделей)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file()\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Вопрос 5.</font> К какому значению ближе всего полученное значение точности?\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 0.3\n",
    "2. 0.35\n",
    "3. 0.4\n",
    "4. 0.52"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ElasticNet регуляризация, вывод\n",
    "Помимо $L_2$ регуляризации, часто используется $L_1$ регуляризация.\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "L &=& -\\mathcal{L} + \\frac{\\lambda}{2} R\\left(W\\right) \\\\\n",
    "&=& -\\mathcal{L} + \\lambda \\sum_{k=1}^K\\sum_{i=1}^M \\left|w_{ki}\\right|\n",
    "\\end{array}$$\n",
    "\n",
    "Если линейно объединить $L_1$ и $L_2$ регуляризацию, то полученный тип регуляризации называется ElasticNet:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "L &=& -\\mathcal{L} + \\lambda R\\left(W\\right) \\\\\n",
    "&=& -\\mathcal{L} + \\lambda \\left(\\gamma \\sum_{k=1}^K\\sum_{i=1}^M w_{ki}^2 + \\left(1 - \\gamma\\right) \\sum_{k=1}^K\\sum_{i=1}^M \\left|w_{ki}\\right| \\right)\n",
    "\\end{array}$$\n",
    "- где $\\gamma \\in \\left[0, 1\\right]$\n",
    "\n",
    "В качестве шестого вопроса вам предлагается вывести формулу градиента ElasticNet регуляризации (не учитывая $-\\mathcal{L}$). \n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>:\n",
    "1. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(W\\right) = \\lambda \\left(2 \\gamma w_{ki} + \\left(1 - \\gamma\\right) w_{ki}\\right)$ \n",
    "2. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(W\\right) = \\lambda \\left(2 \\gamma \\left|w_{ki}\\right| + \\left(1 - \\gamma\\right) \\text{sign}\\left(w_{ki}\\right)\\right)$\n",
    "3. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(W\\right) = \\lambda \\left(2 \\gamma w_{ki} + \\left(1 - \\gamma\\right) \\text{sign}\\left(w_{ki}\\right)\\right)$\n",
    "4. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(W\\right) = \\lambda \\left(\\gamma w_{ki} + \\left(1 - \\gamma\\right) \\text{sign}\\left(w_{ki}\\right)\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Регуляризация ElasticNet , реализация\n",
    "\n",
    "В качестве седьмой задачи вам предлается изменить класс `LogRegressor` таким образом, чтобы метод `iterate_file` принимал два параметра со значениями по умолчанию `lmbda=0.0002` и `gamma=0.1`. Сделайте один проход по датасету с включенной `ElasticNet`-регуляризацией и заданными значениями по умолчанию и ответьте на вопрос."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file()\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"red\">Вопрос 7.</font> К какому значению ближе всего полученное значение точности:\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 0.59\n",
    "2. 0.69\n",
    "3. 0.79\n",
    "4. 0.82"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Самые важные слова для тега\n",
    "\n",
    "Прелесть линейных моделей в том, что они легко интерпретируемы. Вам предлагается вычислить, какие слова вносят наибольший вклад в вероятность появления каждого из тегов. А затем ответьте на контрольный вопрос."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model._vocab_inv = dict([(v, k) for (k, v) in model._vocab.items()])\n",
    "\n",
    "for tag in model._tags:\n",
    "    print(tag, ':', ', '.join([model._vocab_inv[k] for (k, v) in \n",
    "                               sorted(model._w[tag].items(), \n",
    "                                      key=lambda t: t[1], \n",
    "                                      reverse=True)[:5]]))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Вопрос 8.</font> Для многих тегов наличие самого тега в предложении является важным сигналом, у многих сам тег является самым сильным сигналом, что не удивительно. Для каких из тегов само название тега не входит в топ-5 самых важных?\n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. c# \n",
    "2. javascript\n",
    "3. jquery\n",
    "4. android"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 9. Сокращаем размер словаря\n",
    "Сейчас количество слов в словаре – 519290, если бы это была выборка из 10 миллионов вопросов с сайта StackOverflow, то размер словаря был бы миллионов 10. Регуляризировать модель можно не только изящно математически, но и топорно, например, ограничить размер словаря. Вам предоставляется возможность внести следующие изменения в класс `LogRegressor`:\n",
    "- добавить в метод `iterate_file` еще один аргумент со значением по умолчанию `update_vocab=True`\n",
    "- при `update_vocab=True` разрешать добавлять слова в словарь в режиме обучения\n",
    "- при `update_vocab=False` игнорировать слова не из словаря\n",
    "- добавить в класс метод `filter_vocab(n=10000)`, который оставит в словаре только топ-n самых популярных слов, используя данные из ``train``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file(update_vocab=True)\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# оставим только топ 10 000 слов\n",
    "model.filter_vocab(n=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# сделаем еще одну итерацию по датасету, уменьшив скорость обучения в 10 раз\n",
    "acc = model.iterate_file(update_vocab=False, learning_rate=0.01)\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"red\">Вопрос 9.</font> К какому значению ближе всего полученное значение точности:\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 0.48\n",
    "2. 0.58\n",
    "3. 0.68\n",
    "4. 0.78"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Прогнозирование тегов для новых вопросов\n",
    "\n",
    "В завершение этого задания вам предлагается реализовать метод `predict_proba`, который принимает строку, содержащую вопрос, а возвращает список предсказанных тегов вопроса с их вероятностями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file(update_vocab=True)\n",
    "print('%0.2f' % acc)\n",
    "model.filter_vocab(n=10000)\n",
    "acc = model.iterate_file(update_vocab=False, learning_rate=0.01)\n",
    "print('%0.2f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentence = (\"I want to improve my coding skills, so I have planned write \" +\n",
    "            \"a Mobile Application.need to choose between Apple's iOS or Google's Android.\" +\n",
    "            \" my background: I have done basic programming in .Net,C/C++,Python and PHP \" +\n",
    "            \"in college, so got OOP concepts covered. about my skill level, I just know \" +\n",
    "            \"concepts and basic syntax. But can't write complex applications, if asked :(\" +\n",
    "            \" So decided to hone my skills, And I wanted to know which is easier to \" +\n",
    "            \"learn for a programming n00b. A) iOS which uses Objective C B) Android \" + \n",
    "            \"which uses Java. I want to decide based on difficulty \" + \n",
    "            \"level\").lower().replace(',', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted(model.predict_proba(sentence).items(), \n",
    "       key=lambda t: t[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Вопрос 10.</font> Отметьте все теги, ассоциирующиеся с данным вопросом, если порог принятия равен $0.9$. То есть считаем, что вопросу надо поставить некоторый тег, если вероятность его появления, предсказанная моделью, больше или равна 0.9. \n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. android\n",
    "2. ios\n",
    "3. php\n",
    "4. java"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
