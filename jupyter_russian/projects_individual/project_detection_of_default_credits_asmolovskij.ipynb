{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../../img/ods_stickers.jpg\">\n",
    "## Открытый курс по машинному обучению\n",
    "<center>Автор материала: Артём Асмоловский (@Asmolovskij)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Приветствую! Перед вами решение задачи по определению дефолта у ипотечных заёмщиков США, содержащей более 5950 наблюдений. Безусловно, такая задача интересна и сама по себе. Обучив модель, можно предсказывать дальнейшее развитие событий относительно каждого конкретно взятого заёмщика. Однако, скорее всего, подобные данные не останются лишь в стенах банков, а используются различными организациями, имеющими дела с социумом. Вполне вероятно, что по данному набору данных можно попытаться извлечь некий социальный портрет каждого объекта, а затем пытаться кластеризовать их, преследуя уже совсем другие цели. например, предпочтения относительно дорогих покупок, если задачу решает некий ритейлер, либо добавочный коэффициент страхования, если заинтересованы страховщики. Забавная ситуация произошла в офисе одного из амеркианских магазинов Target, предсказав у одной из своих посетительниц беременность, отнеся её к кластеру точно беременных клиенток на основе их поведения. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако я всё же буду решать задачу детектирования наступления дефолта у заёмщика, либо его отсутствия. Анализируемый датасет имеет следующие переменные. Итак, предикторы:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAN - сумма запроса кредита"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MORTDUE - текущая сумма ипотеки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VALUE - стоимость текущей недвижимости"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REASON: DebtCon - погашение задолженности, HomeImp - улучшение жилищных условий"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JOB - род занятости"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOJ - количество лет на текщей работе"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEROG - количество негативных пометок на кредитной истории"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DELINQ - количество просроченных кредитных погашений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLAGE - количество в месяцах самой старой кредитной истории"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NINQ - количество последних кредитных запросов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLNO - количество кредитов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEBTINC - отношение долгов к доходам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А предсказывать мы будем дефолт"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BAD: 1 - не погасит, 0 - погасит"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Подгрузим данные\n",
    "df = pd.read_csv('../../data/hmeq.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Посмотрим на общую характеристику данных\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно, в данных имеется немало пропусков. и если такие переменные как VALUE или CLAGE имеют относительное небольшое число пробелов, которые вполне безболезненно можно заменить на средние или медианные значения по столбцу, то с переменной DEBTINC дела обстоят несоклько сложнее в первую очередь из-за большого количества пропусков (порядка 20%). Однако взглянув на описательную таблицу выше, можно заметить, что среднее практически совпадает с медианой. Что ж, в таком случае так же будем использовать cреднее или медианное для восполнения пробелов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Заполним пропуски для того, чтобы приступить к удобному визуальному анализу.\n",
    "\n",
    "#В большинстве случаев будем порльзоваться медианным значением\n",
    "df[['MORTDUE']] = df[['MORTDUE']].fillna(65000)\n",
    "df[['VALUE']] = df[['VALUE']].fillna(89200)\n",
    "df[['YOJ']] = df[['YOJ']].fillna(7)\n",
    "df[['MORTDUE']] = df[['MORTDUE']].fillna(65000)\n",
    "df[['DEROG']] = df[['DEROG']].fillna(0)\n",
    "df[['DEROG']] = df[['DEROG']].fillna(0)\n",
    "df[['DELINQ']] = df[['DELINQ']].fillna(0)\n",
    "df[['CLAGE']] = df[['CLAGE']].fillna(179)\n",
    "df[['NINQ']] = df[['NINQ']].fillna(0)\n",
    "df[['CLNO']] = df[['CLNO']].fillna(0)\n",
    "df[['DEBTINC']] = df[['DEBTINC']].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Бинаризуем переменную Reason\n",
    "df['REASON'] = df['REASON'].map({'DebtCon' : 0, 'HomeImp' : 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['REASON'].value_counts()\n",
    "#Как видим, больше половины объектов относятся к классу 0, поэтому заполним пропуски так же на 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['REASON'] = df['REASON'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Категоризуем переменную JOB\n",
    "encoder = LabelEncoder().fit_transform(df[\"JOB\"].astype(str))\n",
    "df[[\"JOB\"]] = encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посомтрим на анализируемый датасет теперь и посмотрим, удалось ли нам полностью подготовить данные для дальнейшего анализа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пропусков действительно нет, приступим к графическому анализу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df[['BAD', 'MORTDUE', 'VALUE', 'YOJ', 'DEROG', 'DELINQ', 'NINQ', 'CLNO', 'DEBTINC']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каких-то явных закономерностей, помиомо того, что с ростом стоимости приобритаемого жилья растёт и стоимость ипотеки, нет. Стоит отметить почти идентичную зависимость у количества негативных пометок на кредитной истории и количества просроченных платежей относительно суммы займа, причём сумма займа в общей массе не превышает 0,25 квартиля, что свидетельствует об относительно небольших займах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интересно, а есть ли какие-нибудь профессии, среди которых присутствует наибольшее количество злостных неплательщиков, либо кредитных потребителей?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df[['JOB', \"DELINQ\", \"DEROG\", 'NINQ']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нет, каких-то явных суждений на этот счёт сделать нельзя. На всякий случай дополнительно отрисуем корреляционную матрицу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А тут уже вырисовывется более интересная картинка. Предположение о наибольшей зависимости между стоимостью жилья и ипотеки выполняется. Но по началу я даже не обратил внимания, что между суммой ипотеки и заявкой на кредит так же существует зависимость. Более того, между длиной кредитной истории и вероятностью наступления дефолта существует заметная связь, но с отрицательным знаком. И сильная отрицательная (если даже не отрицательная функциональная) между отношением долгов к доходам и вероятностью дефолта."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предварительно сделаем следующий вывод: С увеличением кредитных просрочек и негативнх пометках на кредитной истории, вероятность дефолта увеличивается. Однако, чем дольше заёмщик берёт кредиты, и чем ниже отношение долгов к доходам, тем менее вероятность наступления дефолта."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы выбрать метрику, на основании которой мы будем строить модели, посмотрим на целевой признак."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df['BAD'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим явную несбалансировать классов, поэтому о простом accuracy_score можно забыть. В данном случе стоит подумать о бизнес-составляющей нашей задачи. Что важнее: отклассифицировать нехороших плательщиков, пожертвовав хорошими? Или найти как можно больше нехороших неплательщиков? Что ж, будем рисовать roc auc, чтобы оценивать модель в целом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поробуем 4 агоритма: логистическкую регрессию, метод к-ближайших, а так же случайный лес и градиентный бустинг (куда же без них)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_val_score, train_test_split,\\\n",
    "validation_curve, learning_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И займёмся финальной подготовкой данных: применим стандартизацию (чтобы избежать сильного влияния каких-то отдельных предикторов для линейки), извлечём целевой признак, а так же поделим выборку на тренировочную, валидационную и тестовую."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[['BAD']]\n",
    "X = df.drop('BAD', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Создадим дамми-переменные для JOB\n",
    "dummies_job = pd.get_dummies(df['JOB'], prefix = 'JOB')\n",
    "X = pd.concat([X, dummies_job], axis = 1)\n",
    "X = X.drop('JOB', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Извлечём из анализируемого датасета отложенную часть выборки, а для тренировочной извлечём ещё и валидационную."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_split = X.shape[0] * 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X.iloc[:int(idx_split), :]\n",
    "y_train = y.iloc[:int(idx_split), :]\n",
    "X_test = X.iloc[int(idx_split) : , :]\n",
    "y_test = y.iloc[int(idx_split) :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_part, X_train_valid, y_train_part, y_train_valid = train_test_split(X_train, y_train, test_size = 0.3, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим работу алгоритмов, настраивая гиперпараметры по сетке. Так же необходимо стандартизировать все не бинарные признаки. Чтобы провести стандартизацию корректно, при кросс-валидации необходимо обучать StandardScaler на каждом фолде."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Приступаем к построениею моделей\n",
    "#Поскольку у нас есть и категориальные, и непрерывные признаки, то, скорее всего, деревья будут лучше справляться\n",
    "\n",
    "cv = StratifiedKFold(random_state=17, n_splits=5)\n",
    "\n",
    "log_params = {'log__C' : [0.01, 0.05, 0.1, 0.25, 0.5, 1], 'log__random_state' : [17]}  \n",
    "pipeline = Pipeline([('scaler', StandardScaler()), ('log', LogisticRegression())])\n",
    "grid = GridSearchCV(pipeline, log_params, cv = cv)\n",
    "grid.fit(X_train_part, y_train_part)\n",
    "print('log best result: %s' % grid.best_score_)\n",
    "print('log best params: %s' % grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_params = {'knn__n_neighbors' : range(1, 20)}  \n",
    "pipeline = Pipeline([('scaler', StandardScaler()), ('knn', KNeighborsClassifier())])\n",
    "grid = GridSearchCV(pipeline, knn_params, cv = cv)\n",
    "grid.fit(X_train_part, y_train_part)\n",
    "print('knn best result: %s' % grid.best_score_)\n",
    "print('knn best params: %s' % grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_params = {'rf__n_estimators' : [100, 250, 500, 750, 1000], 'rf__max_depth' : [1, 2, 3, 4, 5, 6, 7], 'rf__random_state' : [17]}  \n",
    "pipeline = Pipeline([('scaler', StandardScaler()), ('rf', RandomForestClassifier())])\n",
    "grid = GridSearchCV(pipeline, rf_params, cv = cv)\n",
    "grid.fit(X_train_part, y_train_part)\n",
    "print('rf best result: %s' % grid.best_score_)\n",
    "print('rf best params: %s' % grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {'xgb__max_depth' : [1,2,3,4,5, 6, 7], 'xgb__n_estimators':[100, 250, 500, 750, 1000], 'xgb__random_state': [17]}  \n",
    "pipeline = Pipeline([('scaler', StandardScaler()), ('xgb', XGBClassifier())])\n",
    "grid = GridSearchCV(pipeline, xgb_params, cv = cv)\n",
    "grid.fit(X_train_part, y_train_part)\n",
    "print('xgb best result: %s' % grid.best_score_)\n",
    "print('xgb best params: %s' % grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На текущий момент видно, что градиентный бустинг (с настройкой только глубины и количества деревьев) отрабатывает лучше остальных моделей. При этом можно замтить, что и случайный лес очень неплохо старается с настройкой тех же гиперпараметров, причём не факт, что их оптимальные значения были найдены. Однако для экономии вычислительных ресурсов остановимся на xgb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим данную модель на всей X_train и подсчитаем roc auc. Полученное значение будем считать бейзлайном для дальнейшего улучшения моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(max_depth=6, n_estimators=1000, n_jobs=-1, random_state=17)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "xgb.fit(X_train_scaled, y_train)\n",
    "print(\"Результат выбранной модели: %s\" % roc_auc_score(y_test, xgb.predict_proba(X_test_scaled)[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, с моделью мы определились. Самое время подумать о feature engineering. Воспользуемся здравым смыслом и посмотрим, как отличаются наиболее интересные переменные, вроде суммы займа, количества кредитов и прочих у способных к выплате и неспособных. (Предположение о наличии неплательщиков среди определённой профессии мы отклонили ранее)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(df[df['BAD'] == 1]['LOAN']), np.mean(df[df['BAD'] == 0]['LOAN'])\n",
    "#Величина кредитного запроса у неплательщиков ниже почти на 2000 долларов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(df[df['BAD'] == 1]['MORTDUE']), np.mean(df[df['BAD'] == 0]['MORTDUE'])\n",
    "#Так же ниже стоимость ипотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(df[df['BAD'] == 1]['VALUE']), np.mean(df[df['BAD'] == 0]['VALUE'])\n",
    "#И недвижимость дешевле"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(df[df['BAD'] == 1]['YOJ']), np.mean(df[df['BAD'] == 0]['YOJ'])\n",
    "#Работают на основной работе как правило на полтора года меньше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(df[df['BAD'] == 1]['DEROG']), np.mean(df[df['BAD'] == 0]['DEROG'])\n",
    "#Большее количество негативных пометок на кредитнйо истории"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(df[df['BAD'] == 1]['DELINQ']), np.mean(df[df['BAD'] == 0]['DELINQ'])\n",
    "#Больше просчрочек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(df[df['BAD'] == 1]['CLNO']), np.mean(df[df['BAD'] == 0]['CLNO'])\n",
    "#Колчиество кредитов практически идентично"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(df[df['BAD'] == 1]['DEBTINC']), np.mean(df[df['BAD'] == 0]['DEBTINC'])\n",
    "#Отношение долгов к расходам больше у неплательщиков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x = 'JOB', hue='BAD', data = df)\n",
    "#Весьма интересное наблюдение: хуже платят представители 1, 3 и 6 профессий.\n",
    "#Попробуем из этого выделить новый признак, и заново построить модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df[df['BAD'] == 0]['DEBTINC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df[df['BAD'] == 1]['DEBTINC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = pd.concat([X_train, X_test])\n",
    "X_full['notgood_job'] = df['JOB'].map(lambda x: 1 if ((x == 1) or (x == 3) or (x == 6)) else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(max_depth=6, n_estimators=750, n_jobs=-1, random_state=17)\n",
    "scaler = StandardScaler()\n",
    "X_train = X_full.iloc[:int(idx_split), :]\n",
    "X_test = X_full.iloc[int(idx_split) :, :]\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "xgb.fit(X_train_scaled, y_train)\n",
    "print(\"Результат выбранной модели: %s\" % roc_auc_score(y_test, xgb.predict_proba(X_test_scaled)[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Совсем незначительные улучшения, попробуем ещё."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#А теперь попробем добавить признак notgood_debtinc\n",
    "X_full = pd.concat([X_train, X_test])\n",
    "\n",
    "X_full['notgood_debtinc'] = df['DEBTINC'].map(lambda x: 1 if (((x > 45) and (x <= 100)) or \n",
    "                                                                 ((x > 140) and (x < 170))) else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(max_depth=6, n_estimators=750, n_jobs=-1, random_state=17)\n",
    "scaler = StandardScaler()\n",
    "X_train = X_full.iloc[:int(idx_split), :]\n",
    "X_test = X_full.iloc[int(idx_split):, :]\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "xgb.fit(X_train_scaled, y_train)\n",
    "print(\"Результат выбранной модели: %s\" % roc_auc_score(y_test, xgb.predict_proba(X_test_scaled)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Никаких улучшений с этим признаком, удаляем. И заново обучим модель.\n",
    "X_train.drop('notgood_debtinc', axis = 1, inplace=True)\n",
    "X_test.drop('notgood_debtinc', axis = 1, inplace=True)\n",
    "xgb = XGBClassifier(max_depth=6, n_estimators=750, n_jobs=-1, random_state=17)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "xgb.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим кривые валидации и обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Кривые валидации в зависимости от глубины 750 деревьев\n",
    "train_scores, test_scores = validation_curve(XGBClassifier(n_estimators=750), X_train, y_train,'max_depth', range(1,8), cv = cv, scoring='roc_auc')\n",
    "plt.plot(range(1,8), np.mean(train_scores, axis = 1), label = 'train set')\n",
    "plt.plot(range(1,8), np.mean(test_scores, axis = 1), label = 'test set')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Кривые обучения в зависимости от величины выборки\n",
    "train_sizes, train_scores, test_scores = learning_curve(xgb, X_train, y_train, train_sizes = np.linspace(0.1, 1, 7), cv = cv, scoring = 'roc_auc')\n",
    "plt.plot(train_sizes, np.mean(train_scores, axis = 1), label = 'train set')\n",
    "plt.plot(train_sizes, np.mean(test_scores, axis = 1), label = 'test set')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По обоим графикам можно свидетельствовать о нехватке данных. По validation curve заметно, что схоимость графиков может ещё наблюдаться с более сильным увеличением глубины деревьев. По learning curve результат модели на тренировочных данных быстро выходит на плато, а на тестовых заметен сильный спад и небольшой рост под конец. Безусловно, необходим больший размер выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = roc_auc_score(y_test, xgb.predict_proba(X_test_scaled)[:, 1])\n",
    "print('Результат модели %s' % result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В принципе, этот результат мы уже видели, когда создали для себя условный бейзлайн при генерации фичей. Если сравнивать его с резульаттом кросс валидации, то потеря качества не особо существенна, менее 1%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не представляю, как раньше банки составляли скорринговые карты вручную, каким образом исследовали зависимости, определяли закономерности. Скорее всего,  основной инструмент, которым приходилось руководствоваться - это личные педубеждения. И, либо на службу нанимались действительно незаурядные личности, обладающие особенным чутьём, либо уже тогда банки уверенно полагались на коллекторов=). В любом случае, в современных условиях необходимо анализировать риски, чтобы корректно выстраивать сратегию развития и дальнейшего существования компании. Без сбора статистической информации это сделать невозможно, а без машинного обучения, её невозможно адекватно оценивать.\n",
    "Применительно к построенной модели. Не смотря на то, что по кривым валидации и обучения был получен вывод о недостаточной величине обучаемой выборки, а так же о дальнейших возможностях усложнения выбранной модели, результат roc auc в более чем 90% на отложенной выбокре говорит о достаточно хорошем качестве уже сейчас. В качестве улучшения я бы порекомендовал собирать дополнительные признаки, вроде возраста заёмщика, семейного положения, количества детей в семье (вполне возможно, что семьи с детьми тщательнее планируют свой бюджет и в среднем имеют меньшее количество просрочек)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
