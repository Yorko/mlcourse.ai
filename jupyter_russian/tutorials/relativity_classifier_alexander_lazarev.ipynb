{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../../img/ods_stickers.jpg\">\n",
    "## Открытый курс по машинному обучению\n",
    "<center>Автор материала: Лазарев Александр Александрович (@alexander_lazarev)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Novelty Detection при классификации изображений</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Можно найти много информации о принципах работы сверточных нейронных сетей, о том как можно благодаря буквально нескольким строчкам кода и небольшому набору данных создать свою модель, которая будет отличать котиков от собачек и тд. Но когда дело доходит до реальной задачи, возникает масса вопросов на которые гугл не может дать четких ответов. \n",
    "\n",
    "С одним из таких вопросов я столкнулся во время <strike>чего-то</strike> разработки своего [приложения](https://plants-care.com) для распознавания видов растений. Проблема заключалась в следующем - как быстро и эффективно отличить распознаваемое изображение и его отношение к тому на чем обучалась модель. Например, если мы обучали на котиках и собачках, то как отличить вентилятор от этих животных? Мы бы могли добавить еще один класс для вентиляторов, переобучить модель и начать отличать их, но вод беда - объектов которые не относятся к котикам и собачкам великое множество и мы не можем каждый раз добавлять класс хотя бы по следующим причина причинам: бесконечное количество потенциальных классов; сбор данных для обучения нового класса достаточно трудоемкий процесс; переобучение модели занимает время и ресурсы, а при имении порядочного количества данных и классов это время на вес золота; с ростом классов точность модели падает.\n",
    "\n",
    "После некоторых раздумий первое, что пришло на ум - попробовать посмотреть, что происходит с активациями нейронов на последних слоях сети. Берем последние потому, что начальные слои содержат достаточно мало абстрактной информации. Мое интуитивное понимание заключалось в том, что скорее всего на неизвестных объектах сеть должна возбуждаться меньше и соответственно это как-то можно замерять простыми способами.\n",
    "\n",
    "Давайте поэтапно разберем задачу и проблему."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Условия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "За основу мы возьмем предобученную модель Resnet50 и будем ее [файн-тюнить](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html) на котиках и собачках взятых на [каггле](https://www.kaggle.com/c/dogs-vs-cats/data). В тренировочном датасете лежит по 12500 картинок каждого класса, но нам потребуется всего 1000 (этого достаточно чтобы получить хорошую точность). Подготовленные данные использованные в данном туториале проще скачать [здесь](https://www.dropbox.com/s/is44kutatj0e9fy/mlcourse_tutorial_data.zip?dl=0).\n",
    "\n",
    "Для реализации из основных библиотек нам потребуется: \n",
    "- Keras (Keras версии 1.2 так-как во второй беда с весами под Resnet50 для Theano)\n",
    "- Theano\n",
    "- sklearn\n",
    "- pandas\n",
    "- numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Импорт необходимых библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.layers import (Input, Dense, Flatten, Dropout)\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import os\n",
    "import glob \n",
    "from keras.preprocessing import image\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras import backend as K\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создание модели\n",
    "\n",
    "В Keras уже есть готовый модуль который содержит известную ResNet50. Все что нам нужно - это воспользоваться ею. Параметр **include_top=False** отвечает за то, что нам вернеться архитектура модели, но без последних слоев. Из-за того, что мы здесь занимаемся трансфером знаний предобученой сети, нужно прикрутить самим последние слои (я не буду описывать как работает fine-tuning так как это не есть целью даного туториала).\n",
    "\n",
    "Важным моментом в прикручивании своих слоев для нашей задачи являеться добавление дополнительного Dense(2048) слоя. Если бы мы просто файнтюнили, этот слой нам бы не помог в точности, а наоборот чуть ухудшил ее, но именно он является самым полезным в снятии активаций для дальнейшего анализа. Как раз он получает максимум абстрактной полезной информации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NB_EPOCH = 20\n",
    "\n",
    "RELEVANT_LAYER_NAME = 'relevant_layer'\n",
    "IMG_SIZE = (224, 224)\n",
    "\n",
    "NB_VAL_SAMPLES = 200\n",
    "NB_TRAIN_SAMPLES = 800\n",
    "\n",
    "TRAIN_DIR = 'data/train/'\n",
    "VALID_DIR = 'data/valid/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model..\n",
      "Model created\n"
     ]
    }
   ],
   "source": [
    "def create_model():\n",
    "        base_model = ResNet50(include_top=False, input_tensor=Input(shape=(3,) + IMG_SIZE))\n",
    "\n",
    "        # делаем так чтобы слои из основной модели не тренировались\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "        x = base_model.output\n",
    "        x = Flatten()(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        # слой с которого мы будем снимать значения активаций нейронов\n",
    "        x = Dense(2048, activation='elu', name=RELEVANT_LAYER_NAME)(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "    \n",
    "        predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "        return Model(input=base_model.input, output=predictions)\n",
    "    \n",
    "print(\"Creating model..\")\n",
    "model = create_model()\n",
    "print(\"Model created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Файн-тюним"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling model..\n",
      "Found 1600 images belonging to 2 classes.\n",
      "Found 400 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 42s - loss: 0.8139 - acc: 0.5450 - val_loss: 0.5743 - val_acc: 0.7143\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 42s - loss: 0.7156 - acc: 0.6262 - val_loss: 0.3976 - val_acc: 0.8616\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 42s - loss: 0.5195 - acc: 0.7400 - val_loss: 0.2593 - val_acc: 0.9598\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 42s - loss: 0.4822 - acc: 0.7712 - val_loss: 0.2302 - val_acc: 0.9471\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 42s - loss: 0.3826 - acc: 0.8175 - val_loss: 0.2208 - val_acc: 0.9375\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 41s - loss: 0.3657 - acc: 0.8463 - val_loss: 0.1747 - val_acc: 0.9567\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 42s - loss: 0.3242 - acc: 0.8550 - val_loss: 0.1477 - val_acc: 0.9760\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 42s - loss: 0.3338 - acc: 0.8513 - val_loss: 0.1755 - val_acc: 0.9420\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 42s - loss: 0.2878 - acc: 0.8788 - val_loss: 0.1356 - val_acc: 0.9554\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 42s - loss: 0.2703 - acc: 0.8837 - val_loss: 0.1278 - val_acc: 0.9598\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 42s - loss: 0.1991 - acc: 0.9250 - val_loss: 0.1125 - val_acc: 0.9567\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 42s - loss: 0.2379 - acc: 0.9062 - val_loss: 0.1129 - val_acc: 0.9567\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 42s - loss: 0.2053 - acc: 0.9113 - val_loss: 0.1139 - val_acc: 0.9567\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 42s - loss: 0.2071 - acc: 0.9037 - val_loss: 0.0931 - val_acc: 0.9688\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 42s - loss: 0.1902 - acc: 0.9200 - val_loss: 0.1002 - val_acc: 0.9643\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 42s - loss: 0.1924 - acc: 0.9237 - val_loss: 0.1019 - val_acc: 0.9688\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 41s - loss: 0.1796 - acc: 0.9337 - val_loss: 0.0955 - val_acc: 0.9712\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 42s - loss: 0.1824 - acc: 0.9288 - val_loss: 0.1040 - val_acc: 0.9615\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 42s - loss: 0.1562 - acc: 0.9413 - val_loss: 0.0783 - val_acc: 0.9808\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 42s - loss: 0.1865 - acc: 0.9250 - val_loss: 0.0553 - val_acc: 0.9904\n"
     ]
    }
   ],
   "source": [
    "def apply_mean(image_data_generator):\n",
    "    \"\"\"Subtracts the dataset mean\"\"\"\n",
    "    image_data_generator.mean = np.array([103.939, 116.779, 123.68], dtype=np.float32).reshape((3, 1, 1))\n",
    "\n",
    "def get_train_datagen(*args, **kwargs):\n",
    "    idg = ImageDataGenerator(*args, **kwargs)\n",
    "    apply_mean(idg)\n",
    "    return idg.flow_from_directory(TRAIN_DIR, target_size=IMG_SIZE, class_mode='binary')\n",
    "\n",
    "def get_validation_datagen():\n",
    "    idg = ImageDataGenerator()\n",
    "    apply_mean(idg)\n",
    "    return idg.flow_from_directory(VALID_DIR, target_size=IMG_SIZE, class_mode='binary')\n",
    "    \n",
    "def fine_tuning(model):\n",
    "    # выбираем для дообучения 2 identity блока и 1 сверточный \n",
    "    # (можно эксперементировать изменяя значение 80 чтобы добиться лучших результатов)\n",
    "    # все слои выше - \"замораживаем\"\n",
    "    for layer in model.layers[:80]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[80:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    print(\"Compiling model..\")\n",
    "    sgd = SGD(lr=1e-4, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.fit_generator(\n",
    "        get_train_datagen(rotation_range=30., shear_range=0.2, zoom_range=0.2, horizontal_flip=True),\n",
    "        samples_per_epoch=NB_TRAIN_SAMPLES,\n",
    "        nb_epoch=NB_EPOCH,\n",
    "        validation_data=get_validation_datagen(),\n",
    "        nb_val_samples=NB_VAL_SAMPLES)\n",
    "    \n",
    "    \n",
    "fine_tuning(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготавливаем релевантные и нерелевантные данные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В папке irrelevant я подготовил изображения, которые достаточно разные по содержимому и не относятся к нашим животным. Активации будем собирать используя валидационную выборку (так как модель не обучалась на ней) и выборку irrelevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400 relevant files\n",
      "Found 122 relevant files\n"
     ]
    }
   ],
   "source": [
    "def get_files(path):\n",
    "    files = []\n",
    "    if os.path.isdir(path):\n",
    "        files = glob.glob(path + '*.jpg')\n",
    "    elif path.find('*') > 0:\n",
    "        files = glob.glob(path)\n",
    "    else:\n",
    "        files = [path]\n",
    "\n",
    "    if not len(files):\n",
    "        print('No images found by the given path')\n",
    "\n",
    "    return files\n",
    "\n",
    "\n",
    "def load_img(img_path):\n",
    "    img = image.load_img(img_path, target_size=IMG_SIZE)\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    return preprocess_input(x)[0]\n",
    "\n",
    "\n",
    "def get_inputs(files):\n",
    "    inputs = []\n",
    "    for i in files:\n",
    "        x = load_img(i)\n",
    "        inputs.append(x)\n",
    "    return inputs\n",
    "\n",
    "\n",
    "relevant_files = get_files('data/valid/**/*.jpg')\n",
    "print('Found {} relevant files'.format(len(relevant_files)))\n",
    "\n",
    "irrelevant_files = get_files('data/irrelevant/*.jpg')\n",
    "print('Found {} relevant files'.format(len(irrelevant_files)))\n",
    "\n",
    "relevant_inputs = get_inputs(relevant_files)\n",
    "irrelevant_inputs = get_inputs(irrelevant_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Извлекаем активации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_activation_function(m, layer):\n",
    "    x = [m.layers[0].input, K.learning_phase()]\n",
    "    y = [m.get_layer(layer).output]\n",
    "    return K.function(x, y)\n",
    "\n",
    "\n",
    "def get_activations(model, inputs, layer, class_name):\n",
    "    all_activations = []\n",
    "    activation_function = get_activation_function(model, layer)\n",
    "    for i in range(len(inputs)):\n",
    "        activations = activation_function([[inputs[i]], 0])\n",
    "        all_activations.append(activations[0][0])\n",
    "\n",
    "    df = pd.DataFrame(all_activations)\n",
    "    df.insert(0, 'class', class_name)\n",
    "    df.reset_index()\n",
    "    return df\n",
    "\n",
    "irrelevant_activations = get_activations(model, irrelevant_inputs, RELEVANT_LAYER_NAME, 'irrelevant')\n",
    "relevant_activations = get_activations(model, relevant_inputs, RELEVANT_LAYER_NAME ,'relevant')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В итоге, имеем для каждого изображения 2048 значений. Эти значения ни что иное как активации нейронов нашего дополнительного слоя добавленного в ResNet50. То есть мы обучили модель, а потом на ней прогнали новые изображения собирая попутно полезные данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>2038</th>\n",
       "      <th>2039</th>\n",
       "      <th>2040</th>\n",
       "      <th>2041</th>\n",
       "      <th>2042</th>\n",
       "      <th>2043</th>\n",
       "      <th>2044</th>\n",
       "      <th>2045</th>\n",
       "      <th>2046</th>\n",
       "      <th>2047</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>irrelevant</td>\n",
       "      <td>-0.598094</td>\n",
       "      <td>1.239143</td>\n",
       "      <td>-0.389843</td>\n",
       "      <td>-0.863989</td>\n",
       "      <td>0.764257</td>\n",
       "      <td>-0.170501</td>\n",
       "      <td>-0.281559</td>\n",
       "      <td>-0.707091</td>\n",
       "      <td>0.369792</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136632</td>\n",
       "      <td>0.734552</td>\n",
       "      <td>-0.091966</td>\n",
       "      <td>-0.227989</td>\n",
       "      <td>-0.911422</td>\n",
       "      <td>-0.812910</td>\n",
       "      <td>-0.467780</td>\n",
       "      <td>-0.804834</td>\n",
       "      <td>-0.062992</td>\n",
       "      <td>-0.519364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>irrelevant</td>\n",
       "      <td>0.726542</td>\n",
       "      <td>0.587522</td>\n",
       "      <td>0.731024</td>\n",
       "      <td>-0.800377</td>\n",
       "      <td>-0.323168</td>\n",
       "      <td>-0.223053</td>\n",
       "      <td>1.877696</td>\n",
       "      <td>-0.178092</td>\n",
       "      <td>2.228745</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.151967</td>\n",
       "      <td>-0.631110</td>\n",
       "      <td>-0.720813</td>\n",
       "      <td>-0.655249</td>\n",
       "      <td>-0.724119</td>\n",
       "      <td>0.766456</td>\n",
       "      <td>0.128262</td>\n",
       "      <td>-0.634495</td>\n",
       "      <td>0.519373</td>\n",
       "      <td>-0.412953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>irrelevant</td>\n",
       "      <td>0.609969</td>\n",
       "      <td>-0.111925</td>\n",
       "      <td>-0.644175</td>\n",
       "      <td>-0.799153</td>\n",
       "      <td>0.720471</td>\n",
       "      <td>0.242357</td>\n",
       "      <td>0.177311</td>\n",
       "      <td>-0.607280</td>\n",
       "      <td>1.370672</td>\n",
       "      <td>...</td>\n",
       "      <td>0.986953</td>\n",
       "      <td>-0.111110</td>\n",
       "      <td>-0.764166</td>\n",
       "      <td>0.151436</td>\n",
       "      <td>-0.632360</td>\n",
       "      <td>-0.673904</td>\n",
       "      <td>-0.276429</td>\n",
       "      <td>-0.495146</td>\n",
       "      <td>-0.837474</td>\n",
       "      <td>-0.778941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>irrelevant</td>\n",
       "      <td>0.360917</td>\n",
       "      <td>0.613042</td>\n",
       "      <td>0.463755</td>\n",
       "      <td>-0.827774</td>\n",
       "      <td>-0.270739</td>\n",
       "      <td>-0.208567</td>\n",
       "      <td>-0.166589</td>\n",
       "      <td>-0.064751</td>\n",
       "      <td>1.479160</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.234681</td>\n",
       "      <td>-0.398546</td>\n",
       "      <td>-0.619910</td>\n",
       "      <td>-0.604982</td>\n",
       "      <td>-0.463557</td>\n",
       "      <td>0.285751</td>\n",
       "      <td>0.409206</td>\n",
       "      <td>-0.373997</td>\n",
       "      <td>0.154885</td>\n",
       "      <td>0.156137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>irrelevant</td>\n",
       "      <td>0.340706</td>\n",
       "      <td>0.513122</td>\n",
       "      <td>0.528132</td>\n",
       "      <td>-0.499504</td>\n",
       "      <td>1.908270</td>\n",
       "      <td>0.131216</td>\n",
       "      <td>1.503078</td>\n",
       "      <td>-0.374208</td>\n",
       "      <td>0.927220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.233154</td>\n",
       "      <td>-0.285013</td>\n",
       "      <td>-0.705146</td>\n",
       "      <td>-0.586157</td>\n",
       "      <td>-0.809374</td>\n",
       "      <td>2.091043</td>\n",
       "      <td>0.296636</td>\n",
       "      <td>-0.818331</td>\n",
       "      <td>-0.245078</td>\n",
       "      <td>0.334960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2049 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        class         0         1         2         3         4         5  \\\n",
       "0  irrelevant -0.598094  1.239143 -0.389843 -0.863989  0.764257 -0.170501   \n",
       "1  irrelevant  0.726542  0.587522  0.731024 -0.800377 -0.323168 -0.223053   \n",
       "2  irrelevant  0.609969 -0.111925 -0.644175 -0.799153  0.720471  0.242357   \n",
       "3  irrelevant  0.360917  0.613042  0.463755 -0.827774 -0.270739 -0.208567   \n",
       "4  irrelevant  0.340706  0.513122  0.528132 -0.499504  1.908270  0.131216   \n",
       "\n",
       "          6         7         8    ...         2038      2039      2040  \\\n",
       "0 -0.281559 -0.707091  0.369792    ...     0.136632  0.734552 -0.091966   \n",
       "1  1.877696 -0.178092  2.228745    ...    -0.151967 -0.631110 -0.720813   \n",
       "2  0.177311 -0.607280  1.370672    ...     0.986953 -0.111110 -0.764166   \n",
       "3 -0.166589 -0.064751  1.479160    ...    -0.234681 -0.398546 -0.619910   \n",
       "4  1.503078 -0.374208  0.927220    ...     0.233154 -0.285013 -0.705146   \n",
       "\n",
       "       2041      2042      2043      2044      2045      2046      2047  \n",
       "0 -0.227989 -0.911422 -0.812910 -0.467780 -0.804834 -0.062992 -0.519364  \n",
       "1 -0.655249 -0.724119  0.766456  0.128262 -0.634495  0.519373 -0.412953  \n",
       "2  0.151436 -0.632360 -0.673904 -0.276429 -0.495146 -0.837474 -0.778941  \n",
       "3 -0.604982 -0.463557  0.285751  0.409206 -0.373997  0.154885  0.156137  \n",
       "4 -0.586157 -0.809374  2.091043  0.296636 -0.818331 -0.245078  0.334960  \n",
       "\n",
       "[5 rows x 2049 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irrelevant_activations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>2038</th>\n",
       "      <th>2039</th>\n",
       "      <th>2040</th>\n",
       "      <th>2041</th>\n",
       "      <th>2042</th>\n",
       "      <th>2043</th>\n",
       "      <th>2044</th>\n",
       "      <th>2045</th>\n",
       "      <th>2046</th>\n",
       "      <th>2047</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>relevant</td>\n",
       "      <td>-0.590892</td>\n",
       "      <td>-0.120369</td>\n",
       "      <td>0.497180</td>\n",
       "      <td>-0.408394</td>\n",
       "      <td>0.203963</td>\n",
       "      <td>-0.280542</td>\n",
       "      <td>-0.459885</td>\n",
       "      <td>-0.275410</td>\n",
       "      <td>1.263551</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>-0.317722</td>\n",
       "      <td>0.227770</td>\n",
       "      <td>0.101853</td>\n",
       "      <td>-0.709388</td>\n",
       "      <td>-0.053827</td>\n",
       "      <td>-0.078718</td>\n",
       "      <td>0.258835</td>\n",
       "      <td>-0.350082</td>\n",
       "      <td>-0.200404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>relevant</td>\n",
       "      <td>0.318287</td>\n",
       "      <td>0.039049</td>\n",
       "      <td>0.645118</td>\n",
       "      <td>-0.460176</td>\n",
       "      <td>0.661314</td>\n",
       "      <td>0.119426</td>\n",
       "      <td>0.257861</td>\n",
       "      <td>-0.282234</td>\n",
       "      <td>0.776569</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.710556</td>\n",
       "      <td>-0.785034</td>\n",
       "      <td>-0.238885</td>\n",
       "      <td>0.671935</td>\n",
       "      <td>-0.635158</td>\n",
       "      <td>0.353828</td>\n",
       "      <td>-0.567950</td>\n",
       "      <td>-0.209361</td>\n",
       "      <td>0.048338</td>\n",
       "      <td>-0.473797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>relevant</td>\n",
       "      <td>-0.192103</td>\n",
       "      <td>-0.063174</td>\n",
       "      <td>-0.155871</td>\n",
       "      <td>-0.504322</td>\n",
       "      <td>0.177806</td>\n",
       "      <td>0.487485</td>\n",
       "      <td>-0.214208</td>\n",
       "      <td>-0.238188</td>\n",
       "      <td>1.142099</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.439069</td>\n",
       "      <td>-0.643772</td>\n",
       "      <td>-0.184352</td>\n",
       "      <td>-0.178175</td>\n",
       "      <td>-0.749158</td>\n",
       "      <td>0.393253</td>\n",
       "      <td>-0.684870</td>\n",
       "      <td>0.629663</td>\n",
       "      <td>0.432273</td>\n",
       "      <td>-0.098245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>relevant</td>\n",
       "      <td>-0.338937</td>\n",
       "      <td>0.616878</td>\n",
       "      <td>0.823267</td>\n",
       "      <td>-0.353180</td>\n",
       "      <td>-0.334185</td>\n",
       "      <td>0.282569</td>\n",
       "      <td>-0.465371</td>\n",
       "      <td>-0.601170</td>\n",
       "      <td>0.896253</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.334125</td>\n",
       "      <td>-0.330429</td>\n",
       "      <td>-0.062772</td>\n",
       "      <td>-0.222406</td>\n",
       "      <td>-0.368443</td>\n",
       "      <td>1.089609</td>\n",
       "      <td>-0.152031</td>\n",
       "      <td>0.110512</td>\n",
       "      <td>-0.672666</td>\n",
       "      <td>0.306951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>relevant</td>\n",
       "      <td>0.897149</td>\n",
       "      <td>-0.094105</td>\n",
       "      <td>0.505784</td>\n",
       "      <td>-0.736883</td>\n",
       "      <td>0.155456</td>\n",
       "      <td>-0.081272</td>\n",
       "      <td>0.748365</td>\n",
       "      <td>-0.695340</td>\n",
       "      <td>2.062750</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.249161</td>\n",
       "      <td>-0.356041</td>\n",
       "      <td>-0.369375</td>\n",
       "      <td>0.405472</td>\n",
       "      <td>-0.812124</td>\n",
       "      <td>-0.353669</td>\n",
       "      <td>-0.698629</td>\n",
       "      <td>-0.488889</td>\n",
       "      <td>0.205292</td>\n",
       "      <td>-0.547146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2049 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      class         0         1         2         3         4         5  \\\n",
       "0  relevant -0.590892 -0.120369  0.497180 -0.408394  0.203963 -0.280542   \n",
       "1  relevant  0.318287  0.039049  0.645118 -0.460176  0.661314  0.119426   \n",
       "2  relevant -0.192103 -0.063174 -0.155871 -0.504322  0.177806  0.487485   \n",
       "3  relevant -0.338937  0.616878  0.823267 -0.353180 -0.334185  0.282569   \n",
       "4  relevant  0.897149 -0.094105  0.505784 -0.736883  0.155456 -0.081272   \n",
       "\n",
       "          6         7         8    ...         2038      2039      2040  \\\n",
       "0 -0.459885 -0.275410  1.263551    ...     0.007843 -0.317722  0.227770   \n",
       "1  0.257861 -0.282234  0.776569    ...    -0.710556 -0.785034 -0.238885   \n",
       "2 -0.214208 -0.238188  1.142099    ...    -0.439069 -0.643772 -0.184352   \n",
       "3 -0.465371 -0.601170  0.896253    ...    -0.334125 -0.330429 -0.062772   \n",
       "4  0.748365 -0.695340  2.062750    ...    -0.249161 -0.356041 -0.369375   \n",
       "\n",
       "       2041      2042      2043      2044      2045      2046      2047  \n",
       "0  0.101853 -0.709388 -0.053827 -0.078718  0.258835 -0.350082 -0.200404  \n",
       "1  0.671935 -0.635158  0.353828 -0.567950 -0.209361  0.048338 -0.473797  \n",
       "2 -0.178175 -0.749158  0.393253 -0.684870  0.629663  0.432273 -0.098245  \n",
       "3 -0.222406 -0.368443  1.089609 -0.152031  0.110512 -0.672666  0.306951  \n",
       "4  0.405472 -0.812124 -0.353669 -0.698629 -0.488889  0.205292 -0.547146  \n",
       "\n",
       "[5 rows x 2049 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_activations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интересный факт - сеть реагировала на незнакомые объекты бОльшим количеством нейронов нежели на знакомых.\n",
    "Вот что происходило:\n",
    "- для изображений использовавшихся при тренировке модели количество активированных нейронов находилось в диапазоне 19%-23% от общего количества;\n",
    "- для изображений находящихся в валидационной выборке - 20%-26%;\n",
    "- для иррелевантных изображений значение было 24%-28%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Визуализация реагирования нейронов\n",
    "\n",
    "(Изображения взяты при исползовании модели VGG16 и слоя с 4096 нейронами)\n",
    "\n",
    "\n",
    "Активации для изображения на котором обучалась сеть\n",
    "<img src=\"https://habrastorage.org/web/6c6/513/0d5/6c65130d51794868b5d14c9bf3e3b2d2.jpg\"/>\n",
    "\n",
    "Активации для изображения из валидации\n",
    "<img src=\"https://habrastorage.org/web/99a/c8e/bcf/99ac8ebcf81440e6a1be86e0497570e2.jpg\"/>\n",
    "\n",
    "Активации для неизвестного изображения\n",
    "<img src=\"https://habrastorage.org/web/7e5/c67/d08/7e5c67d08e224e7587ca74908af70a15.jpg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Даже визуально можно заметить как хаос увеличиваеться с ростом неуверенности. Для меня это сравнимо толпе людей которые пытаються ответить на один вопрос и чем меньше они уверены в ответе, тем больше от них шума. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее я подумал, а почему бы не попробовать эти данные прогнать через простенькую полносвязную сеть и решить проблему бинарной классификации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode(df):\n",
    "    label_encoder = LabelEncoder().fit(df['class'])\n",
    "    labels = label_encoder.transform(df['class'])\n",
    "    df = df.drop(['class'], axis=1)\n",
    "    return df, labels\n",
    "\n",
    "df = pd.concat([irrelevant_activations, relevant_activations])\n",
    "X, y = encode(df)\n",
    "\n",
    "sss = StratifiedShuffleSplit(np.zeros(y.shape[0]), test_size=0.3, random_state=23)\n",
    "for train_index, test_index in sss:\n",
    "    X_train, X_test = X.values[train_index], X.values[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 365 samples, validate on 157 samples\n",
      "Epoch 1/4\n",
      "365/365 [==============================] - 1s - loss: 0.3491 - acc: 0.8384 - val_loss: 0.0471 - val_acc: 1.0000\n",
      "Epoch 2/4\n",
      "365/365 [==============================] - 1s - loss: 0.0325 - acc: 0.9890 - val_loss: 0.0235 - val_acc: 0.9936\n",
      "Epoch 3/4\n",
      "365/365 [==============================] - 1s - loss: 0.0147 - acc: 0.9973 - val_loss: 0.0092 - val_acc: 0.9936\n",
      "Epoch 4/4\n",
      "365/365 [==============================] - 1s - loss: 0.0049 - acc: 1.0000 - val_loss: 0.0211 - val_acc: 0.9936\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f36942a3e50>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=2048, activation='elu', init='uniform'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu', init='uniform'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid', init='uniform'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    nb_epoch=4,\n",
    "    validation_data=(X_test, y_test),\n",
    "    batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вуаля! На четвертой эпохе имеем почти 100% точность различаемости. А что если попробовать вместо нейронной сети самую обычную Logistic Regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params: {'C': 10, 'tol': 0.001}\n",
      "best score:-0.0441846967223\n",
      "('accuracy', 0.99363057324840764)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "params = {'C': [10, 2, .9, .4, .1], 'tol': [0.0001, 0.001]}\n",
    "log_reg = LogisticRegression(solver='lbfgs', multi_class='multinomial', class_weight='balanced')\n",
    "clf = GridSearchCV(log_reg, params, scoring='neg_log_loss', refit=True, cv=3, n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"best params: \" + str(clf.best_params_))\n",
    "print('best score:'+ str(clf.best_score_))\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "print(\"accuracy\", accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что ж выходит и простой алгоритм способен дать очень высокую точность. На практике я отдал предпочтение LogisticRegression так как потребление памяти и вычислительных мощностей намного меньше. \n",
    "\n",
    "<u>Стоит учесть, что обучать модель для релевантности вам придеться каждый раз после переобучения главной модели, так как каждый последующий раз нейроны будут вести себя иначе.</u>\n",
    "\n",
    "В будущем планирую расписать это все более детально и обоснованно. Надеюсь, что этот туториал будет понятен и пригодиться вам на практике. Данный подход сработал отлично также для VGG16, InceptionV3. Думаю, сработает и для других топологий."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
