{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../../img/ods_stickers.jpg\">\n",
    "## Открытый курс по машинному обучению\n",
    "<center> Автор материала: Тетерников Илья (@tetelias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>mlxtend</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данная библиотека содержит модули расширения и вспомогательные инструменты для программных библиотек \n",
    "Python, предназначенных для анализа данных и машинного обучения.\n",
    "\n",
    "В данном материале будет описаны:\n",
    "\n",
    "* процесс установки;\n",
    "* методы отбора признаков;\n",
    "* прочие методы, доступные в этой библиотеке;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>Установка</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Происходит стандартным для библиотеки Python образом:\n",
    "    \n",
    "    pip install mlxtend\n",
    "    \n",
    "Или через Anaconda:\n",
    "    \n",
    "    conda install -c conda-forge mlxtend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>Отбор признаков методом полного перебора</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала мы рассмотрим обертку для полного перебора всех возможных комбинаций признаков. Для этого воспользуемся алгоритмом ExhaustiveFeatureSelector, которому необходимо передать следующие параметры:\n",
    "* Модель; \n",
    "* Минимальное количество признаков(`min_features=`);\n",
    "* Максимальное количество признаков(`max_features=`);\n",
    "* Метрика оценки(`scoring=`);\n",
    "* Параметр кросс-валидации;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве модели алгоритм принимает любую реализацию классификации или регрессии из scikit-learn. \n",
    "\n",
    "Среди метрик доступны {\"accuracy\", \"f1\", \"precision\", \"recall\", \"roc_auc\"} для классификации и {'mean_absolute_error', 'mean_squared_error', 'median_absolute_error', 'r2'} для регрессии.\n",
    "\n",
    "Рассмотрим простой пример на основе стандартного набора данных __Ирис__. Свойства `best_idx_` и `best_score_` метода ExhaustiveFeatureSelector позволяют получить список индексов в списке признаков и результат метрики для лучшего набора:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Features: 15/15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy score: 0.97\n",
      "Best subset: (0, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from mlxtend.feature_selection import ExhaustiveFeatureSelector as efs\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "fs1 = efs(knn, \n",
    "          min_features=1,\n",
    "          max_features=4,\n",
    "          scoring='accuracy',\n",
    "          print_progress=True,\n",
    "          cv=5)\n",
    "\n",
    "fs1 = fs1.fit(X, y)\n",
    "\n",
    "print('Best accuracy score: %.2f' % fs1.best_score_)\n",
    "print('Best subset:', fs1.best_idx_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью свойства **subsets_** мы можем увидеть подробности каждого шага:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'avg_score': 0.65999999999999992,\n",
       "  'cv_scores': array([ 0.53333333,  0.63333333,  0.73333333,  0.76666667,  0.63333333]),\n",
       "  'feature_idx': (0,)},\n",
       " 1: {'avg_score': 0.56666666666666665,\n",
       "  'cv_scores': array([ 0.53333333,  0.63333333,  0.6       ,  0.5       ,  0.56666667]),\n",
       "  'feature_idx': (1,)},\n",
       " 2: {'avg_score': 0.95333333333333337,\n",
       "  'cv_scores': array([ 0.93333333,  1.        ,  0.9       ,  0.93333333,  1.        ]),\n",
       "  'feature_idx': (2,)},\n",
       " 3: {'avg_score': 0.94666666666666666,\n",
       "  'cv_scores': array([ 0.96666667,  0.96666667,  0.93333333,  0.86666667,  1.        ]),\n",
       "  'feature_idx': (3,)},\n",
       " 4: {'avg_score': 0.72666666666666668,\n",
       "  'cv_scores': array([ 0.66666667,  0.8       ,  0.63333333,  0.86666667,  0.66666667]),\n",
       "  'feature_idx': (0, 1)},\n",
       " 5: {'avg_score': 0.94666666666666666,\n",
       "  'cv_scores': array([ 0.96666667,  1.        ,  0.86666667,  0.93333333,  0.96666667]),\n",
       "  'feature_idx': (0, 2)},\n",
       " 6: {'avg_score': 0.95333333333333337,\n",
       "  'cv_scores': array([ 0.96666667,  0.96666667,  0.9       ,  0.93333333,  1.        ]),\n",
       "  'feature_idx': (0, 3)},\n",
       " 7: {'avg_score': 0.94666666666666666,\n",
       "  'cv_scores': array([ 0.96666667,  1.        ,  0.9       ,  0.93333333,  0.93333333]),\n",
       "  'feature_idx': (1, 2)},\n",
       " 8: {'avg_score': 0.94000000000000006,\n",
       "  'cv_scores': array([ 0.96666667,  0.96666667,  0.86666667,  0.93333333,  0.96666667]),\n",
       "  'feature_idx': (1, 3)},\n",
       " 9: {'avg_score': 0.95333333333333337,\n",
       "  'cv_scores': array([ 0.96666667,  0.96666667,  0.9       ,  0.93333333,  1.        ]),\n",
       "  'feature_idx': (2, 3)},\n",
       " 10: {'avg_score': 0.94000000000000006,\n",
       "  'cv_scores': array([ 0.96666667,  0.96666667,  0.86666667,  0.93333333,  0.96666667]),\n",
       "  'feature_idx': (0, 1, 2)},\n",
       " 11: {'avg_score': 0.94666666666666666,\n",
       "  'cv_scores': array([ 0.93333333,  0.96666667,  0.9       ,  0.93333333,  1.        ]),\n",
       "  'feature_idx': (0, 1, 3)},\n",
       " 12: {'avg_score': 0.97333333333333338,\n",
       "  'cv_scores': array([ 0.96666667,  0.96666667,  0.96666667,  0.96666667,  1.        ]),\n",
       "  'feature_idx': (0, 2, 3)},\n",
       " 13: {'avg_score': 0.95999999999999996,\n",
       "  'cv_scores': array([ 0.96666667,  0.96666667,  0.93333333,  0.93333333,  1.        ]),\n",
       "  'feature_idx': (1, 2, 3)},\n",
       " 14: {'avg_score': 0.96666666666666679,\n",
       "  'cv_scores': array([ 0.96666667,  0.96666667,  0.93333333,  0.96666667,  1.        ]),\n",
       "  'feature_idx': (0, 1, 2, 3)}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs1.subsets_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данный метод может также применяться в процессе подбора параметров моделей с помощью GridSearchCV. Для этого необходимо применение метода make_pipeline. Для извлечения лучшего набора признаков нужно указать **refit=True** в GridSearchCV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:   11.0s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from mlxtend.feature_selection import ExhaustiveFeatureSelector as efs\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=13)\n",
    "\n",
    "logit = LogisticRegression(multi_class='multinomial', \n",
    "                           solver='lbfgs', \n",
    "                           random_state=123)\n",
    "\n",
    "fs1 = efs(estimator=logit, \n",
    "          min_features=2,\n",
    "          max_features=3,\n",
    "          scoring='accuracy',\n",
    "          print_progress=False,\n",
    "          clone_estimator=False,\n",
    "          cv=5,\n",
    "          n_jobs=1)\n",
    "\n",
    "pipe = make_pipeline(fs1, logit)\n",
    "\n",
    "param_grid = {'exhaustivefeatureselector__estimator__C': [0.1, 1.0, 10.0]}\n",
    "\n",
    "gs = GridSearchCV(estimator=pipe, \n",
    "                  param_grid=param_grid, \n",
    "                  scoring='accuracy', \n",
    "                  n_jobs=1, \n",
    "                  cv=5, \n",
    "                  verbose=1, \n",
    "                  refit=True)\n",
    "\n",
    "# run gridearch\n",
    "gs = gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшие параметры GridSearchCV выводятся стандартным"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exhaustivefeatureselector__estimator__C': 0.1}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А вот индексы лучших признаков отыскать не так просто:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_estimator_.steps[0][1].best_idx_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>Отбор признаков методом последовательного перебора</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полный перебор прост в исполнении, но количество вариантов растет пропорционально 2 в степени количества признаков. Для того, чтобы избежать такого массового перебора есть группа методов последовательного отбора признаков. Метод Sequential Forward Selection начинает с 0 признаков и выбирает тот, что максимально увеличивает заданную пользователем метрику. Затем к отобранному добавленяетсяием еще один и т.д.. Метод Sequential Backward Selection наоборот начинает с полного набора и отбрасывает по одному признаки менее всего положительно влияющие на заданную метрику. Есть еще надстройки над этими методами: Sequential Forward loating Selection и Sequential Backward Floating Selection. Они по сравнению с базовыми делают проверку, не улучшат ли уже отброшенные до этого признаки показатель метрики, если их все-таки добавить на текущем этапе работы алгоритма."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Необходимые параметры:\n",
    "* Модель;\n",
    "* Количество признаков, которое мы хотим получить на выходе, задаваемое через k_features;\n",
    "* Направление прохождения алгоритма: от нулевого(`forward=True`) или полного(`forward=False`) набора признаков;\n",
    "* Пытаться ли вернуть ранее отброшенные признаки: да(`floating=True`) или нет(`floating=False`);\n",
    "* Метрика оценки(`scoring=`);\n",
    "* Параметр кросс-валидации.\n",
    "\n",
    "Но к ним добавляется еще и кол-во признаков, которое мы хотим получить на выходе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s finished\n",
      "\n",
      "[2017-11-08 23:26:16] Features: 1/3 -- score: 0.96[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "\n",
      "[2017-11-08 23:26:16] Features: 2/3 -- score: 0.973333333333[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "\n",
      "[2017-11-08 23:26:16] Features: 3/3 -- score: 0.973333333333"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as sfs\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "knn = KNeighborsClassifier(n_neighbors=4)\n",
    "\n",
    "sfs1 = sfs(knn, \n",
    "           k_features=3, \n",
    "           forward=True, \n",
    "           floating=False, \n",
    "           verbose=2,\n",
    "           scoring='accuracy',\n",
    "           cv=0)\n",
    "\n",
    "sfs1 = sfs1.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как и в предыдущий раз свойство **subsets_** позволяет увидеть подробности каждого шага:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'avg_score': 0.95999999999999996,\n",
       "  'cv_scores': array([ 0.96]),\n",
       "  'feature_idx': (3,)},\n",
       " 2: {'avg_score': 0.97333333333333338,\n",
       "  'cv_scores': array([ 0.97333333]),\n",
       "  'feature_idx': (2, 3)},\n",
       " 3: {'avg_score': 0.97333333333333338,\n",
       "  'cv_scores': array([ 0.97333333]),\n",
       "  'feature_idx': (1, 2, 3)}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfs1.subsets_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Индексы лучшего набора признаков можно получить, используя свойство **`k_feature_idx_`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 3)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfs1.k_feature_idx_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так же, как и в случае с полным перебором, данный метод можно использовать вместе с GridSearchCV. Но надо не забыть  указать в GridSearchCV **refit=True**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as sfs\n",
    "import mlxtend\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=13)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=2)\n",
    "\n",
    "sfs1 = sfs(estimator=knn, \n",
    "           k_features=3,\n",
    "           forward=True, \n",
    "           floating=False, \n",
    "           scoring='accuracy',\n",
    "           cv=5)\n",
    "\n",
    "pipe = Pipeline([('sfs', sfs1), \n",
    "                 ('knn', knn)])\n",
    "\n",
    "param_grid = [\n",
    "  {'sfs__k_features': [1, 2, 3, 4],\n",
    "   'sfs__estimator__n_neighbors': [1, 2, 3, 4]}\n",
    "  ]\n",
    "\n",
    "gs = GridSearchCV(estimator=pipe, \n",
    "                  param_grid=param_grid, \n",
    "                  scoring='accuracy', \n",
    "                  n_jobs=1, \n",
    "                  cv=5,                   \n",
    "                  verbose=1,\n",
    "                  refit=True)\n",
    "\n",
    "# run gridearch\n",
    "gs = gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И опять получение лучшего набора признаков не выглядит элегантно:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 3)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_estimator_.steps[0][1].k_feature_idx_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>Другие интересные методы библиотеки</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Библиотека также содержит единственную на Python реализацию алгоритма Априори для построения правил ассоциативности: \n",
    "очень простого, но обладающего исключительной интерпретируемостью метода исследования данных. Помимо [небольшого пояснения от автора](http://rasbt.github.io/mlxtend/user_guide/frequent_patterns/apriori/) рекомендую к прочтению вот [эту статью](http://pbpython.com/market-basket-analysis.html).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И напоследок: библиотека также имеет средства работы с текстом, включая возможность обрабатывать смайлики. Можно пытаться делать свой шаблон через библиотеку __re__ или просто использовать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[':)', ':(', ';-)']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlxtend.text import tokenizer_emoticons\n",
    "\n",
    "tokenizer_emoticons('</a>This :) is :( a test ;-)!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно извлекать смайлики не только отдельно, но и вместе с текстом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this', 'is', 'a', 'test', ':)', ':(', ':-)']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlxtend.text import tokenizer_words_and_emoticons\n",
    "\n",
    "tokenizer_words_and_emoticons('</a>This :) is :( a test :-)!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ссылки\n",
    "* [Документация](http://rasbt.github.io/mlxtend/) mlxtend\n",
    "* [Репозитарий на Github](https://github.com/rasbt/mlxtend)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
