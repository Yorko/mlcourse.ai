{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../../img/ods_stickers.jpg\">\n",
    "## Открытый курс по машинному обучению\n",
    "<center>Автор материала: Данила Сергей Владимирович, sergey.danila."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Pandas. Работа с базами данных</center>\n",
    "## <center>Введение.</center>\n",
    "Pandas - это библиотека Python, предоставляющая широкие возможности для анализа данных. С ее помощью очень удобно загружать, обрабатывать и анализировать табличные данные. В современном мире огромные массивы данных хранятся в базах данных. В курсе <a href=\"https://github.com/Yorko/mlcourse_open\">OpenDataScience</a>  во практически во всех домашних заданиях и семенарах данные загружаются из csv файлов. Я в своей статье попробую приоткрыть тему доступа к данным находящихся в популярных <a href=\"https://ru.wikipedia.org/wiki/%D0%A0%D0%B5%D0%BB%D1%8F%D1%86%D0%B8%D0%BE%D0%BD%D0%BD%D0%B0%D1%8F_%D0%A1%D0%A3%D0%91%D0%94\"> реляционных СУБД</a>. Чтобы использовать данные на полную катушку, нужно обладать знаниями языка <a href=\"https://ru.wikipedia.org/wiki/SQL\">SQL</a>. Даже если вы не знакомы с SQL, думаю, не составит труда разобраться с данным материалом.\n",
    "Не хотел браться за написание данного материала т.к. мне он представляется достаточно тревиальным. Но видя уже вторую ссесию подряд данный вопрос в возможных темах для тьюториалов и видя непонимание в глазах некоторых IT-шников, глядящих на какой нибудь не сильно сложный join таки решился на это. Надеюсь, данная работа кому-нибудь таки пригодится."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python достаточно давно и хорошо  работает с различными СУБД посредством модулей, реализующими работу с конкретными базами данных. Чтобы пользователю не нужно было разбираться  в деталях реализации той или оной СУБД для python был разработан программный интерфейс DB-API. <strong><a href=\"https://habrahabr.ru/post/321510/\">Python DB-API</a></strong> – это не конкретная библиотека, а набор правил, которым подчиняются отдельные модули, реализующие работу с конкретными базами данных. Отдельные нюансы реализации для разных баз могут отличаться, но общие принципы позволяют использовать один и тот же подход при работе с разными базами данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В pandas встроена поддержка <a href=\"https://ru.wikipedia.org/wiki/SQLAlchemy\" >SQLAlchemy</a> которая представляет нам еще более удобный механизм доступа к данным в базе. SQLAlchemy Engine это слой абстракции над DB-API.\n",
    "Он содержит DB-API драйвера для разных СУБД, их можно указать в строке подключения.\n",
    "Engine.execute() и Engine.connect() два основных метода.\n",
    "Так же у него есть свой пул соединений.\n",
    "create_engine() - фабричная функция для создания Engine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Т.е. для нас вся работа с СУБД сводится к созданию engine к нужной базе и всё. А далее методами pandas to_sql - сохраняем данные в базу, а методом  -получаем данные из базы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <left>Работа с разными базами данных используя SQLAlchemy.</left> ###\n",
    "Обратимся к <a href=\"http://pandas.pydata.org/pandas-docs/stable/io.html#engine-connection-examples\">документации pandas</a> где указаны примеры подключения к БД:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sqlalchemy import create_engine\n",
    "\n",
    "# engine = create_engine('postgresql://scott:tiger@localhost:5432/mydatabase')\n",
    "\n",
    "# engine = create_engine('mysql+mysqldb://scott:tiger@localhost/foo')\n",
    "\n",
    "# engine = create_engine('oracle://scott:tiger@127.0.0.1:1521/sidname')\n",
    "\n",
    "# engine = create_engine('mssql+pyodbc://mydsn')\n",
    "\n",
    "# sqlite://<nohostname>/<path>\n",
    "# where <path> is relative:\n",
    "# engine = create_engine('sqlite:///foo.db')\n",
    "\n",
    "# or absolute, starting with a slash:\n",
    "# engine = create_engine('sqlite:////absolute/path/to/foo.db')\n",
    "\n",
    "\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# отключим предупреждения\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем датасет mlbootcamp5 из первых домашних работ '../../data/mlbootcamp5_train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../data/mlbootcamp5_train.csv\", sep=\";\", index_col=\"id\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраним данные из датафрейма df  в MySQL базу:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# для того, чтобы воспользоваться данной СУБД у Вас в системе должен стоять драйвер,\n",
    "# на моей системе он ставился следующей командой:\n",
    "# apt-get install python3-mysqldb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# хост БД: localhost\n",
    "# пользователь БД testuser\n",
    "# пароль: 321\n",
    "# БД: edu\n",
    "mysql_conn = create_engine(\"mysql+mysqldb://testuser:321@localhost:3306/edu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохраним наш датафрейм df в базу в таблицу train:\n",
    "\n",
    "df.to_sql(\n",
    "    name=\"train\", con=mysql_conn, if_exists=\"replace\", index=True, index_label=\"id_s\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "таблица в которую мы пишем может уже существовать в БД, поэтому мы должны определить поведение системы с помощью параметра if_exists \n",
    "\n",
    "<code>if_exists : {'fail', 'replace', 'append'}, default 'fail'</code>  -параметр if_exists может принимать следующие 3 значения:<br />\n",
    "        <strong>fail</strong>:- If table exists, do nothing. - ничего не делать, если таблица существует,<br />\n",
    "        <strong>replace</strong>-: If table exists, drop it, recreate it, and insert data. -если таблица существует пересоздать её и вставить данные,<br />\n",
    "        <strong>append</strong>-: If table exists, insert data. Create if does not exist. - если таблица существует, то дописать данные в конец. Если таблица не существует, создать её."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A теперь вытащим данные из таблицы sql запросом. \n",
    "Например, создадим новый датафрейм со всеми людьми имеющими сердечно-сосудистые заболения "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"SELECT * FROM train WHERE cardio=1\"\n",
    "\n",
    "mysql_df = pd.read_sql_query(sql, mysql_conn)\n",
    "mysql_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сравним с исходным df\n",
    "print(mysql_df.shape, df[df[\"cardio\"] == 1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, оба датафрейма вовзращают одинаковое кол-во строк 34979 только вот кол-во столбцов отличается на 1 т.к. при добавлении данных в таблицу также, по умолчанию, добавляется столбец с индексом. Это поведение можно изменить добавив параметр index=False при вызове функции to_sql."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте убедимся, что независимо от реализации СУБД работа с ней в pandas не меняется.\n",
    "Сделаем тоже самое уже для PostgreSQL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# для того, чтобы воспользоваться данной СУБД у Вас в системе должен стоять драйвер psycopg2,\n",
    "# на моей системе он ставился следующей командой:\n",
    "#!pip3 install psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# хост БД: localhost\n",
    "# пользователь БД testuser\n",
    "# пароль: 4321\n",
    "# БД: edu\n",
    "pgsql_conn = create_engine(\"postgresql://testuser:4321@localhost:5432/edu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пишем в базу:\n",
    "df.to_sql(name=\"train\", con=pgsql_conn, if_exists=\"replace\")\n",
    "\n",
    "# достаём из базы:\n",
    "sql = \"SELECT * FROM train WHERE cardio=1\"\n",
    "\n",
    "pgsql_df = pd.read_sql_query(sql, pgsql_conn)\n",
    "pgsql_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# всё тоже самое, ничего нового:\n",
    "print(mysql_df.shape, pgsql_df.shape, df[df[\"cardio\"] == 1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Работа с mySQL и c PostgreSQL требует наличия соответствующих СУБД, созданных в них баз данных, пользователей к БД, установленных драйверов СУБД. Уверен, что большинству, как и мне, было бы лень ставить соответствующий софт, чтобы погонять игрушечные примеры. Для таких случает есть \"лайтовый\" вариант  <a href=\"https://ru.wikipedia.org/wiki/SQLite\">SQLite</q> - компактная встраиваемая СУБД. Данная СУБД может создаваться \"на лету\" в виде файла. Поддержка SQLite встроена в python и не потребует установки отдельных драйверов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим новую базу и коннект к ней\n",
    "sqlite_conn = create_engine(\"sqlite:///../../data/mybase.db\")\n",
    "# пишем в базу:\n",
    "df.to_sql(name=\"train\", con=sqlite_conn, if_exists=\"replace\")\n",
    "\n",
    "# достаём из базы:\n",
    "sql = \"SELECT * FROM train WHERE cardio=1\"\n",
    "\n",
    "sqlite_df = pd.read_sql_query(sql, sqlite_conn)\n",
    "sqlite_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сравним выдачу, ничего нового:\n",
    "print(mysql_df.shape, pgsql_df.shape, sqlite_df.shape, df[df[\"cardio\"] == 1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Список подддерживаемых SQLAlchemy диалектов СУБД можно посмотреть <a href=\"http://docs.sqlalchemy.org/en/latest/dialects/index.html\">здесь</a>, а это практически все популярные СУБД."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <left>Возможности SQL.</left> ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для разнообразия, воспользуемся встроенным в python модулем для работы с SQLite базами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "# создадим новую БД:\n",
    "db = \"../../data/mybase.sqlite\"\n",
    "conn = sqlite3.connect(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# запишем в неё весь датафрейм df:\n",
    "df.to_sql(\"train\", conn, if_exists=\"replace\", index=False)\n",
    "\n",
    "sql = \"SELECT * FROM train\"\n",
    "df_sql = pd.read_sql_query(sql, conn)\n",
    "df_sql.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сверим размерности\n",
    "print(df.shape, df_sql.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь можно манипулировать данными не используя синтаксис pandas, а используя более привычный, по крайней мере для меня, sql-синтаксис.\n",
    "Составим запрос:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_string = \"SELECT age,\"\n",
    "sql_string += \"age/365.25 as years, \"  # преобразуем возраст в года\n",
    "sql_string += (\n",
    "    \"cast(age/365.25 as int) as years_full, \"  #  а также посчитаем число полных лет\n",
    ")\n",
    "#  значения пола 1 и 2 как то не привычно. Переделаем на \"классическое\" представление :\n",
    "sql_string += (\n",
    "    \"CASE WHEN gender=2 THEN 1 ELSE 0 END as gender_b , \"  # 1-мужской, и 0 -женский\n",
    ")\n",
    "sql_string += 'CASE WHEN gender=2 THEN upper(\"m\") ELSE \"W\" END as gender_chr , '  #  ну или в символьное M/W\n",
    "sql_string += \"height, weight, ap_hi, ap_lo, cholesterol, gluc, smoke,alco, active, cardio \"  # добавим остальные поля\n",
    "sql_string += \" FROM train  \"  # укажем таблицу\n",
    "sql_string += \" WHERE  ap_hi> ap_lo \"  # отфильтруем ошибочные данные там где нижнее давление больше или равно верхнему.\n",
    "sql_string += \" ORDER BY cast(age/365.25 as int) , cholesterol \"  # упорядочим выборку по кол-ву полных лет  и уровню холестерина\n",
    "print(sql_string)  # получился такой вот sql запрос"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# теперь результатом его выполнения можно использовать как dataframe\n",
    "df_new = pd.read_sql_query(sql_string, conn)\n",
    "df_new.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверим размерности отфильтрованных данных:\n",
    "print(df[df[\"ap_hi\"] > df[\"ap_lo\"]].shape, df_new.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "как мы видим в выборке у нас появились новые столбцы. А также кол-во записей уменьшилось из-за того что мы отбросили некорректные данные.\n",
    "Ну и на последок еще одни пример на JOIN,  собственно то, ради чего и нужен sql."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# перезапишем таблицу с исходной выборкой train добавим в нее весь датаблок, а также добавим столбец с индексом\n",
    "df.to_sql(\"train\", conn, if_exists=\"replace\", index=True)\n",
    "sql = \"SELECT * FROM train\"\n",
    "df_sql = pd.read_sql_query(sql, conn)\n",
    "df_sql.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим новую таблицу 'x' куда попадут все столбцы кроме cardio\n",
    "sql = \"SELECT id, age, gender, height, weight, ap_hi, ap_lo,cholesterol, gluc, smoke, alco, active FROM train\"\n",
    "df_sql2 = pd.read_sql_query(sql, conn)\n",
    "\n",
    "\n",
    "df_sql2.to_sql(\"x\", conn, if_exists=\"replace\", index=False)\n",
    "df_sql2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим новую таблицу 'y' в котором будут только столбцы id  и cardio, при этом отфильтруем только те записи, где cardio=1\n",
    "sql = \"SELECT id, cardio FROM train WHERE cardio=1\"\n",
    "df_sql3 = pd.read_sql_query(sql, conn)\n",
    "\n",
    "\n",
    "df_sql3.to_sql(\"y\", conn, if_exists=\"replace\", index=False)\n",
    "df_sql3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сравним размерности новых таблиц\n",
    "print(df_sql2.shape, df_sql3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, они не совпадают по кол-ву строк. И восстановить данные средствами pandas было бы проблемматично. \n",
    "А средствами sql это сделать достаточно легко. Нужно просто написать соответствующий запрос:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"SELECT x.*, COALESCE(y.cardio,0) as cardio  FROM x LEFT JOIN y ON x.id=y.id\"  # вот и весь запрос.\n",
    "df_result = pd.read_sql_query(sql, conn)\n",
    "\n",
    "\n",
    "df_result.to_sql(\n",
    "    \"new_train\", conn, if_exists=\"replace\", index=False\n",
    ")  # сохраним данные в таблицу new_train\n",
    "df_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ни одной строчки не потеряли:\n",
    "print(df_result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим что столбец cardio в обеих таблицах идентичен"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"SELECT train.ID, train.cardio,new_train.cardio FROM  train INNER JOIN new_train   ON train.id=new_train.id WHERE train.cardio=new_train.cardio\"  # вот и весь запрос.\n",
    "df_compare = pd.read_sql_query(sql, conn)\n",
    "print(df_compare.shape)  # получаем 70000 строк т.е. таблицы идентичны"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_compare.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "На этом хочу поставить точку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
