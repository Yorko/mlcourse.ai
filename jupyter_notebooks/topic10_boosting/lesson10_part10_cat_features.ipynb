{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../../img/ods_stickers.jpg\">\n",
    "## Открытый курс по машинному обучению. Сессия № 2\n",
    "Автор материала: программист-исследователь Mail.ru Group, старший преподаватель Факультета Компьютерных Наук ВШЭ Юрий Кашницкий. Материал распространяется на условиях лицензии [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/). Можно использовать в любых целях (редактировать, поправлять и брать за основу), кроме коммерческих, но с обязательным упоминанием автора материала."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Тема 10. Бустинг\n",
    "## <center> Часть 10. Продвинутые методы работы с категориальными признаками и CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max.columns', 100)\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считаем данные и посмотрим на первые несколько строк. Видим, что у нас тут немало категориальных признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/bank.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>married</td>\n",
       "      <td>primary</td>\n",
       "      <td>no</td>\n",
       "      <td>1787</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>19</td>\n",
       "      <td>oct</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>4789</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>11</td>\n",
       "      <td>may</td>\n",
       "      <td>220</td>\n",
       "      <td>1</td>\n",
       "      <td>339</td>\n",
       "      <td>4</td>\n",
       "      <td>failure</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35</td>\n",
       "      <td>management</td>\n",
       "      <td>single</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>1350</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>16</td>\n",
       "      <td>apr</td>\n",
       "      <td>185</td>\n",
       "      <td>1</td>\n",
       "      <td>330</td>\n",
       "      <td>1</td>\n",
       "      <td>failure</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>1476</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>3</td>\n",
       "      <td>jun</td>\n",
       "      <td>199</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>226</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          job  marital  education default  balance housing loan  \\\n",
       "0   30   unemployed  married    primary      no     1787      no   no   \n",
       "1   33     services  married  secondary      no     4789     yes  yes   \n",
       "2   35   management   single   tertiary      no     1350     yes   no   \n",
       "3   30   management  married   tertiary      no     1476     yes  yes   \n",
       "4   59  blue-collar  married  secondary      no        0     yes   no   \n",
       "\n",
       "    contact  day month  duration  campaign  pdays  previous poutcome  y  \n",
       "0  cellular   19   oct        79         1     -1         0  unknown  0  \n",
       "1  cellular   11   may       220         1    339         4  failure  0  \n",
       "2  cellular   16   apr       185         1    330         1  failure  0  \n",
       "3   unknown    3   jun       199         4     -1         0  unknown  0  \n",
       "4   unknown    5   may       226         1     -1         0  unknown  0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4521 entries, 0 to 4520\n",
      "Data columns (total 17 columns):\n",
      "age          4521 non-null int64\n",
      "job          4521 non-null object\n",
      "marital      4521 non-null object\n",
      "education    4521 non-null object\n",
      "default      4521 non-null object\n",
      "balance      4521 non-null int64\n",
      "housing      4521 non-null object\n",
      "loan         4521 non-null object\n",
      "contact      4521 non-null object\n",
      "day          4521 non-null int64\n",
      "month        4521 non-null object\n",
      "duration     4521 non-null int64\n",
      "campaign     4521 non-null int64\n",
      "pdays        4521 non-null int64\n",
      "previous     4521 non-null int64\n",
      "poutcome     4521 non-null object\n",
      "y            4521 non-null int64\n",
      "dtypes: int64(8), object(9)\n",
      "memory usage: 600.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Всего 9 признаков со строковыми значениями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact',\n",
       "       'month', 'poutcome'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[df.dtypes == 'object']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Без категориальных признаков\n",
    "Попытаемся сначала просто проигнорировать категориальные признаки. Обучим случайный лес и посмотрим на ROC AUC на кросс-валидации и на отоженной выборке. Это будет наш бейзлайн. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_no_cat, y = df.loc[:, df.dtypes != 'object'].drop('y', axis=1), df['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_no_cat_part, df_no_cat_valid, y_train_part, y_valid = train_test_split(df_no_cat, y,\n",
    "                                                                            test_size=.3, \n",
    "                                                                            stratify=y,\n",
    "                                                                            random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80544654453542641"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score(forest, df_no_cat_part, y_train_part, cv=skf, scoring='roc_auc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=17, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.fit(df_no_cat_part, y_train_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82466000555092989"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_valid, forest.predict_proba(df_no_cat_valid)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LabelEncoder для категориальных признаков\n",
    "Сделаем то же самое, но попробуем закодировать категориальные признаки по-простому: с помощью `LabelEncoder`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_cat_label_enc = df.copy().drop('y', axis=1)\n",
    "for col in df.columns[df.dtypes == 'object']:\n",
    "    df_cat_label_enc[col] = label_encoder.fit_transform(df_cat_label_enc[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4521, 16)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat_label_enc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_cat_label_enc_part, df_cat_label_enc_valid = train_test_split(df_cat_label_enc, test_size=.3, \n",
    "                                                    stratify=y, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84296976359098053"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score(forest, df_cat_label_enc_part, y_train_part, cv=skf, scoring='roc_auc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=17, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.fit(df_cat_label_enc_part, y_train_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84814737718567856"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_valid, forest.predict_proba(df_cat_label_enc_valid)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Бинаризация категориальных признаков (dummies, OHE)\n",
    "Теперь сделаем то, что обычно по умолчанию и делают – бинаризацию категориальных признаков. Dummy-признаки, One-Hot Encoding... с небольшими различиями это об одном же - для каждого значения каждого категориального признака завести свой бинарный признак."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_cat_dummies = pd.get_dummies(df, columns=df.columns[df.dtypes == 'object']).drop('y', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4521, 51)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat_dummies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_cat_dummies_part, df_cat_dummies_valid = train_test_split(df_cat_dummies, test_size=.3, \n",
    "                                                    stratify=y, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85510562350997199"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score(forest, df_cat_dummies_part, y_train_part, cv=skf, scoring='roc_auc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=17, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.fit(df_cat_dummies_part, y_train_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85877420525630344"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_valid, forest.predict_proba(df_cat_dummies_valid)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Попарные взаимодействия признаков\n",
    "Пока лес все еще лучше регрессии (хотя мы не тюнили гиперпараметры, но и не будем). Мы хотим идти дальше. Мощной техникой для работы с категориальными признаками будет учет попарных взаимодействий признаков (feature interactions). Построим попарные взаимодействия всех признаков. Вообще тут можно пойти дальше и строить взаимодействия трех и более признаков. Owen Zhang [как-то строил](https://www.youtube.com/watch?v=LgLcfZjNF44) даже 7-way interactions. Чего не сделаешь ради победы на Kaggle! :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_interact = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_features = df.columns[df.dtypes == 'object']\n",
    "for i, col1 in enumerate(cat_features):\n",
    "    for j, col2 in enumerate(cat_features[i + 1:]):\n",
    "        df_interact[col1 + '_' + col2] = df_interact[col1] + '_' + df_interact[col2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4521, 53)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_interact.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "      <th>job_marital</th>\n",
       "      <th>job_education</th>\n",
       "      <th>job_default</th>\n",
       "      <th>job_housing</th>\n",
       "      <th>job_loan</th>\n",
       "      <th>job_contact</th>\n",
       "      <th>job_month</th>\n",
       "      <th>job_poutcome</th>\n",
       "      <th>marital_education</th>\n",
       "      <th>marital_default</th>\n",
       "      <th>marital_housing</th>\n",
       "      <th>marital_loan</th>\n",
       "      <th>marital_contact</th>\n",
       "      <th>marital_month</th>\n",
       "      <th>marital_poutcome</th>\n",
       "      <th>education_default</th>\n",
       "      <th>education_housing</th>\n",
       "      <th>education_loan</th>\n",
       "      <th>education_contact</th>\n",
       "      <th>education_month</th>\n",
       "      <th>education_poutcome</th>\n",
       "      <th>default_housing</th>\n",
       "      <th>default_loan</th>\n",
       "      <th>default_contact</th>\n",
       "      <th>default_month</th>\n",
       "      <th>default_poutcome</th>\n",
       "      <th>housing_loan</th>\n",
       "      <th>housing_contact</th>\n",
       "      <th>housing_month</th>\n",
       "      <th>housing_poutcome</th>\n",
       "      <th>loan_contact</th>\n",
       "      <th>loan_month</th>\n",
       "      <th>loan_poutcome</th>\n",
       "      <th>contact_month</th>\n",
       "      <th>contact_poutcome</th>\n",
       "      <th>month_poutcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>married</td>\n",
       "      <td>primary</td>\n",
       "      <td>no</td>\n",
       "      <td>1787</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>19</td>\n",
       "      <td>oct</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>unemployed_married</td>\n",
       "      <td>unemployed_primary</td>\n",
       "      <td>unemployed_no</td>\n",
       "      <td>unemployed_no</td>\n",
       "      <td>unemployed_no</td>\n",
       "      <td>unemployed_cellular</td>\n",
       "      <td>unemployed_oct</td>\n",
       "      <td>unemployed_unknown</td>\n",
       "      <td>married_primary</td>\n",
       "      <td>married_no</td>\n",
       "      <td>married_no</td>\n",
       "      <td>married_no</td>\n",
       "      <td>married_cellular</td>\n",
       "      <td>married_oct</td>\n",
       "      <td>married_unknown</td>\n",
       "      <td>primary_no</td>\n",
       "      <td>primary_no</td>\n",
       "      <td>primary_no</td>\n",
       "      <td>primary_cellular</td>\n",
       "      <td>primary_oct</td>\n",
       "      <td>primary_unknown</td>\n",
       "      <td>no_no</td>\n",
       "      <td>no_no</td>\n",
       "      <td>no_cellular</td>\n",
       "      <td>no_oct</td>\n",
       "      <td>no_unknown</td>\n",
       "      <td>no_no</td>\n",
       "      <td>no_cellular</td>\n",
       "      <td>no_oct</td>\n",
       "      <td>no_unknown</td>\n",
       "      <td>no_cellular</td>\n",
       "      <td>no_oct</td>\n",
       "      <td>no_unknown</td>\n",
       "      <td>cellular_oct</td>\n",
       "      <td>cellular_unknown</td>\n",
       "      <td>oct_unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>4789</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>11</td>\n",
       "      <td>may</td>\n",
       "      <td>220</td>\n",
       "      <td>1</td>\n",
       "      <td>339</td>\n",
       "      <td>4</td>\n",
       "      <td>failure</td>\n",
       "      <td>0</td>\n",
       "      <td>services_married</td>\n",
       "      <td>services_secondary</td>\n",
       "      <td>services_no</td>\n",
       "      <td>services_yes</td>\n",
       "      <td>services_yes</td>\n",
       "      <td>services_cellular</td>\n",
       "      <td>services_may</td>\n",
       "      <td>services_failure</td>\n",
       "      <td>married_secondary</td>\n",
       "      <td>married_no</td>\n",
       "      <td>married_yes</td>\n",
       "      <td>married_yes</td>\n",
       "      <td>married_cellular</td>\n",
       "      <td>married_may</td>\n",
       "      <td>married_failure</td>\n",
       "      <td>secondary_no</td>\n",
       "      <td>secondary_yes</td>\n",
       "      <td>secondary_yes</td>\n",
       "      <td>secondary_cellular</td>\n",
       "      <td>secondary_may</td>\n",
       "      <td>secondary_failure</td>\n",
       "      <td>no_yes</td>\n",
       "      <td>no_yes</td>\n",
       "      <td>no_cellular</td>\n",
       "      <td>no_may</td>\n",
       "      <td>no_failure</td>\n",
       "      <td>yes_yes</td>\n",
       "      <td>yes_cellular</td>\n",
       "      <td>yes_may</td>\n",
       "      <td>yes_failure</td>\n",
       "      <td>yes_cellular</td>\n",
       "      <td>yes_may</td>\n",
       "      <td>yes_failure</td>\n",
       "      <td>cellular_may</td>\n",
       "      <td>cellular_failure</td>\n",
       "      <td>may_failure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35</td>\n",
       "      <td>management</td>\n",
       "      <td>single</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>1350</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>16</td>\n",
       "      <td>apr</td>\n",
       "      <td>185</td>\n",
       "      <td>1</td>\n",
       "      <td>330</td>\n",
       "      <td>1</td>\n",
       "      <td>failure</td>\n",
       "      <td>0</td>\n",
       "      <td>management_single</td>\n",
       "      <td>management_tertiary</td>\n",
       "      <td>management_no</td>\n",
       "      <td>management_yes</td>\n",
       "      <td>management_no</td>\n",
       "      <td>management_cellular</td>\n",
       "      <td>management_apr</td>\n",
       "      <td>management_failure</td>\n",
       "      <td>single_tertiary</td>\n",
       "      <td>single_no</td>\n",
       "      <td>single_yes</td>\n",
       "      <td>single_no</td>\n",
       "      <td>single_cellular</td>\n",
       "      <td>single_apr</td>\n",
       "      <td>single_failure</td>\n",
       "      <td>tertiary_no</td>\n",
       "      <td>tertiary_yes</td>\n",
       "      <td>tertiary_no</td>\n",
       "      <td>tertiary_cellular</td>\n",
       "      <td>tertiary_apr</td>\n",
       "      <td>tertiary_failure</td>\n",
       "      <td>no_yes</td>\n",
       "      <td>no_no</td>\n",
       "      <td>no_cellular</td>\n",
       "      <td>no_apr</td>\n",
       "      <td>no_failure</td>\n",
       "      <td>yes_no</td>\n",
       "      <td>yes_cellular</td>\n",
       "      <td>yes_apr</td>\n",
       "      <td>yes_failure</td>\n",
       "      <td>no_cellular</td>\n",
       "      <td>no_apr</td>\n",
       "      <td>no_failure</td>\n",
       "      <td>cellular_apr</td>\n",
       "      <td>cellular_failure</td>\n",
       "      <td>apr_failure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>1476</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>3</td>\n",
       "      <td>jun</td>\n",
       "      <td>199</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>management_married</td>\n",
       "      <td>management_tertiary</td>\n",
       "      <td>management_no</td>\n",
       "      <td>management_yes</td>\n",
       "      <td>management_yes</td>\n",
       "      <td>management_unknown</td>\n",
       "      <td>management_jun</td>\n",
       "      <td>management_unknown</td>\n",
       "      <td>married_tertiary</td>\n",
       "      <td>married_no</td>\n",
       "      <td>married_yes</td>\n",
       "      <td>married_yes</td>\n",
       "      <td>married_unknown</td>\n",
       "      <td>married_jun</td>\n",
       "      <td>married_unknown</td>\n",
       "      <td>tertiary_no</td>\n",
       "      <td>tertiary_yes</td>\n",
       "      <td>tertiary_yes</td>\n",
       "      <td>tertiary_unknown</td>\n",
       "      <td>tertiary_jun</td>\n",
       "      <td>tertiary_unknown</td>\n",
       "      <td>no_yes</td>\n",
       "      <td>no_yes</td>\n",
       "      <td>no_unknown</td>\n",
       "      <td>no_jun</td>\n",
       "      <td>no_unknown</td>\n",
       "      <td>yes_yes</td>\n",
       "      <td>yes_unknown</td>\n",
       "      <td>yes_jun</td>\n",
       "      <td>yes_unknown</td>\n",
       "      <td>yes_unknown</td>\n",
       "      <td>yes_jun</td>\n",
       "      <td>yes_unknown</td>\n",
       "      <td>unknown_jun</td>\n",
       "      <td>unknown_unknown</td>\n",
       "      <td>jun_unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>226</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>blue-collar_married</td>\n",
       "      <td>blue-collar_secondary</td>\n",
       "      <td>blue-collar_no</td>\n",
       "      <td>blue-collar_yes</td>\n",
       "      <td>blue-collar_no</td>\n",
       "      <td>blue-collar_unknown</td>\n",
       "      <td>blue-collar_may</td>\n",
       "      <td>blue-collar_unknown</td>\n",
       "      <td>married_secondary</td>\n",
       "      <td>married_no</td>\n",
       "      <td>married_yes</td>\n",
       "      <td>married_no</td>\n",
       "      <td>married_unknown</td>\n",
       "      <td>married_may</td>\n",
       "      <td>married_unknown</td>\n",
       "      <td>secondary_no</td>\n",
       "      <td>secondary_yes</td>\n",
       "      <td>secondary_no</td>\n",
       "      <td>secondary_unknown</td>\n",
       "      <td>secondary_may</td>\n",
       "      <td>secondary_unknown</td>\n",
       "      <td>no_yes</td>\n",
       "      <td>no_no</td>\n",
       "      <td>no_unknown</td>\n",
       "      <td>no_may</td>\n",
       "      <td>no_unknown</td>\n",
       "      <td>yes_no</td>\n",
       "      <td>yes_unknown</td>\n",
       "      <td>yes_may</td>\n",
       "      <td>yes_unknown</td>\n",
       "      <td>no_unknown</td>\n",
       "      <td>no_may</td>\n",
       "      <td>no_unknown</td>\n",
       "      <td>unknown_may</td>\n",
       "      <td>unknown_unknown</td>\n",
       "      <td>may_unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          job  marital  education default  balance housing loan  \\\n",
       "0   30   unemployed  married    primary      no     1787      no   no   \n",
       "1   33     services  married  secondary      no     4789     yes  yes   \n",
       "2   35   management   single   tertiary      no     1350     yes   no   \n",
       "3   30   management  married   tertiary      no     1476     yes  yes   \n",
       "4   59  blue-collar  married  secondary      no        0     yes   no   \n",
       "\n",
       "    contact  day month  duration  campaign  pdays  previous poutcome  y  \\\n",
       "0  cellular   19   oct        79         1     -1         0  unknown  0   \n",
       "1  cellular   11   may       220         1    339         4  failure  0   \n",
       "2  cellular   16   apr       185         1    330         1  failure  0   \n",
       "3   unknown    3   jun       199         4     -1         0  unknown  0   \n",
       "4   unknown    5   may       226         1     -1         0  unknown  0   \n",
       "\n",
       "           job_marital          job_education     job_default  \\\n",
       "0   unemployed_married     unemployed_primary   unemployed_no   \n",
       "1     services_married     services_secondary     services_no   \n",
       "2    management_single    management_tertiary   management_no   \n",
       "3   management_married    management_tertiary   management_no   \n",
       "4  blue-collar_married  blue-collar_secondary  blue-collar_no   \n",
       "\n",
       "       job_housing        job_loan          job_contact        job_month  \\\n",
       "0    unemployed_no   unemployed_no  unemployed_cellular   unemployed_oct   \n",
       "1     services_yes    services_yes    services_cellular     services_may   \n",
       "2   management_yes   management_no  management_cellular   management_apr   \n",
       "3   management_yes  management_yes   management_unknown   management_jun   \n",
       "4  blue-collar_yes  blue-collar_no  blue-collar_unknown  blue-collar_may   \n",
       "\n",
       "          job_poutcome  marital_education marital_default marital_housing  \\\n",
       "0   unemployed_unknown    married_primary      married_no      married_no   \n",
       "1     services_failure  married_secondary      married_no     married_yes   \n",
       "2   management_failure    single_tertiary       single_no      single_yes   \n",
       "3   management_unknown   married_tertiary      married_no     married_yes   \n",
       "4  blue-collar_unknown  married_secondary      married_no     married_yes   \n",
       "\n",
       "  marital_loan   marital_contact marital_month marital_poutcome  \\\n",
       "0   married_no  married_cellular   married_oct  married_unknown   \n",
       "1  married_yes  married_cellular   married_may  married_failure   \n",
       "2    single_no   single_cellular    single_apr   single_failure   \n",
       "3  married_yes   married_unknown   married_jun  married_unknown   \n",
       "4   married_no   married_unknown   married_may  married_unknown   \n",
       "\n",
       "  education_default education_housing education_loan   education_contact  \\\n",
       "0        primary_no        primary_no     primary_no    primary_cellular   \n",
       "1      secondary_no     secondary_yes  secondary_yes  secondary_cellular   \n",
       "2       tertiary_no      tertiary_yes    tertiary_no   tertiary_cellular   \n",
       "3       tertiary_no      tertiary_yes   tertiary_yes    tertiary_unknown   \n",
       "4      secondary_no     secondary_yes   secondary_no   secondary_unknown   \n",
       "\n",
       "  education_month education_poutcome default_housing default_loan  \\\n",
       "0     primary_oct    primary_unknown           no_no        no_no   \n",
       "1   secondary_may  secondary_failure          no_yes       no_yes   \n",
       "2    tertiary_apr   tertiary_failure          no_yes        no_no   \n",
       "3    tertiary_jun   tertiary_unknown          no_yes       no_yes   \n",
       "4   secondary_may  secondary_unknown          no_yes        no_no   \n",
       "\n",
       "  default_contact default_month default_poutcome housing_loan housing_contact  \\\n",
       "0     no_cellular        no_oct       no_unknown        no_no     no_cellular   \n",
       "1     no_cellular        no_may       no_failure      yes_yes    yes_cellular   \n",
       "2     no_cellular        no_apr       no_failure       yes_no    yes_cellular   \n",
       "3      no_unknown        no_jun       no_unknown      yes_yes     yes_unknown   \n",
       "4      no_unknown        no_may       no_unknown       yes_no     yes_unknown   \n",
       "\n",
       "  housing_month housing_poutcome  loan_contact loan_month loan_poutcome  \\\n",
       "0        no_oct       no_unknown   no_cellular     no_oct    no_unknown   \n",
       "1       yes_may      yes_failure  yes_cellular    yes_may   yes_failure   \n",
       "2       yes_apr      yes_failure   no_cellular     no_apr    no_failure   \n",
       "3       yes_jun      yes_unknown   yes_unknown    yes_jun   yes_unknown   \n",
       "4       yes_may      yes_unknown    no_unknown     no_may    no_unknown   \n",
       "\n",
       "  contact_month  contact_poutcome month_poutcome  \n",
       "0  cellular_oct  cellular_unknown    oct_unknown  \n",
       "1  cellular_may  cellular_failure    may_failure  \n",
       "2  cellular_apr  cellular_failure    apr_failure  \n",
       "3   unknown_jun   unknown_unknown    jun_unknown  \n",
       "4   unknown_may   unknown_unknown    may_unknown  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_interact.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Бинаризация категориальных признаков (dummies, OHE) + попарные взаимодействия\n",
    "Получилось аж 824 бинарных признака – многовато для такой задачи, и тут случайный лес начинает не справляться, да и логистическая регрессия сработала хуже, чем в прошлый раз."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_interact_cat_dummies = pd.get_dummies(df_interact, columns=df_interact.columns[df_interact.dtypes == 'object']).drop('y', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4521, 824)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_interact_cat_dummies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_interact_cat_dummies_part, df_interact_cat_dummies_valid = train_test_split(df_interact_cat_dummies, test_size=.3, \n",
    "                                                    stratify=y, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76169299122349465"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score(forest, df_interact_cat_dummies_part, y_train_part, cv=skf, scoring='roc_auc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=17, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.fit(df_interact_cat_dummies_part, y_train_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76730395610495528"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_valid, forest.predict_proba(df_interact_cat_dummies_valid)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Случайному лесу уже тяжеловато, когда признаков так много, а вот логистической регрессии – норм."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logit = LogisticRegression(random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86537104978487578"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score(logit, df_interact_cat_dummies_part, y_train_part, cv=skf, scoring='roc_auc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=17, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.fit(df_interact_cat_dummies_part, y_train_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88170648391297857"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_valid, logit.predict_proba(df_interact_cat_dummies_valid)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Target\n",
    "Теперь будем использовать технику кодирования категориальных признаков средним значением целевого признака. Это очень мощная техника, правда, надо умело ее использовать – легко переобучиться. \n",
    "Основная идея – для каждого значения категориального признака посчитать среднее значение целевого признака и заменить категориальный признак на посчитанные средние. Правда, считать средние надо на кросс-валидации, а то легко переобучиться. \n",
    "Но далее я адресую к видео топ-участников соревнований Kaggle, от них можно узнать про эту технику из первых уст. \n",
    "- [Специализация](https://www.coursera.org/specializations/aml) \"Advanced Machine Learning\" на Coursera, [курс](https://www.coursera.org/learn/competitive-data-science)\", How to Win a Data Science Competition: Learn from Top Kagglers\", несколько видео посвящено различным способам построяния признаков с задействованием целевого, и как при этом не переобучиться. Рассказывает Дмитрий Алтухов\n",
    "- [Лекция](https://www.youtube.com/watch?v=g335THJxkto) с презентацией решения конкурса Kaggle BNP paribas, Станислав Семенов\n",
    "\n",
    "Похожая техника [используется](https://tech.yandex.com/catboost/doc/dg/concepts/algorithm-main-stages_cat-to-numberic-docpage/) и в CatBoost.\n",
    "\n",
    "Для начала давайте таким образом закодируем исходные категориальные признаки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df, y = df.copy(), df['y']\n",
    "train_df_part, valid_df, y_train_part, y_valid = train_test_split(train_df.drop('y', axis=1), y, \n",
    "                                                                  test_size=.3, stratify=y, \n",
    "                                                                               random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_target_enc(train_df, y_train, valid_df, skf):\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "    \n",
    "    glob_mean = y_train.mean()\n",
    "    train_df = pd.concat([train_df, pd.Series(y_train, name='y')], axis=1)\n",
    "    new_train_df = train_df.copy()\n",
    "    \n",
    "    cat_features = train_df.columns[train_df.dtypes == 'object'].tolist()    \n",
    "\n",
    "    for col in cat_features:\n",
    "        new_train_df[col + '_mean_target'] = [glob_mean for _ in range(new_train_df.shape[0])]\n",
    "\n",
    "    for train_idx, valid_idx in skf.split(train_df, y_train):\n",
    "        train_df_cv, valid_df_cv = train_df.iloc[train_idx, :], train_df.iloc[valid_idx, :]\n",
    "\n",
    "        for col in cat_features:\n",
    "            \n",
    "            means = valid_df_cv[col].map(train_df_cv.groupby(col)['y'].mean())\n",
    "            valid_df_cv[col + '_mean_target'] = means.fillna(glob_mean)\n",
    "            \n",
    "        new_train_df.iloc[valid_idx] = valid_df_cv\n",
    "    \n",
    "    new_train_df.drop(cat_features + ['y'], axis=1, inplace=True)\n",
    "    \n",
    "    for col in cat_features:\n",
    "        means = valid_df[col].map(train_df.groupby(col)['y'].mean())\n",
    "        valid_df[col + '_mean_target'] = means.fillna(glob_mean)\n",
    "        \n",
    "    valid_df.drop(train_df.columns[train_df.dtypes == 'object'], axis=1, inplace=True)\n",
    "    \n",
    "    return new_train_df, valid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean_target_part, valid_mean_target = mean_target_enc(train_df_part, y_train_part, valid_df, skf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86043919723156748"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score(forest, train_mean_target_part, y_train_part, cv=skf, scoring='roc_auc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=17, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.fit(train_mean_target_part, y_train_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87816776617775782"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_valid, forest.predict_proba(valid_mean_target)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Target + попарные взаимодействия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df, y = df_interact.drop('y', axis=1).copy(), df_interact['y']\n",
    "train_df_part, valid_df, y_train_part, y_valid = train_test_split(train_df, y, \n",
    "                                                                  test_size=.3, stratify=y, \n",
    "                                                                               random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean_target_part, valid_mean_target = mean_target_enc(train_df_part, y_train_part, valid_df, skf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85829352194476427"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score(forest, train_mean_target_part, y_train_part, cv=skf, scoring='roc_auc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=17, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.fit(train_mean_target_part, y_train_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85002348470291844"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_valid, forest.predict_proba(valid_mean_target)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Опять лучше справляется логистическая регрессия."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89699479956169981"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score(logit, train_mean_target_part, y_train_part, cv=skf, scoring='roc_auc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=17, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.fit(train_mean_target_part, y_train_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89738252311108258"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_valid, logit.predict_proba(valid_mean_target)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catboost\n",
    "В библиотеке [Catboost](https://catboost.yandex), помимо всего прочего, реализована как раз техника кодирования категориальных значений средним значением целевого признака. Результаты получаются хорошими именно когда в данных много важных категориальных признаков. Из минусов можно отметить меньшую (пока что) производительность в сравнении с Xgboost и LightGBM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ctb = CatBoostClassifier(random_seed=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df, y = df.drop('y', axis=1), df['y']\n",
    "train_df_part, valid_df, y_train_part, y_valid = train_test_split(train_df, y, \n",
    "                                                                  test_size=.3, stratify=y, \n",
    "                                                                  random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features_idx = np.where(train_df_part.dtypes == 'object')[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 32s, sys: 2min 39s, total: 6min 12s\n",
      "Wall time: 1min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cv_scores = []\n",
    "for train_idx, test_idx in skf.split(train_df_part, y_train_part):\n",
    "    cv_train_df, cv_valid_df = train_df_part.iloc[train_idx, :], train_df_part.iloc[test_idx, :]\n",
    "    y_cv_train, y_cv_valid = y_train_part.iloc[train_idx], y_train_part.iloc[test_idx]\n",
    "    \n",
    "    ctb.fit(cv_train_df, y_cv_train,\n",
    "        cat_features=cat_features_idx);\n",
    "    \n",
    "    cv_scores.append(roc_auc_score(y_cv_valid, ctb.predict_proba(cv_valid_df)[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91049797128643883"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 44.2 s, sys: 30.8 s, total: 1min 14s\n",
      "Wall time: 14 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x111bbd208>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "ctb.fit(train_df_part, y_train_part,\n",
    "        cat_features=cat_features_idx);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91797433762462899"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_valid, ctb.predict_proba(valid_df)[:, 1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
