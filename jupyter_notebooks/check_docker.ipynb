{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# packages in environment at /opt/conda:\n",
      "#\n",
      "pandas                    0.19.2              np112py35_1    conda-forge\n"
     ]
    }
   ],
   "source": [
    "!conda list pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# packages in environment at /opt/conda:\n",
      "#\n",
      "scikit-learn              0.18            np112py35_blas_openblas_204  [blas_openblas]  conda-forge\n"
     ]
    }
   ],
   "source": [
    "!conda list scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# packages in environment at /opt/conda:\n",
      "#\n",
      "statsmodels               0.8.0               np112py35_0    conda-forge\n"
     ]
    }
   ],
   "source": [
    "!conda list statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "VW options:\r\n",
      "  -h [ --help ]                         Look here: http://hunch.net/~vw/ and \r\n",
      "                                        click on Tutorial.\r\n",
      "  --active_learning                     active learning mode\r\n",
      "  --active_simulation                   active learning simulation mode\r\n",
      "  --active_mellowness arg               active learning mellowness parameter \r\n",
      "                                        c_0. Default 8\r\n",
      "  --binary                              report loss as binary classification on\r\n",
      "                                        -1,1\r\n",
      "  --autolink arg                        create link function with polynomial d\r\n",
      "  --sgd                                 use regular stochastic gradient descent\r\n",
      "                                        update.\r\n",
      "  --adaptive                            use adaptive, individual learning \r\n",
      "                                        rates.\r\n",
      "  --invariant                           use safe/importance aware updates.\r\n",
      "  --normalized                          use per feature normalized updates\r\n",
      "  --exact_adaptive_norm                 use current default invariant \r\n",
      "                                        normalized adaptive update rule\r\n",
      "  -a [ --audit ]                        print weights of features\r\n",
      "  -b [ --bit_precision ] arg            number of bits in the feature table\r\n",
      "  --bfgs                                use bfgs optimization\r\n",
      "  -c [ --cache ]                        Use a cache.  The default is \r\n",
      "                                        <data>.cache\r\n",
      "  --cache_file arg                      The location(s) of cache_file.\r\n",
      "  --compressed                          use gzip format whenever possible. If a\r\n",
      "                                        cache file is being created, this \r\n",
      "                                        option creates a compressed cache file.\r\n",
      "                                        A mixture of raw-text & compressed \r\n",
      "                                        inputs are supported with \r\n",
      "                                        autodetection.\r\n",
      "  --no_stdin                            do not default to reading from stdin\r\n",
      "  --conjugate_gradient                  use conjugate gradient based \r\n",
      "                                        optimization\r\n",
      "  --csoaa arg                           Use one-against-all multiclass learning\r\n",
      "                                        with <k> costs\r\n",
      "  --wap arg                             Use weighted all-pairs multiclass \r\n",
      "                                        learning with <k> costs\r\n",
      "  --csoaa_ldf arg                       Use one-against-all multiclass learning\r\n",
      "                                        with label dependent features.  Specify\r\n",
      "                                        singleline or multiline.\r\n",
      "  --wap_ldf arg                         Use weighted all-pairs multiclass \r\n",
      "                                        learning with label dependent features.\r\n",
      "                                          Specify singleline or multiline.\r\n",
      "  --cb arg                              Use contextual bandit learning with <k>\r\n",
      "                                        costs\r\n",
      "  --l1 arg                              l_1 lambda\r\n",
      "  --l2 arg                              l_2 lambda\r\n",
      "  -d [ --data ] arg                     Example Set\r\n",
      "  --daemon                              persistent daemon mode on port 26542\r\n",
      "  --num_children arg                    number of children for persistent \r\n",
      "                                        daemon mode\r\n",
      "  --pid_file arg                        Write pid file in persistent daemon \r\n",
      "                                        mode\r\n",
      "  --decay_learning_rate arg             Set Decay factor for learning_rate \r\n",
      "                                        between passes\r\n",
      "  --input_feature_regularizer arg       Per feature regularization input file\r\n",
      "  -f [ --final_regressor ] arg          Final regressor\r\n",
      "  --readable_model arg                  Output human-readable final regressor\r\n",
      "  --hash arg                            how to hash the features. Available \r\n",
      "                                        options: strings, all\r\n",
      "  --hessian_on                          use second derivative in line search\r\n",
      "  --version                             Version information\r\n",
      "  --ignore arg                          ignore namespaces beginning with \r\n",
      "                                        character <arg>\r\n",
      "  --keep arg                            keep namespaces beginning with \r\n",
      "                                        character <arg>\r\n",
      "  -k [ --kill_cache ]                   do not reuse existing cache: create a \r\n",
      "                                        new one always\r\n",
      "  --initial_weight arg                  Set all weights to an initial value of \r\n",
      "                                        1.\r\n",
      "  -i [ --initial_regressor ] arg        Initial regressor(s)\r\n",
      "  --initial_pass_length arg             initial number of examples per pass\r\n",
      "  --initial_t arg                       initial t value\r\n",
      "  --lda arg                             Run lda with <int> topics\r\n",
      "  --span_server arg                     Location of server for setting up \r\n",
      "                                        spanning tree\r\n",
      "  --min_prediction arg                  Smallest prediction to output\r\n",
      "  --max_prediction arg                  Largest prediction to output\r\n",
      "  --mem arg                             memory in bfgs\r\n",
      "  --nn arg                              Use sigmoidal feedforward network with \r\n",
      "                                        <k> hidden units\r\n",
      "  --noconstant                          Don't add a constant feature\r\n",
      "  --noop                                do no learning\r\n",
      "  --oaa arg                             Use one-against-all multiclass learning\r\n",
      "                                        with <k> labels\r\n",
      "  --ect arg                             Use error correcting tournament with \r\n",
      "                                        <k> labels\r\n",
      "  --output_feature_regularizer_binary arg\r\n",
      "                                        Per feature regularization output file\r\n",
      "  --output_feature_regularizer_text arg Per feature regularization output file,\r\n",
      "                                        in text\r\n",
      "  --port arg                            port to listen on\r\n",
      "  --power_t arg                         t power value\r\n",
      "  -l [ --learning_rate ] arg            Set Learning Rate\r\n",
      "  --passes arg                          Number of Training Passes\r\n",
      "  --termination arg                     Termination threshold\r\n",
      "  -p [ --predictions ] arg              File to output predictions to\r\n",
      "  -q [ --quadratic ] arg                Create and use quadratic features\r\n",
      "  --cubic arg                           Create and use cubic features\r\n",
      "  --quiet                               Don't output diagnostics\r\n",
      "  --rank arg                            rank for matrix factorization.\r\n",
      "  --random_weights arg                  make initial weights random\r\n",
      "  --random_seed arg                     seed random number generator\r\n",
      "  -r [ --raw_predictions ] arg          File to output unnormalized predictions\r\n",
      "                                        to\r\n",
      "  --ring_size arg                       size of example ring\r\n",
      "  --examples arg                        number of examples to parse\r\n",
      "  --save_per_pass                       Save the model after every pass over \r\n",
      "                                        data\r\n",
      "  --save_resume                         save extra state so learning can be \r\n",
      "                                        resumed later with new data\r\n",
      "  --sendto arg                          send examples to <host>\r\n",
      "  --searn arg                           use searn, argument=maximum action id\r\n",
      "  --searnimp arg                        use searn, argument=maximum action id \r\n",
      "                                        or 0 for LDF\r\n",
      "  -t [ --testonly ]                     Ignore label information and just test\r\n",
      "  --loss_function arg (=squared)        Specify the loss function to be used, \r\n",
      "                                        uses squared by default. Currently \r\n",
      "                                        available ones are squared, classic, \r\n",
      "                                        hinge, logistic and quantile.\r\n",
      "  --quantile_tau arg (=0.5)             Parameter \\tau associated with Quantile\r\n",
      "                                        loss. Defaults to 0.5\r\n",
      "  --unique_id arg                       unique id used for cluster parallel \r\n",
      "                                        jobs\r\n",
      "  --total arg                           total number of nodes used in cluster \r\n",
      "                                        parallel job\r\n",
      "  --node arg                            node number in cluster parallel job\r\n",
      "  --sort_features                       turn this on to disregard order in \r\n",
      "                                        which features have been defined. This \r\n",
      "                                        will lead to smaller cache sizes\r\n",
      "  --ngram arg                           Generate N grams\r\n",
      "  --skips arg                           Generate skips in N grams. This in \r\n",
      "                                        conjunction with the ngram tag can be \r\n",
      "                                        used to generate generalized \r\n",
      "                                        n-skip-k-gram.\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!vw --help"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
