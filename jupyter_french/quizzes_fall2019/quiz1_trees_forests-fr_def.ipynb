{
  "cells": [
    {
      "metadata": {
        "lang": "fr"
      },
      "cell_type": "markdown",
      "source": "<center>\n<img src=\"https://github.com/Yorko/mlcourse.ai/blob/master/img/ods_stickers.jpg?raw=true\" />\n    \n##  mlcourse.ai – Open Machine Learning Course\nAuteur: [Yury Kashnitsky](https://yorko.github.io) (@yorko). Edité par Roman Volykhin(@GerrBert) et [Ousmane Cissé](https://github.com/oussou-dev). Ce matériel est soumis aux termes et conditions de la licence [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/). L'utilisation gratuite est autorisée à des fins non commerciales."
    },
    {
      "metadata": {
        "lang": "fr"
      },
      "cell_type": "markdown",
      "source": "# <center> Automne 2019. Quiz 1. Arbres de décision et forêts aléatoires\n    \nAvant de vous atteler à la tâche, nous vous conseillons de consulter le matériel de cours correspondant :\n\n 1. [Classification, arbres-de-décision et k-plus-proches-voisins](https://mlcourse.ai/articles/topic3-dt-knn/) et en version interactive sur [Kaggle Kernel](https://www.kaggle.com/kashnitsky/topic-3-decision-trees-and-knn)\n 2. Ensembles:\n  - [Bagging](https://mlcourse.ai/articles/topic5-part1-bagging/), en version interactive sur [Kaggle](https://www.kaggle.com/kashnitsky/topic-5-ensembles- part-1-bagging)\n  - [Forêt aléatoire](https://mlcourse.ai/articles/topic5-part2-rf/), en version interactive sur [Kaggle](https://www.kaggle.com/kashnitsky/topic-5-ensembles -part-2-random-forest)\n  - [Feature Importance](https://mlcourse.ai/articles/topic5-part3-feature-importance/), en version intercative sur [Kaggle](https://www.kaggle.com/kashnitsky/topic-5 -assemble-part-3-feature-importance)\n 3. Il y a 5 conférences vidéo sur les arbres, les forêts et leurs applications : [mlcourse.ai/lectures](https://mlcourse.ai/lectures)\n  \nNous vous suggérons de commencer par lire les articles (les questions du quiz basées sur ceux-ci), si quelque chose n’est pas clair - regardez le cours correspondant.\n \n### Votre mission consiste à:\n 1. étudier le matériel\n 1. écrire le code si nécessaire\n 1. Choisir les réponses dans le [formulaire](https://docs.google.com/forms/d/1eT1niiuyFvmpYjL5rY6wRplocoqUHdeCTd6jAa_vsrk).\n\n \n### <center> Date limite de soummission : 27 septembre 2019, 20h59 CET (heure de Londres)\n    \nLes solutions seront discutées lors d'une session en direct sur YouTube le 28 septembre. Vous pouvez obtenir jusqu'à 10 crédits (les points le formulaire Web, 15 maximum, seront réduits à un maximum de 10 crédits)."
    },
    {
      "metadata": {
        "lang": "fr"
      },
      "cell_type": "markdown",
      "source": "## Partie 1. Les arbres de décision\n\n*Pour les discussions, merci de vous en tenir à [ODS Slack](https://opendatascience.slack.com/), channel __#mlcourse_ai_news__, fil épinglé __#quiz1\\_fall2019__*\n\n**Question 1**. Lequel de ces problèmes n'entre pas dans 3 types principaux de tâches de ML (machine learning): classification, régression et regroupement?\n 1. Identifier quel est sujet de la discussion en direct (live-chat) avec un client\n 2. Regrouper les informations en sujets/thématiques\n 3. Prédire la Valeur Vie Client (Life-Time Value) - le montant dépensé par un client sur une longue période de temps\n 4. Répertorier les meilleurs produits qu'un utilisateur est susceptible d'acheter (en fonction de l'historique de ses clics)"
    },
    {
      "metadata": {
        "lang": "fr"
      },
      "cell_type": "markdown",
      "source": "**Question 2**. L'entropie maximale possible est atteinte lorsque tous les états sont également probables (prouvez-le vous-même avec un système à 2 états et des probabilités $p$ et $1-p$). Quelle est l'entropie maximale possible d'un système à N états ? (ici tous les \"log\" sont en base 2)\n 1. $N \\log N$\n 1. $-\\log N$\n 1. $\\log N$\n 1. $-N \\log N$"
    },
    {
      "metadata": {
        "lang": "fr"
      },
      "cell_type": "markdown",
      "source": "**Question 3**. Dans l’article du Thème 3 portant sur un exemple basé sur un jeu avec 20 boules, quel est le gain d’information lié à la partition de 20 boules en 2 groupes en fonction de la condition X <= 8 ?\n\n 1. ~ 0.1\n 1. ~ 0.01\n 1. ~ 0.001\n 1. ~ 0.0001"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<img src=\"https://github.com/Yorko/mlcourse.ai/blob/master/img/topic3_entropy_balls1.png?raw=true\">"
    },
    {
      "metadata": {
        "lang": "fr"
      },
      "cell_type": "markdown",
      "source": "**Question 4.** Dans une tâche de classification binaire basée sur un jeu, il existe des caractéristiques $d$, $x_1 \\ldots x_d$, mais la cible $y$ dépend uniquement de $x_1$ et $x_2$: $y = [\\frac{x_1^2}{4} + \\frac{x_2^2}{9} \\leq 16]$, où $[\\cdot]$ est une fonction \"d'indicateur\". Toutes les caractéristiques $x_3 \\ldots x_d$ sont assimilées à du bruit, c’est-à-dire qu’elles n’influencent pas la caractéristque cible. De toute évidence, les algorithmes d’apprentissage automatique fonctionneront presque parfaitement dans cette tâche, où la cible est une simple fonction des caractéristiques d'entrée. Si nous entraînons le `DecisionTreeClassifier` de Sklearn pour cette tâche, quels paramètres ont un effet crucial sur la précision (crucial - signifie que si ces paramètres ne sont pas définis correctement, la précision peut chuter de manière significative) ? Sélectionnez tous les paramètres cruciaux (pour obtenir des crédits, vous devez sélectionner tous les bons paramètres, pas de réponses partiellement correctes).\n 1. `max_features`\n 2. `criterion`\n 3. `min_samples_leaf`\n 4. `max_depth`"
    },
    {
      "metadata": {
        "lang": "fr"
      },
      "cell_type": "markdown",
      "source": "**Question 5.** Chargez les données du dataset iris avec `sklearn.datasets.load_iris`. Entraînez un arbre de décision avec ces données en spécifiant les paramètres `max_depth` = 4 et `random_state` = 17 (tous les autres arguments ne doivent pas être modifiés). Utilisez toutes les 150 instances disponibles pour former un arbre (n'effectuez pas de fractionnement train/validation). Visualisez l’arbre de décision entraîné, voir l Thème 3 pour des exemples. Appelons \"feuille dans un arbre pur\" (leaf in a _tree pure_), s'il contient des instances d'une seule classe. Combien de feuilles \"pures\" y a-t-il dans cet arbre ?\n\n 1. 6\n 2. 7\n 3. 8\n 4. 9"
    },
    {
      "metadata": {
        "lang": "fr"
      },
      "cell_type": "markdown",
      "source": "## Partie 2. Ensembles et forêts aléatoires\n\n*Pour les discussions, merci de vous en tenir à [ODS Slack](https://opendatascience.slack.com/), channel __#mlcourse_ai_news__, fil épinglé __#quiz1_fall2019__*"
    },
    {
      "metadata": {
        "lang": "fr"
      },
      "cell_type": "markdown",
      "source": "**Question 6.** Il y a 7 jurés dans la salle d'audience. Chacun d’eux individuellement peut déterminer correctement si le défendeur est coupable ou non avec une probabilité de 80%. Quelle est la probabilité que le jury rende un verdict correct conjointement si la décision est prise à la majorité des voix ?\n\n\n\n 1. 20,97%\n 2. 80,00%\n 3. 83,70%\n 4. 96,66%"
    },
    {
      "metadata": {
        "lang": "fr"
      },
      "cell_type": "markdown",
      "source": "**Question 7.** Dans [Thème 5, partie 2](https://mlcourse.ai/articles/topic5-part2-rf/), section 2. \"Comparaison avec les Arbres de décision et le Bagging\", nous montrons comment le Bagging et le Random Forest (forêts aléatoires) améliorent la précision de la classification par rapport à un arbre de décision unique. Lequel des éléments suivants explique mieux la différence visuelle entre les limites de décision construites par un seul arbre de décision et celles construites par des modèles d'Ensemble ?\n\n 1. Les ensembles ignorent certaines des fonctionnalités. Ne choisissant que les plus importants, ils établissent une frontière de décision plus lisse\n 2. Certaines des règles de classification créées par un arbre de décision ne peuvent être appliquées qu'à un petit nombre d'instances d'entraînement\n 3. Lors de la construction d'un arbre de décision, si deux divisions potentielles sont également bonnes en termes de critère d'information, une division aléatoire est choisie. Cela conduit à un certain hasard dans la construction d'un arbre de décision. Par conséquent, sa limite de décision est très irrégulière"
    },
    {
      "metadata": {
        "lang": "fr"
      },
      "cell_type": "markdown",
      "source": "**Question 8.** Random Forest apprend (forêts aléatoires) un coefficient pour chaque caractéristique d'entrée, qui indique dans quelle mesure cette caractéristique influence la caractéristique cible. Vrai faux?\n 1. Vrai\n 2. Faux\n\n**Question 9.** Supposons que nous entraînions le `RandomForestRegressor` pour prédire l'âge d'un client (une tâche bien réelle, utile pour le ciblage des annonces), et que l'âge maximal indiqué dans le jeu de données est de 98 ans. Est-il possible que, pour certains clients, le modèle prédise un âge qui sera de 105 ans?\n 1. oui\n 2. non\n \n**Question 10.** Sélectionnez toutes les déclarations soutenant les avantages de Random Forest par rapport aux arbres de décision (certaines déclarations peuvent être vraies mais ne concernent pas les avantages de Random Forest, ne les sélectionnez pas).\n\n 1. Random Forest (forêts aléatoires) est plus facile à entraîner en termes de ressources informatiques\n 2. Une forêt aléatoire nécessite généralement plus de RAM qu'un seul arbre de décision\n 3. Random Forest réalise généralement de meilleurs métriques dans les tâches de classification/régression\n 4. La prédiction d'un arbre de décision unique peut être beaucoup plus facile à interpréter"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "file_extension": ".py",
      "version": "3.5.4",
      "pygments_lexer": "ipython3",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    },
    "hide_input": false,
    "toc": {
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "base_numbering": 1,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "nbTranslate": {
      "hotkey": "alt-t",
      "sourceLang": "en",
      "targetLang": "fr",
      "displayLangs": [
        "*"
      ],
      "langInMainMenu": true,
      "useGoogleTranslate": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}