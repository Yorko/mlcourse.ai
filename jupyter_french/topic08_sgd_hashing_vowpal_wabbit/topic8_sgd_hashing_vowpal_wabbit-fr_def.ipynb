{
 "cells": [
  {
   "metadata": {
    "lang": "fr"
   },
   "cell_type": "markdown",
   "source": "<center>\n<img src=\"https://raw.githubusercontent.com/Yorko/mlcourse.ai/master/img/ods_stickers.jpg\" />\n    \n## [mlcourse.ai](https://mlcourse.ai) - Open Machine Learning Course\n\n<center>\nAuteur: [Yury Kashnitskiy](https://yorko.github.io).  \nTraduit et édité par [Serge Oreshkov](https://www.linkedin.com/in/sergeoreshkov/), [Yuanyuan Pao](https://www.linkedin.com/in/yuanyuanpao/) et [Ousmane Cissé](https://www.linkedin.com/in/ousmane-ciss%C3%A9/).  \nCe matériel est soumis aux termes et conditions de la licence [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/).  \nL'utilisation gratuite est autorisée à des fins non commerciales.\n\n# <center> Topic 8. Vowpal Wabbit: apprendre avec des gigaoctets de données\nCette semaine, nous aborderons deux raisons qui expliquent la vitesse d'entraînement exceptionnelle de Vowpal Wabbit, à savoir l'apprentissage en ligne et le hashing trick, tant en théorie qu'en pratique. Nous allons l'essayer avec des articles d'actualités, des critiques de films et des questions sur le StackOverflow."
  },
  {
   "metadata": {
    "lang": "fr"
   },
   "cell_type": "markdown",
   "source": "# Plan de l'article\n1. [Stochastic gradient descent and online learning](#1.-Stochastic-gradient-descent-and-online-learning)\n    - 1.1. [SGD](#1.1.-Stochastic-gradient-descent)\n    - 1.2. [Online approach to learning](#1.2.-Online-approach-to-learning)\n2. [Categorical feature processing](#2.-Categorical-feature-processing)\n    - 2.1. [Label Encoding](#2.1.-Label-Encoding)\n    - 2.2. [One-Hot Encoding](#2.2.-One-Hot-Encoding)\n    - 2.3. [Hashing trick](#2.3.-Hashing-trick)\n3. [Vowpal Wabbit](#3.-Vowpal-Wabbit)\n    - 3.1. [News. Binary classification](#3.1.-News.-Binary-classification)\n    - 3.2. [News. Multiclass classification](#3.2.-News.-Multiclass-classification)\n    - 3.3. [IMDB movie reviews](#3.3.-IMDB-movie-reviews)\n    - 3.4. [Classifying gigabytes of StackOverflow questions](#3.4.-Classifying-gigabytes-of-StackOverflow-questions)\n4. [Demo assignment](#4.-Demo-assignment)\n5. [Useful resources](#5.-Useful-resources)"
  },
  {
   "metadata": {
    "_cell_guid": "64efb6ef-3591-4036-8461-b7b467f404b7",
    "_uuid": "bd1f11458028d021571d4a77e3de846bf0dee992",
    "trusted": false
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.datasets import fetch_20newsgroups, load_files\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    log_loss,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": false
   },
   "cell_type": "code",
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "lang": "fr"
   },
   "cell_type": "markdown",
   "source": "## 1. Descente de gradient stochastique et apprentissage en ligne\n### 1.1. Descente de gradient stochastique\n\nBien que la descente de gradient soit l'une des premières choses apprises dans les cours d'apprentissage automatique et d'optimisation, c'est l'une de ses modifications, la descente de gradient stochastique (SGD), qui est difficile à surmonter.\n\nRappelons que l'idée de la descente en gradient est de minimiser certaines fonctions en faisant de petits pas dans le sens de la décroissance la plus rapide. Cette méthode a été nommée en raison du fait suivant du calcul: le vecteur $\\nabla f = (\\frac{\\partial f}{\\partial x_1}, \\ldots \\frac{\\partial f}{\\partial x_n})^\\text{T}$ des dérivées partielles de la fonction $f(x) = f(x_1, \\ldots x_n)$ pointe vers la direction de la croissance de la fonction la plus rapide. Cela signifie qu'en se déplaçant dans la direction opposée (antigradient), il est possible de diminuer la valeur de la fonction avec le taux le plus rapide.\n\n<img src='https://habrastorage.org/files/4f2/75d/a46/4f275da467a44fc4a8d1a11007776ed2.jpg' width=50%>\n\nVoici un snowboarder (moi) à Sheregesh, la station d'hiver la plus populaire de Russie. (Je le recommande vivement si vous aimez le ski ou le snowboard). En plus de faire la publicité des beaux paysages, cette image dépeint l'idée d'une descente en pente. Si vous voulez rouler le plus vite possible, vous devez choisir le chemin de descente le plus raide. Le calcul des antigradients peut être considéré comme une évaluation de la pente à divers endroits."
  },
  {
   "metadata": {
    "lang": "fr"
   },
   "cell_type": "markdown",
   "source": "**Exemple**\n\nLe problème de la régression par paires peut être résolu par la descente en pente. Prévoyons une variable à l'aide d'une autre : la taille avec le poids. Supposons que ces variables soient linéairement dépendantes. Nous utiliserons l'ensemble de données [SOCR](http://wiki.stat.ucla.edu/socr/index.php/SOCR_Data)."
  },
  {
   "metadata": {
    "_cell_guid": "84022022-7ce2-4fac-90ae-3cefc5a12961",
    "_uuid": "0873cf8a28158f2ebdd5b3b42d3026efcd8e6b58",
    "trusted": false
   },
   "cell_type": "code",
   "source": [
    "PATH_TO_ALL_DATA = \"../../data/\"\n",
    "data_demo = pd.read_csv(os.path.join(PATH_TO_ALL_DATA, \"weights_heights.csv\"))"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "_cell_guid": "094aa0fc-8af4-4a13-88a7-4eedf53fd712",
    "_uuid": "a60148fd610f423b517a38dad8768f0f6c76d192",
    "trusted": false
   },
   "cell_type": "code",
   "source": [
    "plt.scatter(data_demo[\"Weight\"], data_demo[\"Height\"])\n",
    "plt.xlabel(\"Weight in lb\")\n",
    "plt.ylabel(\"Height in inches\");"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": "<Figure size 432x288 with 1 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ]
  },
  {
   "metadata": {
    "lang": "fr"
   },
   "cell_type": "markdown",
   "source": "Nous avons un vecteur $x$ de dimension $\\ell$ (poids de chaque personne, c'est-à-dire un échantillon d'entraînement) et $y$, un vecteur contenant la taille de chaque personne dans l'ensemble de données.\n\nLa tâche est la suivante: trouver les poids $w_0$ et $w_1$ de telle sorte que la prédiction de la hauteur comme $y_i = w_0 + w_1 x_i$ (où $y_i$ est la valeur de hauteur $i$-th, $x_i$ est la valeur de poids $i$-th) minimise l'erreur quadratique (ainsi que l'erreur quadratique moyenne car $\\frac{1}{\\ell}$ ne fait aucune différence):\n$$SE(w_0, w_1) = \\frac{1}{2}\\sum_{i=1}^\\ell(y_i - (w_0 + w_1x_{i}))^2 \\rightarrow min_{w_0,w_1}$$\n\nNous utiliserons la descente de gradient, en utilisant les dérivées partielles de $SE(w_0, w_1)$ sur les poids $w_0$ et $w_1$.\nUne procédure d'apprentissage itérative est alors définie par de simples formules de mise à jour (on modifie les poids du modèle par petits pas, proportionnels à une petite constante $\\eta$, vers l'antigradient de la fonction $SE(w_0, w_1)$):\n\n$$\\begin{array}{rcl} w_0^{(t+1)} = w_0^{(t)} -\\eta \\frac{\\partial SE}{\\partial w_0} |_{t} \\\\  w_1^{(t+1)} = w_1^{(t)} -\\eta \\frac{\\partial SE}{\\partial w_1} |_{t} \\end{array}$$\n\nEn calculant les dérivées partielles, nous obtenons ce qui suit:\n\n$$\\begin{array}{rcl} w_0^{(t+1)} = w_0^{(t)} + \\eta \\sum_{i=1}^{\\ell}(y_i - w_0^{(t)} - w_1^{(t)}x_i) \\\\  w_1^{(t+1)} = w_1^{(t)} + \\eta \\sum_{i=1}^{\\ell}(y_i - w_0^{(t)} - w_1^{(t)}x_i)x_i \\end{array}$$\n\nCe calcul fonctionne très bien tant que la quantité de données n'est pas importante (nous ne discuterons pas des problèmes avec les minima locaux, les points-selle, le choix du taux d'apprentissage, des moments et d'autres choses - ces sujets sont traités en détail dans [the Numeric Computation chapter in \"Deep Learning\"](http://www.deeplearningbook.org/contents/numerical.html)).\nIl y a un problème avec la descente de gradient par lots - l'évaluation du gradient nécessite la somme d'un certain nombre de valeurs pour chaque objet de l'ensemble d'apprentissage. En d'autres termes, l'algorithme nécessite beaucoup d'itérations, et chaque itération recalcule les poids avec une formule qui contient une somme $\\sum_{i=1}^\\ell$ sur l'ensemble de l'entraînement. Que se passe-t-il lorsque nous avons des milliards d'échantillons d'entraînement?\n\n<img src=\"https://habrastorage.org/webt/ow/ng/cs/owngcs-lzoguklv1pn9vz_r4ssm.jpeg\" />\n\nD'où la motivation pour une descente de gradient stochastique! Autrement dit, nous jetons le signe de sommation et mettons à jour les poids uniquement sur des échantillons d'entraînement uniques (ou un petit nombre d'entre eux). Dans notre cas, nous avons les éléments suivants:\n\n$$\\begin{array}{rcl} w_0^{(t+1)} = w_0^{(t)} + \\eta (y_i - w_0^{(t)} - w_1^{(t)}x_i) \\\\  w_1^{(t+1)} = w_1^{(t)} + \\eta (y_i - w_0^{(t)} - w_1^{(t)}x_i)x_i \\end{array}$$\n\nAvec cette approche, rien ne garantit que nous irons dans la meilleure direction possible à chaque itération. Par conséquent, nous pouvons avoir besoin de beaucoup plus d'itérations, mais nous obtenons des mises à jour de poids beaucoup plus rapides."
  },
  {
   "metadata": {
    "lang": "fr"
   },
   "cell_type": "markdown",
   "source": "Andrew Ng a fait une bonne illustration dans son [cours d'apprentissage automatique](https://www.coursera.org/learn/machine-learning). Jetons un coup d'oeil.\n\n<img src='https://habrastorage.org/files/f8d/90c/f83/f8d90cf83b044255bb07df3373f25fc7.png'>\n\nCe sont les tracés de contour pour une fonction, et nous voulons trouver le minimum global de cette fonction. La courbe rouge montre les changements de poids (dans cette image, $\\theta_0$ et $\\theta_1$ correspondent à nos $w_0$ et $w_1$). Selon les propriétés d'un gradient, la direction du changement en chaque point est orthogonale aux courbes de niveau. Avec la descente de gradient stochastique, les poids changent de manière moins prévisible, et il peut même sembler que certaines étapes sont fausses en s'éloignant des minima; cependant, les deux procédures convergent vers la même solution."
  },
  {
   "metadata": {
    "lang": "fr"
   },
   "cell_type": "markdown",
   "source": "### 1.2. Approche d'apprentissage en ligne\nLa descente de gradient stochastique nous donne des conseils pratiques pour la formation des classificateurs et des régresseurs avec de grandes quantités de données jusqu'à des centaines de Go (en fonction des ressources de calcul).\n\nEn considérant le cas de la régression par paires, nous pouvons stocker l'ensemble de données d'apprentissage $(X,y)$ dans le disque dur sans le charger dans la RAM (où il ne rentre tout simplement pas), lire les objets un par un et mettre à jour les poids de notre modèle:\n\n$$\\begin{array}{rcl} w_0^{(t+1)} = w_0^{(t)} + \\eta (y_i - w_0^{(t)} - w_1^{(t)}x_i) \\\\  w_1^{(t+1)} = w_1^{(t)} + \\eta (y_i - w_0^{(t)} - w_1^{(t)}x_i)x_i \\end{array}$$\n\nAprès avoir travaillé sur la totalité de l'ensemble de données d'entraînement, notre fonction de perte (par exemple, l'erreur quadratique de racine carrée dans la régression ou la perte logistique dans la classification) diminuera, mais il faut généralement des dizaines de passes sur l'ensemble d'entraînement pour rendre la perte suffisamment petite.\n\nCette approche de l'apprentissage s'appelle **apprentissage en ligne**, et ce nom est apparu avant même que les MOOC d'apprentissage automatique ne deviennent courants.\n\nNous n'avons pas discuté ici de nombreux détails sur SGD. Si vous voulez plonger dans la théorie, je vous recommande vivement [\"Convex Optimization\" de Stephen Boyd](https://www.amazon.com/Convex-Optimization-Stephen-Boyd/dp/0521833787). Maintenant, nous allons présenter la bibliothèque Vowpal Wabbit, qui est idéale pour entraîner des modèles simples avec d'énormes ensembles de données grâce à l'optimisation stochastique et à une autre astuce, le hachage de caractéristiques."
  },
  {
   "metadata": {
    "lang": "fr"
   },
   "cell_type": "markdown",
   "source": "Dans scikit-learn, les classificateurs et les régresseurs formés avec SGD sont nommés `SGDClassifier` et` SGDRegressor` dans `sklearn.linear_model`. Ce sont de belles implémentations de SGD, mais nous allons nous concentrer sur VW car il est plus performant que les modèles SGD de sklearn à bien des égards."
  },
  {
   "metadata": {
    "lang": "fr"
   },
   "cell_type": "markdown",
   "source": "## 2. Traitement des caractéristiques catégorielles\n\n### 2.1. Encodage d'étiquettes\nDe nombreux algorithmes de classification et de régression fonctionnent dans l'espace euclidien ou métrique, ce qui implique que les données sont représentées par des vecteurs de nombres réels. Cependant, dans les données réelles, nous avons souvent des caractéristiques catégoriques avec des valeurs discrètes telles que oui / non ou janvier / février /.../ décembre. Nous verrons comment traiter ce type de données, notamment avec des modèles linéaires, et comment traiter de nombreuses caractéristiques catégorielles même lorsqu'elles ont de nombreuses valeurs uniques."
  },
  {
   "metadata": {
    "lang": "fr"
   },
   "cell_type": "markdown",
   "source": "Explorons [l'ensemble de données marketing de la banque UCI](https://archive.ics.uci.edu/ml/datasets/bank+marketing) où la plupart des caractéristiques sont catégoriques."
  },
  {
   "metadata": {
    "_cell_guid": "be6b51fd-ad36-4265-9086-fde116c6d5e4",
    "_uuid": "c8f015ed0ce62cdfc232529b9db5e17f1ebf55f5",
    "trusted": false
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(os.path.join(PATH_TO_ALL_DATA, \"bank_train.csv\"))\n",
    "labels = pd.read_csv(\n",
    "    os.path.join(PATH_TO_ALL_DATA, \"bank_train_target.csv\"), header=None\n",
    ")\n",
    "\n",
    "df.head()"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>job</th>\n      <th>marital</th>\n      <th>education</th>\n      <th>default</th>\n      <th>housing</th>\n      <th>loan</th>\n      <th>contact</th>\n      <th>month</th>\n      <th>day_of_week</th>\n      <th>duration</th>\n      <th>campaign</th>\n      <th>pdays</th>\n      <th>previous</th>\n      <th>poutcome</th>\n      <th>emp.var.rate</th>\n      <th>cons.price.idx</th>\n      <th>cons.conf.idx</th>\n      <th>euribor3m</th>\n      <th>nr.employed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>26</td>\n      <td>student</td>\n      <td>single</td>\n      <td>high.school</td>\n      <td>no</td>\n      <td>no</td>\n      <td>no</td>\n      <td>telephone</td>\n      <td>jun</td>\n      <td>mon</td>\n      <td>901</td>\n      <td>1</td>\n      <td>999</td>\n      <td>0</td>\n      <td>nonexistent</td>\n      <td>1.4</td>\n      <td>94.465</td>\n      <td>-41.8</td>\n      <td>4.961</td>\n      <td>5228.1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>46</td>\n      <td>admin.</td>\n      <td>married</td>\n      <td>university.degree</td>\n      <td>no</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>cellular</td>\n      <td>aug</td>\n      <td>tue</td>\n      <td>208</td>\n      <td>2</td>\n      <td>999</td>\n      <td>0</td>\n      <td>nonexistent</td>\n      <td>1.4</td>\n      <td>93.444</td>\n      <td>-36.1</td>\n      <td>4.963</td>\n      <td>5228.1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>49</td>\n      <td>blue-collar</td>\n      <td>married</td>\n      <td>basic.4y</td>\n      <td>unknown</td>\n      <td>yes</td>\n      <td>yes</td>\n      <td>telephone</td>\n      <td>jun</td>\n      <td>tue</td>\n      <td>131</td>\n      <td>5</td>\n      <td>999</td>\n      <td>0</td>\n      <td>nonexistent</td>\n      <td>1.4</td>\n      <td>94.465</td>\n      <td>-41.8</td>\n      <td>4.864</td>\n      <td>5228.1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>31</td>\n      <td>technician</td>\n      <td>married</td>\n      <td>university.degree</td>\n      <td>no</td>\n      <td>no</td>\n      <td>no</td>\n      <td>cellular</td>\n      <td>jul</td>\n      <td>tue</td>\n      <td>404</td>\n      <td>1</td>\n      <td>999</td>\n      <td>0</td>\n      <td>nonexistent</td>\n      <td>-2.9</td>\n      <td>92.469</td>\n      <td>-33.6</td>\n      <td>1.044</td>\n      <td>5076.2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>42</td>\n      <td>housemaid</td>\n      <td>married</td>\n      <td>university.degree</td>\n      <td>no</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>telephone</td>\n      <td>nov</td>\n      <td>mon</td>\n      <td>85</td>\n      <td>1</td>\n      <td>999</td>\n      <td>0</td>\n      <td>nonexistent</td>\n      <td>-0.1</td>\n      <td>93.200</td>\n      <td>-42.0</td>\n      <td>4.191</td>\n      <td>5195.8</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "   age          job  marital          education  default housing loan  \\\n0   26      student   single        high.school       no      no   no   \n1   46       admin.  married  university.degree       no     yes   no   \n2   49  blue-collar  married           basic.4y  unknown     yes  yes   \n3   31   technician  married  university.degree       no      no   no   \n4   42    housemaid  married  university.degree       no     yes   no   \n\n     contact month day_of_week  duration  campaign  pdays  previous  \\\n0  telephone   jun         mon       901         1    999         0   \n1   cellular   aug         tue       208         2    999         0   \n2  telephone   jun         tue       131         5    999         0   \n3   cellular   jul         tue       404         1    999         0   \n4  telephone   nov         mon        85         1    999         0   \n\n      poutcome  emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  \\\n0  nonexistent           1.4          94.465          -41.8      4.961   \n1  nonexistent           1.4          93.444          -36.1      4.963   \n2  nonexistent           1.4          94.465          -41.8      4.864   \n3  nonexistent          -2.9          92.469          -33.6      1.044   \n4  nonexistent          -0.1          93.200          -42.0      4.191   \n\n   nr.employed  \n0       5228.1  \n1       5228.1  \n2       5228.1  \n3       5076.2  \n4       5195.8  "
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "metadata": {
    "lang": "fr"
   },
   "cell_type": "markdown",
   "source": "Nous pouvons voir que la plupart des caractéristiques ne sont pas représentées par des nombres. Cela pose un problème car nous ne pouvons pas utiliser la plupart des méthodes d'apprentissage automatique (du moins celles implémentées dans scikit-learn) prêtes à l'emploi.\n\nIntéressons nous à la caractéristique «éducation»."
  },
  {
   "metadata": {
    "_cell_guid": "d5cb0f31-1e52-49a0-9bdb-ae3207541710",
    "_uuid": "136b05d444ff42d4e8521e51066bf9cd22c023fa",
    "trusted": false
   },
   "cell_type": "code",
   "source": [
    "df[\"education\"].value_counts().plot.barh();"
   ],
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": "<Figure size 432x288 with 1 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ]
  },
  {
   "metadata": {
    "lang": "fr"
   },
   "cell_type": "markdown",
   "source": "La solution la plus simple consiste à mapper chaque valeur de cette fonction en un numéro unique. Par exemple, nous pouvons mapper `university.degree` à 0,` basic.9y` à 1, et ainsi de suite. Vous pouvez utiliser `sklearn.preprocessing.LabelEncoder` pour effectuer ce mappage."
  },
  {
   "metadata": {
    "_cell_guid": "fb569cfb-711b-428d-9a29-5393dff4b348",
    "_uuid": "05c9087139ca3fcdf3b715b9b30f566bdaf0ad1c",
    "trusted": false
   },
   "cell_type": "code",
   "source": [
    "label_encoder = LabelEncoder()"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {
    "lang": "fr"
   },
   "cell_type": "markdown",
   "source": "La méthode `fit` de cette classe trouve toutes les valeurs uniques et construit le mappage réel entre les catégories et les nombres, et la méthode` transform` convertit les catégories en nombres. Après l'exécution de `fit`,` label _encoder` aura l'attribut `classes_` avec toutes les valeurs uniques de l'entité. Comptons-les pour nous assurer que la transformation était correcte."
  },
  {
   "metadata": {
    "_cell_guid": "c692cf31-3233-4b92-8bb9-de7d7be15315",
    "_uuid": "efe26525483e1c3ba137e8f1c55f92c76ab4c799",
    "trusted": false
   },
   "cell_type": "code",
   "source": [
    "mapped_education = pd.Series(label_encoder.fit_transform(df[\"education\"]))\n",
    "mapped_education.value_counts().plot.barh()\n",
    "print(dict(enumerate(label_encoder.classes_)))"
   ],
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "{0: 'basic.4y', 1: 'basic.6y', 2: 'basic.9y', 3: 'high.school', 4: 'illiterate', 5: 'professional.course', 6: 'university.degree', 7: 'unknown'}\n"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": "<Figure size 432x288 with 1 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ]
  },
  {
   "metadata": {
    "_cell_guid": "4658ebf0-6610-4c6f-88d0-3b1027a5c212",
    "_uuid": "68fba174918a7c498100b8bb2c4f9822a4c9a659",
    "trusted": false
   },
   "cell_type": "code",
   "source": [
    "df[\"education\"] = mapped_education\n",
    "df.head()"
   ],
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>job</th>\n      <th>marital</th>\n      <th>education</th>\n      <th>default</th>\n      <th>housing</th>\n      <th>loan</th>\n      <th>contact</th>\n      <th>month</th>\n      <th>day_of_week</th>\n      <th>duration</th>\n      <th>campaign</th>\n      <th>pdays</th>\n      <th>previous</th>\n      <th>poutcome</th>\n      <th>emp.var.rate</th>\n      <th>cons.price.idx</th>\n      <th>cons.conf.idx</th>\n      <th>euribor3m</th>\n      <th>nr.employed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>26</td>\n      <td>student</td>\n      <td>single</td>\n      <td>3</td>\n      <td>no</td>\n      <td>no</td>\n      <td>no</td>\n      <td>telephone</td>\n      <td>jun</td>\n      <td>mon</td>\n      <td>901</td>\n      <td>1</td>\n      <td>999</td>\n      <td>0</td>\n      <td>nonexistent</td>\n      <td>1.4</td>\n      <td>94.465</td>\n      <td>-41.8</td>\n      <td>4.961</td>\n      <td>5228.1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>46</td>\n      <td>admin.</td>\n      <td>married</td>\n      <td>6</td>\n      <td>no</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>cellular</td>\n      <td>aug</td>\n      <td>tue</td>\n      <td>208</td>\n      <td>2</td>\n      <td>999</td>\n      <td>0</td>\n      <td>nonexistent</td>\n      <td>1.4</td>\n      <td>93.444</td>\n      <td>-36.1</td>\n      <td>4.963</td>\n      <td>5228.1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>49</td>\n      <td>blue-collar</td>\n      <td>married</td>\n      <td>0</td>\n      <td>unknown</td>\n      <td>yes</td>\n      <td>yes</td>\n      <td>telephone</td>\n      <td>jun</td>\n      <td>tue</td>\n      <td>131</td>\n      <td>5</td>\n      <td>999</td>\n      <td>0</td>\n      <td>nonexistent</td>\n      <td>1.4</td>\n      <td>94.465</td>\n      <td>-41.8</td>\n      <td>4.864</td>\n      <td>5228.1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>31</td>\n      <td>technician</td>\n      <td>married</td>\n      <td>6</td>\n      <td>no</td>\n      <td>no</td>\n      <td>no</td>\n      <td>cellular</td>\n      <td>jul</td>\n      <td>tue</td>\n      <td>404</td>\n      <td>1</td>\n      <td>999</td>\n      <td>0</td>\n      <td>nonexistent</td>\n      <td>-2.9</td>\n      <td>92.469</td>\n      <td>-33.6</td>\n      <td>1.044</td>\n      <td>5076.2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>42</td>\n      <td>housemaid</td>\n      <td>married</td>\n      <td>6</td>\n      <td>no</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>telephone</td>\n      <td>nov</td>\n      <td>mon</td>\n      <td>85</td>\n      <td>1</td>\n      <td>999</td>\n      <td>0</td>\n      <td>nonexistent</td>\n      <td>-0.1</td>\n      <td>93.200</td>\n      <td>-42.0</td>\n      <td>4.191</td>\n      <td>5195.8</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "   age          job  marital  education  default housing loan    contact  \\\n0   26      student   single          3       no      no   no  telephone   \n1   46       admin.  married          6       no     yes   no   cellular   \n2   49  blue-collar  married          0  unknown     yes  yes  telephone   \n3   31   technician  married          6       no      no   no   cellular   \n4   42    housemaid  married          6       no     yes   no  telephone   \n\n  month day_of_week  duration  campaign  pdays  previous     poutcome  \\\n0   jun         mon       901         1    999         0  nonexistent   \n1   aug         tue       208         2    999         0  nonexistent   \n2   jun         tue       131         5    999         0  nonexistent   \n3   jul         tue       404         1    999         0  nonexistent   \n4   nov         mon        85         1    999         0  nonexistent   \n\n   emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  nr.employed  \n0           1.4          94.465          -41.8      4.961       5228.1  \n1           1.4          93.444          -36.1      4.963       5228.1  \n2           1.4          94.465          -41.8      4.864       5228.1  \n3          -2.9          92.469          -33.6      1.044       5076.2  \n4          -0.1          93.200          -42.0      4.191       5195.8  "
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "metadata": {
    "lang": "fr"
   },
   "cell_type": "markdown",
   "source": "Appliquons la transformation à d'autres colonnes de type `objet`."
  },
  {
   "metadata": {
    "_cell_guid": "f6b6056e-3823-4caf-a617-d99ab490512d",
    "_uuid": "8079ecf58d4fa138d92c21f46b001cb3ed050a0a",
    "trusted": false
   },
   "cell_type": "code",
   "source": [
    "categorical_columns = df.columns[df.dtypes == \"object\"].union([\"education\"])\n",
    "for column in categorical_columns:\n",
    "    df[column] = label_encoder.fit_transform(df[column])\n",
    "df.head()"
   ],
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>job</th>\n      <th>marital</th>\n      <th>education</th>\n      <th>default</th>\n      <th>housing</th>\n      <th>loan</th>\n      <th>contact</th>\n      <th>month</th>\n      <th>day_of_week</th>\n      <th>duration</th>\n      <th>campaign</th>\n      <th>pdays</th>\n      <th>previous</th>\n      <th>poutcome</th>\n      <th>emp.var.rate</th>\n      <th>cons.price.idx</th>\n      <th>cons.conf.idx</th>\n      <th>euribor3m</th>\n      <th>nr.employed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>26</td>\n      <td>8</td>\n      <td>2</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>4</td>\n      <td>1</td>\n      <td>901</td>\n      <td>1</td>\n      <td>999</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1.4</td>\n      <td>94.465</td>\n      <td>-41.8</td>\n      <td>4.961</td>\n      <td>5228.1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>46</td>\n      <td>0</td>\n      <td>1</td>\n      <td>6</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>208</td>\n      <td>2</td>\n      <td>999</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1.4</td>\n      <td>93.444</td>\n      <td>-36.1</td>\n      <td>4.963</td>\n      <td>5228.1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>49</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>4</td>\n      <td>3</td>\n      <td>131</td>\n      <td>5</td>\n      <td>999</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1.4</td>\n      <td>94.465</td>\n      <td>-41.8</td>\n      <td>4.864</td>\n      <td>5228.1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>31</td>\n      <td>9</td>\n      <td>1</td>\n      <td>6</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>3</td>\n      <td>404</td>\n      <td>1</td>\n      <td>999</td>\n      <td>0</td>\n      <td>1</td>\n      <td>-2.9</td>\n      <td>92.469</td>\n      <td>-33.6</td>\n      <td>1.044</td>\n      <td>5076.2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>42</td>\n      <td>3</td>\n      <td>1</td>\n      <td>6</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>7</td>\n      <td>1</td>\n      <td>85</td>\n      <td>1</td>\n      <td>999</td>\n      <td>0</td>\n      <td>1</td>\n      <td>-0.1</td>\n      <td>93.200</td>\n      <td>-42.0</td>\n      <td>4.191</td>\n      <td>5195.8</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "   age  job  marital  education  default  housing  loan  contact  month  \\\n0   26    8        2          3        0        0     0        1      4   \n1   46    0        1          6        0        2     0        0      1   \n2   49    1        1          0        1        2     2        1      4   \n3   31    9        1          6        0        0     0        0      3   \n4   42    3        1          6        0        2     0        1      7   \n\n   day_of_week  duration  campaign  pdays  previous  poutcome  emp.var.rate  \\\n0            1       901         1    999         0         1           1.4   \n1            3       208         2    999         0         1           1.4   \n2            3       131         5    999         0         1           1.4   \n3            3       404         1    999         0         1          -2.9   \n4            1        85         1    999         0         1          -0.1   \n\n   cons.price.idx  cons.conf.idx  euribor3m  nr.employed  \n0          94.465          -41.8      4.961       5228.1  \n1          93.444          -36.1      4.963       5228.1  \n2          94.465          -41.8      4.864       5228.1  \n3          92.469          -33.6      1.044       5076.2  \n4          93.200          -42.0      4.191       5195.8  "
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "metadata": {
    "lang": "fr"
   },
   "cell_type": "markdown",
   "source": "Le principal problème avec cette approche est que nous avons maintenant introduit un ordre relatif là où il pourrait ne pas exister.\n\nPar exemple, nous avons implicitement introduit l'algèbre sur les valeurs de la caractéristique **job** où nous pouvons maintenant soustraire le job du client #2 du job du client# 1:"
  },
  {
   "metadata": {
    "_cell_guid": "9e85d727-a23c-4fda-859e-9cfa2491b044",
    "_uuid": "10efbea02831df6e1e8476a8813aedd227f9d4ae",
    "trusted": false
   },
   "cell_type": "code",
   "source": [
    "df.loc[1].job - df.loc[2].job"
   ],
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "-1.0"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "metadata": {
    "lang": "fr"
   },
   "cell_type": "markdown",
   "source": "Cette opération a-t-elle un sens? Pas vraiment. Essayons de former la régression logisitique avec cette transformation de caractéristique."
  },
  {
   "metadata": {
    "_cell_guid": "7dede4d6-e787-4232-a1ac-01191a88ec88",
    "_uuid": "15c8fdb284d4e5166f3f56c4e9d8f1810186ff7c",
    "trusted": false
   },
   "cell_type": "code",
   "source": [
    "def logistic_regression_accuracy_on(dataframe, labels):\n",
    "    features = dataframe.as_matrix()\n",
    "    train_features, test_features, train_labels, test_labels = train_test_split(\n",
    "        features, labels\n",
    "    )\n",
    "\n",
    "    logit = LogisticRegression()\n",
    "    logit.fit(train_features, train_labels)\n",
    "    return classification_report(test_labels, logit.predict(test_features))\n",
    "\n",
    "\n",
    "print(logistic_regression_accuracy_on(df[categorical_columns], labels))"
   ],
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "              precision    recall  f1-score   support\n\n           0       0.89      1.00      0.94      6133\n           1       0.00      0.00      0.00       766\n\n   micro avg       0.89      0.89      0.89      6899\n   macro avg       0.44      0.50      0.47      6899\nweighted avg       0.79      0.89      0.84      6899\n\n"
    }
   ]
  },
  {
   "metadata": {
    "lang": "fr"
   },
   "cell_type": "markdown",
   "source": "Nous pouvons voir que la régression logistique ne prédit jamais la classe 1. Afin d'utiliser des modèles linéaires avec des caractéristiques catégoriques, nous utiliserons une approche différente: One-Hot Encoding.\n\n### 2.2. Encodage One-Hot\n\nSupposons qu'une caractéristique puisse avoir l'une des 10 valeurs uniques. L'encodage One-Hot crée 10 nouvelles caractéristiques correspondant à ces valeurs uniques, toutes *sauf un* sont des zéros."
  },
  {
   "metadata": {
    "_cell_guid": "df17447f-6ff8-4342-b755-c856fb1c7bd6",
    "_uuid": "6ca824f36f66c8e6889688e8f64c2ca6ec7605df",
    "trusted": false
   },
   "cell_type": "code",
   "source": [
    "one_hot_example = pd.DataFrame([{i: 0 for i in range(10)}])\n",
    "one_hot_example.loc[0, 6] = 1\n",
    "one_hot_example"
   ],
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "   0  1  2  3  4  5  6  7  8  9\n0  0  0  0  0  0  0  1  0  0  0"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "metadata": {
    "lang": "fr"
   },
   "cell_type": "markdown",
   "source": "Cette idée est implémentée dans la classe `OneHotEncoder` de` sklearn.preprocessing`. Par défaut, OneHotEncoder transforme les données en une matrice creuse (sparse matrix) pour économiser de l'espace mémoire car la plupart des valeurs sont des zéros et parce que nous ne voulons pas utiliser plus de RAM. Cependant, dans cet exemple particulier, nous ne rencontrons pas de tels problèmes, nous allons donc utiliser une représentation matricielle \"dense\"."
  },
  {
   "metadata": {
    "_cell_guid": "29d1f40e-cfb4-4ee0-b9ee-8c779b7c803b",
    "_uuid": "fa7ad1f51154182f467a5df5dd7d43ec111132b8",
    "trusted": false
   },
   "cell_type": "code",
   "source": [
    "onehot_encoder = OneHotEncoder(sparse=False)"
   ],
   "execution_count": 14,
   "outputs": []
  },
  {
   "metadata": {
    "_cell_guid": "0d70a254-f732-40c9-b738-67ca6b8d2d24",
    "_uuid": "ecfb22058b460d751779df0f9492928a317914de",
    "trusted": false
   },
   "cell_type": "code",
   "source": [
    "encoded_categorical_columns = pd.DataFrame(\n",
    "    onehot_encoder.fit_transform(df[categorical_columns])\n",
    ")\n",
    "encoded_categorical_columns.head()"
   ],
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>43</th>\n      <th>44</th>\n      <th>45</th>\n      <th>46</th>\n      <th>47</th>\n      <th>48</th>\n      <th>49</th>\n      <th>50</th>\n      <th>51</th>\n      <th>52</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 53 columns</p>\n</div>",
      "text/plain": "    0    1    2    3    4    5    6    7    8    9  ...    43   44   45   46  \\\n0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  1.0  0.0  0.0   \n1  1.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n2  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0  0.0   \n3  1.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0 ...   1.0  0.0  0.0  0.0   \n4  0.0  1.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n\n    47   48   49   50   51   52  \n0  0.0  0.0  0.0  0.0  1.0  0.0  \n1  0.0  0.0  0.0  0.0  1.0  0.0  \n2  0.0  0.0  0.0  0.0  1.0  0.0  \n3  0.0  0.0  0.0  0.0  1.0  0.0  \n4  1.0  0.0  0.0  0.0  1.0  0.0  \n\n[5 rows x 53 columns]"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "metadata": {
    "lang": "fr"
   },
   "cell_type": "markdown",
   "source": "Nous avons 53 colonnes qui correspondent au nombre de valeurs uniques des caractéristiques catégorielles dans notre ensemble de données. Lorsqu'elles sont transformées avec l'encodage One-Hot, ces données peuvent être utilisées avec des modèles linéaires:"
  },
  {
   "metadata": {
    "_cell_guid": "84c611df-8c2e-45dc-a108-aab6bf39a530",
    "_uuid": "cebd716350bc29dabb07f797db16e693fa92a76a",
    "trusted": false
   },
   "cell_type": "code",
   "source": [
    "print(logistic_regression_accuracy_on(encoded_categorical_columns, labels))"
   ],
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "              precision    recall  f1-score   support\n\n           0       0.91      0.99      0.95      6140\n           1       0.64      0.16      0.26       759\n\n   micro avg       0.90      0.90      0.90      6899\n   macro avg       0.77      0.57      0.60      6899\nweighted avg       0.88      0.90      0.87      6899\n\n"
    }
   ]
  },
  {
   "metadata": {
    "lang": "fr"
   },
   "cell_type": "markdown",
   "source": "### 2.3. Astuce de hachage\nLes données réelles peuvent être volatiles, ce qui signifie que nous ne pouvons pas garantir que de nouvelles valeurs de caractéristiques catégorielles ne se produiront pas. Ce problème empêche l'utilisation d'un modèle entraîné sur de nouvelles données. En outre, «LabelEncoder» nécessite une analyse préliminaire de l'ensemble de données et le stockage des mappages construits en mémoire, ce qui rend difficile le travail avec de grands ensembles de données.\n\nIl existe une approche simple de la vectorisation des données catégorielles basée sur le hachage et est connue sous le nom, sans surprise, de l'astuce de hachage.\n\nLes fonctions de hachage peuvent nous aider à trouver des codes uniques pour différentes valeurs de caractéristiques, par exemple:"
  },
  {
   "metadata": {
    "_cell_guid": "d9eb2e54-18e7-4056-8f28-f22a044596d8",
    "_uuid": "01064911e1e0af0b3829b0e0be2a965aa3e8eb3e",
    "trusted": false
   },
   "cell_type": "code",
   "source": [
    "for s in (\"university.degree\", \"high.school\", \"illiterate\"):\n",
    "    print(s, \"->\", hash(s))"
   ],
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "university.degree -> -4819547379497397962\nhigh.school -> 6407817176082389474\nilliterate -> -426073671251698964\n"
    }
   ]
  },
  {
   "metadata": {
    "lang": "fr"
   },
   "cell_type": "markdown",
   "source": "Nous n'utiliserons pas de valeurs négatives ou de valeurs de grande amplitude, nous limitons donc la plage de valeurs pour la fonction de hachage:"
  },
  {
   "metadata": {
    "_cell_guid": "943fc564-80f0-4350-980a-cce6c6a2e7cd",
    "_uuid": "b92f7eabc498b8339abed0f8fd400bba5750209a",
    "trusted": false
   },
   "cell_type": "code",
   "source": [
    "hash_space = 25\n",
    "for s in (\"university.degree\", \"high.school\", \"illiterate\"):\n",
    "    print(s, \"->\", hash(s) % hash_space)"
   ],
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "university.degree -> 13\nhigh.school -> 24\nilliterate -> 11\n"
    }
   ]
  },
  {
   "metadata": {
    "lang": "fr"
   },
   "cell_type": "markdown",
   "source": "Imaginons que notre ensemble de données contienne un étudiant célibataire (c'est-à-dire non marié), qui a reçu un appel lundi. Ses vecteurs de caractéristiques seront créés de la même manière que dans le cas de l'encodage One-Hot, mais dans l'espace avec une plage fixe pour toutes les caractéristiques:"
  },
  {
   "metadata": {
    "_cell_guid": "c94253b2-3981-4bbd-817f-96c3f660d464",
    "_uuid": "af62a2ed3770a537bc3168d0a06c6d20b737f887",
    "trusted": false
   },
   "cell_type": "code",
   "source": [
    "hashing_example = pd.DataFrame([{i: 0.0 for i in range(hash_space)}])\n",
    "for s in (\"job=student\", \"marital=single\", \"day_of_week=mon\"):\n",
    "    print(s, \"->\", hash(s) % hash_space)\n",
    "    hashing_example.loc[0, hash(s) % hash_space] = 1\n",
    "hashing_example"
   ],
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "job=student -> 9\nmarital=single -> 17\nday_of_week=mon -> 15\n"
    },
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n      <th>18</th>\n      <th>19</th>\n      <th>20</th>\n      <th>21</th>\n      <th>22</th>\n      <th>23</th>\n      <th>24</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows × 25 columns</p>\n</div>",
      "text/plain": "    0    1    2    3    4    5    6    7    8    9  ...    15   16   17   18  \\\n0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0 ...   1.0  0.0  1.0  0.0   \n\n    19   20   21   22   23   24  \n0  0.0  0.0  0.0  0.0  0.0  0.0  \n\n[1 rows x 25 columns]"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "metadata": {
    "lang": "fr"
   },
   "cell_type": "markdown",
   "source": "Nous tenons à souligner que nous hachons non seulement les valeurs de caractéristique, mais également des paires de **nom de caractéristique + valeur de caractéristique**. Il est important de le faire afin que nous puissions distinguer les mêmes valeurs de différentes caractéristiques."
  },
  {
   "metadata": {
    "_cell_guid": "48540748-405a-413d-ac0c-5aa0422b9087",
    "_uuid": "e025f8486b3091090e93c27c082145b5f3e11967",
    "trusted": false
   },
   "cell_type": "code",
   "source": [
    "assert hash(\"no\") == hash(\"no\")\n",
    "assert hash(\"housing=no\") != hash(\"loan=no\")"
   ],
   "execution_count": 20,
   "outputs": []
  },
  {
   "metadata": {
    "lang": "fr"
   },
   "cell_type": "markdown",
   "source": "Est-il possible d'avoir une collision lors de l'utilisation de codes de hachage? Bien sûr, c'est possible, mais c'est un cas rare avec des espaces de hachage suffisamment grands. Même en cas de collision, les métriques de régression ou de classification n'en souffriront pas beaucoup. Dans ce cas, les collisions de hachage fonctionnent comme une forme de régularisation.\n\n\n<img src=\"https://habrastorage.org/webt/4o/wx/59/4owx59vdvwc9mzrf81t2fa2rqrc.jpeg\">\n\nVous dites peut-être \"WTF?\"; le hachage semble contre-intuitif. C'est vrai, mais ces heuristiques sont parfois, en fait, la seule approche plausible pour travailler avec des données catégorielles (que pouvez-vous faire d'autre si vous avez 30 millions de caractéristiques?). De plus, cette technique s'est avérée efficace. Au fur et à mesure que vous travaillez avec des données, vous pouvez le constater par vous-même.\n\nUne bonne analyse des collisions de hachage, de leur dépendance à l'espace des caractéristiques et des dimensions de l'espace de hachage et affectant les performances de classification / régression est effectuée dans [cet article](https://booking.ai/dont-be-tricked-by-the-hashing- trick-192a6aae3087) par Booking.com."
  },
  {
   "metadata": {
    "lang": "fr"
   },
   "cell_type": "markdown",
   "source": "## 3. Vowpal Wabbit"
  },
  {
   "metadata": {
    "lang": "fr"
   },
   "cell_type": "markdown",
   "source": "[Vowpal Wabbit](https://github.com/JohnLangford/vowpal_wabbit)(VW) est l'une des bibliothèques d'apprentissage automatique les plus répandues dans l'industrie. Il se distingue par sa vitesse d'entraînement et sa prise en charge de nombreux modes d'entraînement, en particulier pour l'apprentissage en ligne avec des données volumineuses et de haute dimension. C'est l'un des principaux mérites de la bibliothèque. De plus, avec l'astuce de hachage implémentée, Vowpal Wabbit est un choix parfait pour travailler avec des données textuelles.\n\nShell est l'interface principale de VW."
  },
  {
   "metadata": {
    "_cell_guid": "24fd028f-416e-43ff-9530-5c8f47bde176",
    "_uuid": "4cc17ec6551c7e7dcf224a3b03794720d90cb966",
    "trusted": false
   },
   "cell_type": "code",
   "source": [
    "!vw --help"
   ],
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Num weight bits = 18\r\nlearning rate = 0.5\r\ninitial_t = 0\r\npower_t = 0.5\r\nusing no cache\r\nReading datafile = \r\nnum sources = 1\r\n\r\nVW options:\r\n  --ring_size arg                       size of example ring\r\n  --onethread                           Disable parse thread\r\n\r\nUpdate options:\r\n  -l [ --learning_rate ] arg            Set learning rate\r\n  --power_t arg                         t power value\r\n  --decay_learning_rate arg             Set Decay factor for learning_rate \r\n                                        between passes\r\n  --initial_t arg                       initial t value\r\n  --feature_mask arg                    Use existing regressor to determine \r\n                                        which parameters may be updated.  If no\r\n                                        initial_regressor given, also used for \r\n                                        initial weights.\r\n\r\nWeight options:\r\n  -i [ --initial_regressor ] arg        Initial regressor(s)\r\n  --initial_weight arg                  Set all weights to an initial value of \r\n                                        arg.\r\n  --random_weights arg                  make initial weights random\r\n  --normal_weights arg                  make initial weights normal\r\n  --truncated_normal_weights arg        make initial weights truncated normal\r\n  --sparse_weights                      Use a sparse datastructure for weights\r\n  --input_feature_regularizer arg       Per feature regularization input file\r\n\r\nParallelization options:\r\n  --span_server arg                     Location of server for setting up \r\n                                        spanning tree\r\n  --threads                             Enable multi-threading\r\n  --unique_id arg (=0)                  unique id used for cluster parallel \r\n                                        jobs\r\n  --total arg (=1)                      total number of nodes used in cluster \r\n                                        parallel job\r\n  --node arg (=0)                       node number in cluster parallel job\r\n\r\nDiagnostic options:\r\n  --version                             Version information\r\n  -a [ --audit ]                        print weights of features\r\n  -P [ --progress ] arg                 Progress update frequency. int: \r\n                                        additive, float: multiplicative\r\n  --quiet                               Don't output disgnostics and progress \r\n                                        updates\r\n  -h [ --help ]                         Look here: http://hunch.net/~vw/ and \r\n                                        click on Tutorial.\r\n\r\nRandom Seed option:\r\n  --random_seed arg                     seed random number generator\r\n\r\nFeature options:\r\n  --hash arg                            how to hash the features. Available \r\n                                        options: strings, all\r\n  --hash_seed arg (=0)                  seed for hash function\r\n  --ignore arg                          ignore namespaces beginning with \r\n                                        character <arg>\r\n  --ignore_linear arg                   ignore namespaces beginning with \r\n                                        character <arg> for linear terms only\r\n  --keep arg                            keep namespaces beginning with \r\n                                        character <arg>\r\n  --redefine arg                        redefine namespaces beginning with \r\n                                        characters of string S as namespace N. \r\n                                        <arg> shall be in form 'N:=S' where := \r\n                                        is operator. Empty N or S are treated \r\n                                        as default namespace. Use ':' as a \r\n                                        wildcard in S.\r\n  -b [ --bit_precision ] arg            number of bits in the feature table\r\n  --noconstant                          Don't add a constant feature\r\n  -C [ --constant ] arg                 Set initial value of constant\r\n  --ngram arg                           Generate N grams. To generate N grams \r\n                                        for a single namespace 'foo', arg \r\n                                        should be fN.\r\n  --skips arg                           Generate skips in N grams. This in \r\n                                        conjunction with the ngram tag can be \r\n                                        used to generate generalized \r\n                                        n-skip-k-gram. To generate n-skips for \r\n                                        a single namespace 'foo', arg should be\r\n                                        fN.\r\n  --feature_limit arg                   limit to N features. To apply to a \r\n                                        single namespace 'foo', arg should be \r\n                                        fN\r\n  --affix arg                           generate prefixes/suffixes of features;\r\n                                        argument '+2a,-3b,+1' means generate \r\n                                        2-char prefixes for namespace a, 3-char\r\n                                        suffixes for b and 1 char prefixes for \r\n                                        default namespace\r\n  --spelling arg                        compute spelling features for a give \r\n                                        namespace (use '_' for default \r\n                                        namespace)\r\n  --dictionary arg                      read a dictionary for additional \r\n                                        features (arg either 'x:file' or just \r\n                                        'file')\r\n  --dictionary_path arg                 look in this directory for \r\n                                        dictionaries; defaults to current \r\n                                        directory or env{PATH}\r\n  --interactions arg                    Create feature interactions of any \r\n                                        level between namespaces.\r\n  --permutations                        Use permutations instead of \r\n                                        combinations for feature interactions \r\n                                        of same namespace.\r\n  --leave_duplicate_interactions        Don't remove interactions with \r\n                                        duplicate combinations of namespaces. \r\n                                        For ex. this is a duplicate: '-q ab -q \r\n                                        ba' and a lot more in '-q ::'.\r\n  -q [ --quadratic ] arg                Create and use quadratic features\r\n  --q: arg                              : corresponds to a wildcard for all \r\n                                        printable characters\r\n  --cubic arg                           Create and use cubic features\r\n\r\nExample options:\r\n  -t [ --testonly ]                     Ignore label information and just test\r\n  --holdout_off                         no holdout data in multiple passes\r\n  --holdout_period arg (=10)            holdout period for test only\r\n  --holdout_after arg                   holdout after n training examples, \r\n                                        default off (disables holdout_period)\r\n  --early_terminate arg (=3)            Specify the number of passes tolerated \r\n                                        when holdout loss doesn't decrease \r\n                                        before early termination\r\n  --passes arg                          Number of Training Passes\r\n  --initial_pass_length arg             initial number of examples per pass\r\n  --examples arg                        number of examples to parse\r\n  --min_prediction arg                  Smallest prediction to output\r\n  --max_prediction arg                  Largest prediction to output\r\n  --sort_features                       turn this on to disregard order in \r\n                                        which features have been defined. This \r\n                                        will lead to smaller cache sizes\r\n  --loss_function arg (=squared)        Specify the loss function to be used, \r\n                                        uses squared by default. Currently \r\n                                        available ones are squared, classic, \r\n                                        hinge, logistic, quantile and poisson.\r\n  --quantile_tau arg (=0.5)             Parameter \\tau associated with Quantile\r\n                                        loss. Defaults to 0.5\r\n  --l1 arg                              l_1 lambda\r\n  --l2 arg                              l_2 lambda\r\n  --no_bias_regularization arg          no bias in regularization\r\n  --named_labels arg                    use names for labels (multiclass, etc.)\r\n                                        rather than integers, argument \r\n                                        specified all possible labels, \r\n                                        comma-sep, eg \"--named_labels \r\n                                        Noun,Verb,Adj,Punc\"\r\n\r\nOutput model:\r\n  -f [ --final_regressor ] arg          Final regressor\r\n  --readable_model arg                  Output human-readable final regressor \r\n                                        with numeric features\r\n  --invert_hash arg                     Output human-readable final regressor \r\n                                        with feature names.  Computationally \r\n                                        expensive.\r\n  --save_resume                         save extra state so learning can be \r\n                                        resumed later with new data\r\n  --preserve_performance_counters       reset performance counters when \r\n                                        warmstarting\r\n  --save_per_pass                       Save the model after every pass over \r\n                                        data\r\n  --output_feature_regularizer_binary arg\r\n                                        Per feature regularization output file\r\n  --output_feature_regularizer_text arg Per feature regularization output file,\r\n                                        in text\r\n  --id arg                              User supplied ID embedded into the \r\n                                        final regressor\r\n\r\nOutput options:\r\n  -p [ --predictions ] arg              File to output predictions to\r\n  -r [ --raw_predictions ] arg          File to output unnormalized predictions\r\n                                        to\r\n\r\nAudit Regressor:\r\n  --audit_regressor arg                 stores feature names and their \r\n                                        regressor values. Same dataset must be \r\n                                        used for both regressor training and \r\n                                        this mode.\r\n\r\n\r\nSearch options:\r\n  --search arg                          Use learning to search, \r\n                                        argument=maximum action id or 0 for LDF\r\n  --search_task arg                     the search task (use \"--search_task \r\n                                        list\" to get a list of available tasks)\r\n\r\n  --search_metatask arg                 the search metatask (use \r\n                                        \"--search_metatask list\" to get a list \r\n                                        of available metatasks)\r\n  --search_interpolation arg            at what level should interpolation \r\n                                        happen? [*data|policy]\r\n  --search_rollout arg                  how should rollouts be executed?       \r\n                                            [policy|oracle|*mix_per_state|mix_p\r\n                                        er_roll|none]\r\n  --search_rollin arg                   how should past trajectories be \r\n                                        generated? [policy|oracle|*mix_per_stat\r\n                                        e|mix_per_roll]\r\n  --search_passes_per_policy arg (=1)   number of passes per policy (only valid\r\n                                        for search_interpolation=policy)\r\n  --search_beta arg (=0.5)              interpolation rate for policies (only \r\n                                        valid for search_interpolation=policy)\r\n  --search_alpha arg (=1.00000001e-10)  annealed beta = 1-(1-alpha)^t (only \r\n                                        valid for search_interpolation=data)\r\n  --search_total_nb_policies arg        if we are going to train the policies \r\n                                        through multiple separate calls to vw, \r\n                                        we need to specify this parameter and \r\n                                        tell vw how many policies are \r\n                                        eventually going to be trained\r\n  --search_trained_nb_policies arg      the number of trained policies in a \r\n                                        file\r\n  --search_allowed_transitions arg      read file of allowed transitions [def: \r\n                                        all transitions are allowed]\r\n  --search_subsample_time arg           instead of training at all timesteps, \r\n                                        use a subset. if value in (0,1), train \r\n                                        on a random v%. if v>=1, train on \r\n                                        precisely v steps per example, if \r\n                                        v<=-1, use active learning\r\n  --search_neighbor_features arg        copy features from neighboring lines. \r\n                                        argument looks like: '-1:a,+2' meaning \r\n                                        copy previous line namespace a and next\r\n                                        next line from namespace _unnamed_, \r\n                                        where ',' separates them\r\n  --search_rollout_num_steps arg        how many calls of \"loss\" before we stop\r\n                                        really predicting on rollouts and \r\n                                        switch to oracle (default means \r\n                                        \"infinite\")\r\n  --search_history_length arg (=1)      some tasks allow you to specify how \r\n                                        much history their depend on; specify \r\n                                        that here\r\n  --search_no_caching                   turn off the built-in caching ability \r\n                                        (makes things slower, but technically \r\n                                        more safe)\r\n  --search_xv                           train two separate policies, \r\n                                        alternating prediction/learning\r\n  --search_perturb_oracle arg (=0)      perturb the oracle on rollin with this \r\n                                        probability\r\n  --search_linear_ordering              insist on generating examples in linear\r\n                                        order (def: hoopla permutation)\r\n  --search_active_verify arg            verify that active learning is doing \r\n                                        the right thing (arg = multiplier, \r\n                                        should be = cost_range * range_c)\r\n  --search_save_every_k_runs arg        save model every k runs\r\n\r\nExperience Replay:\r\n  --replay_c arg                        use experience replay at a specified \r\n                                        level [b=classification/regression, \r\n                                        m=multiclass, c=cost sensitive] with \r\n                                        specified buffer size\r\n\r\n  --replay_c_count arg (=1)             how many times (in expectation) should \r\n                                        each example be played (default: 1 = \r\n                                        permuting)\r\n\r\nExplore evaluation:\r\n  --explore_eval                        Evaluate explore_eval adf policies\r\n\r\n  --multiplier arg                      Multiplier used to make all rejection \r\n                                        sample probabilities <= 1\r\n\r\nMake Multiclass into Contextual Bandit:\r\n  --cbify arg                           Convert multiclass on <k> classes into \r\n                                        a contextual bandit problem\r\n\r\n  --cbify_cs                            consume cost-sensitive classification \r\n                                        examples instead of multiclass\r\n  --loss0 arg (=0)                      loss for correct label\r\n  --loss1 arg (=1)                      loss for incorrect label\r\n\r\nContextual Bandit Exploration with Action Dependent Features:\r\n  --cb_explore_adf                      Online explore-exploit for a contextual\r\n                                        bandit problem with multiline action \r\n                                        dependent features\r\n\r\n  --first arg                           tau-first exploration\r\n  --epsilon arg                         epsilon-greedy exploration\r\n  --bag arg                             bagging-based exploration\r\n  --cover arg                           Online cover based exploration\r\n  --psi arg (=1)                        disagreement parameter for cover\r\n  --nounif                              do not explore uniformly on \r\n                                        zero-probability actions in cover\r\n  --softmax                             softmax exploration\r\n  --regcb                               RegCB-elim exploration\r\n  --regcbopt                            RegCB optimistic exploration\r\n  --mellowness arg (=0.100000001)       RegCB mellowness parameter c_0. Default\r\n                                        0.1\r\n  --greedify                            always update first policy once in \r\n                                        bagging\r\n  --cb_min_cost arg (=0)                lower bound on cost\r\n  --cb_max_cost arg (=1)                upper bound on cost\r\n  --first_only                          Only explore the first action in a \r\n                                        tie-breaking event\r\n  --lambda arg (=-1)                    parameter for softmax\r\n\r\nContextual Bandit Exploration:\r\n  --cb_explore arg                      Online explore-exploit for a <k> action\r\n                                        contextual bandit problem\r\n\r\n  --first arg                           tau-first exploration\r\n  --epsilon arg (=0.0500000007)         epsilon-greedy exploration\r\n  --bag arg                             bagging-based exploration\r\n  --cover arg                           Online cover based exploration\r\n  --psi arg (=1)                        disagreement parameter for cover\r\n\r\nMultiworld Testing Options:\r\n  --multiworld_test arg                 Evaluate features as a policies\r\n\r\n  --learn arg                           Do Contextual Bandit learning on <n> \r\n                                        classes.\r\n  --exclude_eval                        Discard mwt policy features before \r\n                                        learning\r\n\r\nContextual Bandit with Action Dependent Features:\r\n  --cb_adf                              Do Contextual Bandit learning with \r\n                                        multiline action dependent features.\r\n\r\n  --rank_all                            Return actions sorted by score order\r\n  --no_predict                          Do not do a prediction when training\r\n  --cb_type arg (=ips)                  contextual bandit method to use in \r\n                                        {ips,dm,dr, mtr}\r\n\r\nContextual Bandit Options:\r\n  --cb arg                              Use contextual bandit learning with <k>\r\n                                        costs\r\n\r\n  --cb_type arg (=dr)                   contextual bandit method to use in \r\n                                        {ips,dm,dr}\r\n  --eval                                Evaluate a policy rather than \r\n                                        optimizing.\r\n\r\nCost Sensitive One Against All with Label Dependent Features:\r\n  --csoaa_ldf arg                       Use one-against-all multiclass learning\r\n                                        with label dependent features.\r\n\r\n  --ldf_override arg                    Override singleline or multiline from \r\n                                        csoaa_ldf or wap_ldf, eg if stored in \r\n                                        file\r\n  --csoaa_rank                          Return actions sorted by score order\r\n  --probabilities                       predict probabilites of all classes\r\n\r\n  --wap_ldf arg                         Use weighted all-pairs multiclass \r\n                                        learning with label dependent features.\r\n                                          Specify singleline or multiline.\r\n\r\n\r\nInteract via elementwise multiplication:\r\n  --interact arg                        Put weights on feature products from \r\n                                        namespaces <n1> and <n2>\r\n\r\n\r\nCost Sensitive One Against All:\r\n  --csoaa arg                           One-against-all multiclass with <k> \r\n                                        costs\r\n\r\n\r\nCost-sensitive Active Learning:\r\n  --cs_active arg                       Cost-sensitive active learning with <k>\r\n                                        costs\r\n\r\n  --simulation                          cost-sensitive active learning \r\n                                        simulation mode\r\n  --baseline                            cost-sensitive active learning baseline\r\n  --domination                          cost-sensitive active learning use \r\n                                        domination. Default 1\r\n  --mellowness arg (=0.100000001)       mellowness parameter c_0. Default 0.1.\r\n  --range_c arg (=0.5)                  parameter controlling the threshold for\r\n                                        per-label cost uncertainty. Default \r\n                                        0.5.\r\n  --max_labels arg (=18446744073709551615)\r\n                                        maximum number of label queries.\r\n  --min_labels arg (=18446744073709551615)\r\n                                        minimum number of label queries.\r\n  --cost_max arg (=1)                   cost upper bound. Default 1.\r\n  --cost_min arg (=0)                   cost lower bound. Default 0.\r\n  --csa_debug                           print debug stuff for cs_active\r\n\r\nMultilabel One Against All:\r\n  --multilabel_oaa arg                  One-against-all multilabel with <k> \r\n                                        labels\r\n\r\n\r\nimportance weight classes:\r\n  --classweight arg                     importance weight multiplier for class\r\n\r\n\r\nRecall Tree:\r\n  --recall_tree arg                     Use online tree for multiclass\r\n\r\n  --max_candidates arg                  maximum number of labels per leaf in \r\n                                        the tree\r\n  --bern_hyper arg (=1)                 recall tree depth penalty\r\n  --max_depth arg                       maximum depth of the tree, default \r\n                                        log_2 (#classes)\r\n  --node_only arg (=0)                  only use node features, not full path \r\n                                        features\r\n  --randomized_routing arg (=0)         randomized routing\r\n\r\nLogarithmic Time Multiclass Tree:\r\n  --log_multi arg                       Use online tree for multiclass\r\n\r\n  --no_progress                         disable progressive validation\r\n  --swap_resistance arg (=4)            higher = more resistance to swap, \r\n                                        default=4\r\n\r\nError Correcting Tournament Options:\r\n  --ect arg                             Error correcting tournament with <k> \r\n                                        labels\r\n\r\n  --error arg (=0)                      errors allowed by ECT\r\n\r\nBoosting:\r\n  --boosting arg                        Online boosting with <N> weak learners\r\n\r\n  --gamma arg (=0.100000001)            weak learner's edge (=0.1), used only \r\n                                        by online BBM\r\n  --alg arg (=BBM)                      specify the boosting algorithm: BBM \r\n                                        (default), logistic (AdaBoost.OL.W), \r\n                                        adaptive (AdaBoost.OL)\r\n\r\nOne Against All Options:\r\n  --oaa arg                             One-against-all multiclass with <k> \r\n                                        labels\r\n\r\n  --oaa_subsample arg                   subsample this number of negative \r\n                                        examples when learning\r\n  --probabilities                       predict probabilites of all classes\r\n  --scores                              output raw scores per class\r\n\r\nTop K:\r\n  --top arg                             top k recommendation\r\n\r\n\r\nExperience Replay:\r\n  --replay_m arg                        use experience replay at a specified \r\n                                        level [b=classification/regression, \r\n                                        m=multiclass, c=cost sensitive] with \r\n                                        specified buffer size\r\n\r\n  --replay_m_count arg (=1)             how many times (in expectation) should \r\n                                        each example be played (default: 1 = \r\n                                        permuting)\r\n\r\nBinary loss:\r\n  --binary                              report loss as binary classification on\r\n                                        -1,1\r\n\r\n\r\nBootstrap:\r\n  --bootstrap arg                       k-way bootstrap by online importance \r\n                                        resampling\r\n\r\n  --bs_type arg                         prediction type {mean,vote}\r\n\r\nscorer options:\r\n  --link arg (=identity)                Specify the link function: identity, \r\n                                        logistic, glf1 or poisson\r\n\r\nStagewise polynomial options:\r\n  --stage_poly                          use stagewise polynomial feature \r\n                                        learning\r\n\r\n  --sched_exponent arg (=1)             exponent controlling quantity of \r\n                                        included features\r\n  --batch_sz arg (=1000)                multiplier on batch size before \r\n                                        including more features\r\n  --batch_sz_no_doubling                batch_sz does not double\r\n\r\nLow Rank Quadratics FA:\r\n  --lrqfa arg                           use low rank quadratic features with \r\n                                        field aware weights\r\n\r\n\r\nLow Rank Quadratics:\r\n  --lrq arg                             use low rank quadratic features\r\n\r\n  --lrqdropout                          use dropout training for low rank \r\n                                        quadratic features\r\n\r\nAutolink:\r\n  --autolink arg                        create link function with polynomial d\r\n\r\n\r\nMarginal:\r\n  --marginal arg                        substitute marginal label estimates for\r\n                                        ids\r\n\r\n  --initial_denominator arg (=1)        initial denominator\r\n  --initial_numerator arg (=0.5)        initial numerator\r\n  --compete                             enable competition with marginal \r\n                                        features\r\n  --update_before_learn arg (=0)        update marginal values before learning\r\n  --unweighted_marginals arg (=0)       ignore importance weights when \r\n                                        computing marginals\r\n  --decay arg (=0)                      decay multiplier per event (1e-3 for \r\n                                        example)\r\n\r\nMatrix Factorization Reduction:\r\n  --new_mf arg                          rank for reduction-based matrix \r\n                                        factorization\r\n\r\n\r\nNeural Network:\r\n  --nn arg                              Sigmoidal feedforward network with <k> \r\n                                        hidden units\r\n\r\n  --inpass                              Train or test sigmoidal feedforward \r\n                                        network with input passthrough.\r\n  --multitask                           Share hidden layer across all reduced \r\n                                        tasks.\r\n  --dropout                             Train or test sigmoidal feedforward \r\n                                        network using dropout.\r\n  --meanfield                           Train or test sigmoidal feedforward \r\n                                        network using mean field.\r\n\r\nConfidence:\r\n  --confidence                          Get confidence for binary predictions\r\n\r\n  --confidence_after_training           Confidence after training\r\n\r\nActive Learning with Cover:\r\n  --active_cover                        enable active learning with cover\r\n\r\n  --mellowness arg (=8)                 active learning mellowness parameter \r\n                                        c_0. Default 8.\r\n  --alpha arg (=1)                      active learning variance upper bound \r\n                                        parameter alpha. Default 1.\r\n  --beta_scale arg (=3.1622777)         active learning variance upper bound \r\n                                        parameter beta_scale. Default sqrt(10).\r\n  --cover arg (=12)                     cover size. Default 12.\r\n  --oracular                            Use Oracular-CAL style query or not. \r\n                                        Default false.\r\n\r\nActive Learning:\r\n  --active                              enable active learning\r\n\r\n  --simulation                          active learning simulation mode\r\n  --mellowness arg (=8)                 active learning mellowness parameter \r\n                                        c_0. Default 8\r\n\r\nExperience Replay:\r\n  --replay_b arg                        use experience replay at a specified \r\n                                        level [b=classification/regression, \r\n                                        m=multiclass, c=cost sensitive] with \r\n                                        specified buffer size\r\n\r\n  --replay_b_count arg (=1)             how many times (in expectation) should \r\n                                        each example be played (default: 1 = \r\n                                        permuting)\r\n\r\nBaseline options:\r\n  --baseline                            Learn an additive baseline (from \r\n                                        constant features) and a residual \r\n                                        separately in regression.\r\n\r\n  --lr_multiplier arg                   learning rate multiplier for baseline \r\n                                        model\r\n  --global_only                         use separate example with only global \r\n                                        constant for baseline predictions\r\n  --check_enabled                       only use baseline when the example \r\n                                        contains enabled flag\r\n\r\nOjaNewton options:\r\n  --OjaNewton                           Online Newton with Oja's Sketch\r\n\r\n  --sketch_size arg (=10)               size of sketch\r\n  --epoch_size arg (=1)                 size of epoch\r\n  --alpha arg (=1)                      mutiplicative constant for indentiy\r\n  --alpha_inverse arg                   one over alpha, similar to learning \r\n                                        rate\r\n  --learning_rate_cnt arg (=2)          constant for the learning rate 1/t\r\n  --normalize arg (=1)                  normalize the features or not\r\n  --random_init arg (=1)                randomize initialization of Oja or not\r\n\r\nLBFGS and Conjugate Gradient options:\r\n  --conjugate_gradient                  use conjugate gradient based \r\n                                        optimization\r\n\r\n\r\n  --bfgs                                use bfgs optimization\r\n\r\n  --hessian_on                          use second derivative in line search\r\n  --mem arg (=15)                       memory in bfgs\r\n  --termination arg (=0.00100000005)    Termination threshold\r\n\r\nLatent Dirichlet Allocation:\r\n  --lda arg                             Run lda with <int> topics\r\n\r\n  --lda_alpha arg (=0.100000001)        Prior on sparsity of per-document topic\r\n                                        weights\r\n  --lda_rho arg (=0.100000001)          Prior on sparsity of topic \r\n                                        distributions\r\n  --lda_D arg (=10000)                  Number of documents\r\n  --lda_epsilon arg (=0.00100000005)    Loop convergence threshold\r\n  --minibatch arg (=1)                  Minibatch size, for LDA\r\n  --math-mode arg (=0)                  Math mode: simd, accuracy, fast-approx\r\n  --metrics arg (=0)                    Compute metrics\r\n\r\nNoop Learner:\r\n  --noop                                do no learning\r\n\r\n\r\nPrint psuedolearner:\r\n  --print                               print examples\r\n\r\n\r\nGradient Descent Matrix Factorization:\r\n  --rank arg                            rank for matrix factorization.\r\n\r\n\r\nNetwork sending:\r\n  --sendto arg                          send examples to <host>\r\n\r\n\r\nStochastic Variance Reduced Gradient:\r\n  --svrg                                Streaming Stochastic Variance Reduced \r\n                                        Gradient\r\n\r\n  --stage_size arg (=1)                 Number of passes per SVRG stage\r\n\r\nFollow the Regularized Leader:\r\n  --ftrl                                FTRL: Follow the Proximal Regularized \r\n                                        Leader\r\n\r\n  --ftrl_alpha arg (=0.00499999989)     Learning rate for FTRL optimization\r\n  --ftrl_beta arg (=0.100000001)        FTRL beta parameter\r\n\r\n  --pistol                              FTRL: Parameter-free Stochastic \r\n                                        Learning\r\n\r\n  --ftrl_alpha arg (=1)                 Learning rate for FTRL optimization\r\n  --ftrl_beta arg (=0.5)                FTRL beta parameter\r\n\r\nKernel SVM:\r\n  --ksvm                                kernel svm\r\n\r\n  --reprocess arg (=1)                  number of reprocess steps for LASVM\r\n  --pool_greedy                         use greedy selection on mini pools\r\n  --para_active                         do parallel active learning\r\n  --pool_size arg (=1)                  size of pools for active learning\r\n  --subsample arg (=1)                  number of items to subsample from the \r\n                                        pool\r\n  --kernel arg (=linear)                type of kernel (rbf or linear \r\n                                        (default))\r\n  --bandwidth arg (=1)                  bandwidth of rbf kernel\r\n  --degree arg (=2)                     degree of poly kernel\r\n  --lambda arg                          saving regularization for test time\r\n\r\nGradient Descent options:\r\n  --sgd                                 use regular stochastic gradient descent\r\n                                        update.\r\n  --adaptive                            use adaptive, individual learning \r\n                                        rates.\r\n  --adax                                use adaptive learning rates with x^2 \r\n                                        instead of g^2x^2\r\n  --invariant                           use safe/importance aware updates.\r\n  --normalized                          use per feature normalized updates\r\n  --sparse_l2 arg (=0)                  use per feature normalized updates\r\n  --l1_state arg (=0)                   use per feature normalized updates\r\n  --l2_state arg (=1)                   use per feature normalized updates\r\n\r\nInput options:\r\n  -d [ --data ] arg                     Example Set\r\n  --daemon                              persistent daemon mode on port 26542\r\n  --foreground                          in persistent daemon mode, do not run \r\n                                        in the background\r\n  --port arg                            port to listen on; use 0 to pick unused\r\n                                        port\r\n  --num_children arg                    number of children for persistent \r\n                                        daemon mode\r\n  --pid_file arg                        Write pid file in persistent daemon \r\n                                        mode\r\n  --port_file arg                       Write port used in persistent daemon \r\n                                        mode\r\n  -c [ --cache ]                        Use a cache.  The default is \r\n                                        <data>.cache\r\n  --cache_file arg                      The location(s) of cache_file.\r\n  --json                                Enable JSON parsing.\r\n  --dsjson                              Enable Decision Service JSON parsing.\r\n  -k [ --kill_cache ]                   do not reuse existing cache: create a \r\n                                        new one always\r\n  --compressed                          use gzip format whenever possible. If a\r\n                                        cache file is being created, this \r\n                                        option creates a compressed cache file.\r\n                                        A mixture of raw-text & compressed \r\n                                        inputs are supported with \r\n                                        autodetection.\r\n  --no_stdin                            do not default to reading from stdin\r\n"
    }
   ]
  },
  {
   "metadata": {
    "lang": "fr"
   },
   "cell_type": "markdown",
   "source": "Vowpal Wabbit lit les données des fichiers ou du flux d'entrée standard (stdin) avec le format suivant:\n\n`[Label] [Importance] [Tag]|Namespace Features |Namespace Features ... |Namespace Features`\n\n`Namespace=String[:Value]`\n\n`Features=(String[:Value] )*`\n\n[] désigne des éléments non obligatoires et (...)* signifie plusieurs entrées autorisées.\n\n- **Label** est un nombre. Dans le cas de la classification, il vaut généralement 1 et -1; pour la régression, c'est une vraie valeur flottante\n- **Importance** est un nombre. Il indique le poids de l'échantillon pendant l'entraînement. Cette configuration aide lorsque vous travaillez avec des données déséquilibrées.\n- **Tag** est une chaîne sans espaces. C'est le \"nom\" de l'échantillon que VW enregistre lors de la prédiction. Afin de séparer Tag de Importance, il est préférable de commencer Tag avec le caractère '.\n- **Namespace** sert à créer différents espaces de caractéristiques.\n- **Les caractéristiques** sont des caractéristiques d'objet à l'intérieur d'un **espace de noms** donné. Les caractéristiques ont un poids de 1,0 par défaut, mais il peut être modifié, par exemple caractéristique: 0,1.\n\n\nLa chaîne suivante correspond au format VW:\n\n```\n1 1.0 |Subject WHAT car is this |Organization University of Maryland:0.5 College Park\n```\n\n\nVérifions le format en exécutant VW avec cet exemple d'entraînement:"
  },
  {
   "metadata": {
    "_cell_guid": "5cbedd43-8d8e-4577-9a67-4f2879f0666c",
    "_uuid": "250fa571012a53fbe15f9b16bd88244dae4f805a",
    "trusted": false
   },
   "cell_type": "code",
   "source": [
    "! echo '1 1.0 |Subject WHAT car is this |Organization University of Maryland:0.5 College Park' | vw"
   ],
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Num weight bits = 18\r\nlearning rate = 0.5\r\ninitial_t = 0\r\npower_t = 0.5\r\nusing no cache\r\nReading datafile = \r\nnum sources = 1\r\naverage  since         example        example  current  current  current\r\nloss     last          counter         weight    label  predict features\r\n1.000000 1.000000            1            1.0   1.0000   0.0000       10\r\n\r\nfinished run\r\nnumber of examples = 1\r\nweighted example sum = 1.000000\r\nweighted label sum = 1.000000\r\naverage loss = 1.000000\r\nbest constant = 1.000000\r\nbest constant's loss = 0.000000\r\ntotal feature number = 10\r\n"
    }
   ]
  },
  {
   "metadata": {
    "lang": "fr"
   },
   "cell_type": "markdown",
   "source": "VW est un outil formidable pour travailler avec des données textuelles. Nous allons l'illustrer avec le jeu de données [20newsgroups](http://scikit-learn.org/stable/datasets/twenty_newsgroups.html), qui contient des articles de 20 newsletters différentes.\n\n\n### 3.1. Articles. Classification binaire."
  },
  {
   "metadata": {
    "_cell_guid": "a37611a4-5bdb-40bb-9b89-bfddd8726ba9",
    "_uuid": "0f527d54e1a759be5fb53665ae4b768116094b27",
    "trusted": false
   },
   "cell_type": "code",
   "source": [
    "# load data with sklearn's function\n",
    "newsgroups = fetch_20newsgroups(PATH_TO_ALL_DATA)"
   ],
   "execution_count": 23,
   "outputs": []
  },
  {
   "metadata": {
    "_cell_guid": "7fad47bd-c5fc-4b56-b024-0e866137d07b",
    "_uuid": "a582c83f4d792d71d12e5063d7539c040b017a67",
    "trusted": false
   },
   "cell_type": "code",
   "source": [
    "newsgroups[\"target_names\"]"
   ],
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "['alt.atheism',\n 'comp.graphics',\n 'comp.os.ms-windows.misc',\n 'comp.sys.ibm.pc.hardware',\n 'comp.sys.mac.hardware',\n 'comp.windows.x',\n 'misc.forsale',\n 'rec.autos',\n 'rec.motorcycles',\n 'rec.sport.baseball',\n 'rec.sport.hockey',\n 'sci.crypt',\n 'sci.electronics',\n 'sci.med',\n 'sci.space',\n 'soc.religion.christian',\n 'talk.politics.guns',\n 'talk.politics.mideast',\n 'talk.politics.misc',\n 'talk.religion.misc']"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "metadata": {
    "lang": "fr"
   },
   "cell_type": "markdown",
   "source": "Regardons le premier document de cette collection:"
  },
  {
   "metadata": {
    "_cell_guid": "d571d3d0-fba9-4d2f-a4a9-3a36e80fe456",
    "_uuid": "039c32b72a84277884c788de8fe2a5e692a4dfb5",
    "trusted": false
   },
   "cell_type": "code",
   "source": [
    "text = newsgroups[\"data\"][0]\n",
    "target = newsgroups[\"target_names\"][newsgroups[\"target\"][0]]\n",
    "\n",
    "print(\"-----\")\n",
    "print(target)\n",
    "print(\"-----\")\n",
    "print(text.strip())\n",
    "print(\"----\")"
   ],
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "-----\nrec.autos\n-----\nFrom: lerxst@wam.umd.edu (where's my thing)\nSubject: WHAT car is this!?\nNntp-Posting-Host: rac3.wam.umd.edu\nOrganization: University of Maryland, College Park\nLines: 15\n\n I was wondering if anyone out there could enlighten me on this car I saw\nthe other day. It was a 2-door sports car, looked to be from the late 60s/\nearly 70s. It was called a Bricklin. The doors were really small. In addition,\nthe front bumper was separate from the rest of the body. This is \nall I know. If anyone can tellme a model name, engine specs, years\nof production, where this car is made, history, or whatever info you\nhave on this funky looking car, please e-mail.\n\nThanks,\n- IL\n   ---- brought to you by your neighborhood Lerxst ----\n----\n"
    }
   ]
  },
  {
   "metadata": {
    "lang": "fr"
   },
   "cell_type": "markdown",
   "source": "Maintenant, nous convertissons les données en quelque chose que Vowpal Wabbit peut comprendre. Nous rejetterons les mots de moins de 3 symboles. Ici, nous allons sauter certaines étapes importantes du NLP telles que le stemming et la lemmatisation; cependant, nous verrons plus tard que VW résout le problème même sans ces étapes."
  },
  {
   "metadata": {
    "_cell_guid": "61c25a92-1b0a-45cf-904f-6c35de89575f",
    "_uuid": "9b480cff8801ad51f371b05f6f63225c758883ca",
    "trusted": false
   },
   "cell_type": "code",
   "source": [
    "def to_vw_format(document, label=None):\n",
    "    return (\n",
    "        str(label or \"\")\n",
    "        + \" |text \"\n",
    "        + \" \".join(re.findall(\"\\w{3,}\", document.lower()))\n",
    "        + \"\\n\"\n",
    "    )\n",
    "\n",
    "\n",
    "to_vw_format(text, 1 if target == \"rec.autos\" else -1)"
   ],
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "'1 |text from lerxst wam umd edu where thing subject what car this nntp posting host rac3 wam umd edu organization university maryland college park lines was wondering anyone out there could enlighten this car saw the other day was door sports car looked from the late 60s early 70s was called bricklin the doors were really small addition the front bumper was separate from the rest the body this all know anyone can tellme model name engine specs years production where this car made history whatever info you have this funky looking car please mail thanks brought you your neighborhood lerxst\\n'"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "metadata": {
    "lang": "fr"
   },
   "cell_type": "markdown",
   "source": "Nous divisons l'ensemble de données en **train** et **test** et les écrivons dans des fichiers séparés. Nous considérerons un document comme positif s'il correspond à **rec.autos**. Ainsi, nous construisons un modèle qui distingue les articles sur les voitures d'autres sujets:"
  },
  {
   "metadata": {
    "_cell_guid": "297c4ed7-3157-412e-b3af-1bc59084defd",
    "_uuid": "f5754e324f2165a47ab603e2e5fafa5b681ea1e9",
    "trusted": false
   },
   "cell_type": "code",
   "source": [
    "all_documents = newsgroups[\"data\"]\n",
    "all_targets = [\n",
    "    1 if newsgroups[\"target_names\"][target] == \"rec.autos\" else -1\n",
    "    for target in newsgroups[\"target\"]\n",
    "]"
   ],
   "execution_count": 27,
   "outputs": []
  },
  {
   "metadata": {
    "_cell_guid": "d0cd644c-fdd2-4b46-9ff5-377ef12a3d6e",
    "_uuid": "623b5b239dda745dc0e79a7b225825eed8f98d09",
    "trusted": false
   },
   "cell_type": "code",
   "source": [
    "train_documents, test_documents, train_labels, test_labels = train_test_split(\n",
    "    all_documents, all_targets, random_state=7\n",
    ")\n",
    "\n",
    "with open(os.path.join(PATH_TO_ALL_DATA, \"20news_train.vw\"), \"w\") as vw_train_data:\n",
    "    for text, target in zip(train_documents, train_labels):\n",
    "        vw_train_data.write(to_vw_format(text, target))\n",
    "with open(os.path.join(PATH_TO_ALL_DATA, \"20news_test.vw\"), \"w\") as vw_test_data:\n",
    "    for text in test_documents:\n",
    "        vw_test_data.write(to_vw_format(text))"
   ],
   "execution_count": 28,
   "outputs": []
  },
  {
   "metadata": {
    "lang": "fr"
   },
   "cell_type": "markdown",
   "source": "Maintenant, nous transmettons le fichier de formation créé à Vowpal Wabbit. Nous résolvons le problème de classification avec une fonction de perte charnière (SVM linéaire). Le modèle entraîné sera enregistré dans le fichier `20news_model.vw`:"
  },
  {
   "metadata": {
    "_cell_guid": "80f2960a-2389-4810-9b04-1928b613b4b2",
    "_uuid": "7a5a15cc11e801a98b493bab026136c9eeb33816",
    "trusted": false
   },
   "cell_type": "code",
   "source": [
    "!vw -d $PATH_TO_ALL_DATA/20news_train.vw \\\n",
    " --loss_function hinge -f $PATH_TO_ALL_DATA/20news_model.vw"
   ],
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "final_regressor = ../../data//20news_model.vw\nNum weight bits = 18\nlearning rate = 0.5\ninitial_t = 0\npower_t = 0.5\nusing no cache\nReading datafile = ../../data//20news_train.vw\nnum sources = 1\naverage  since         example        example  current  current  current\nloss     last          counter         weight    label  predict features\n1.000000 1.000000            1            1.0  -1.0000   0.0000      157\n0.911276 0.822551            2            2.0  -1.0000  -0.1774      159\n0.605793 0.300311            4            4.0  -1.0000  -0.3994       92\n0.419594 0.233394            8            8.0  -1.0000  -0.8167      129\n0.313998 0.208402           16           16.0  -1.0000  -0.6509      108\n0.196014 0.078029           32           32.0  -1.0000  -1.0000      115\n0.183158 0.170302           64           64.0  -1.0000  -0.7072      114\n0.261046 0.338935          128          128.0   1.0000  -0.7900      110\n0.262910 0.264774          256          256.0  -1.0000  -0.6425       44\n0.216663 0.170415          512          512.0  -1.0000  -1.0000      160\n0.176710 0.136757         1024         1024.0  -1.0000  -1.0000      194\n0.134541 0.092371         2048         2048.0  -1.0000  -1.0000      438\n0.104403 0.074266         4096         4096.0  -1.0000  -1.0000      644\n0.081329 0.058255         8192         8192.0  -1.0000  -1.0000      174\n\nfinished run\nnumber of examples = 8485\nweighted example sum = 8485.000000\nweighted label sum = -7555.000000\naverage loss = 0.079837\nbest constant = -1.000000\nbest constant's loss = 0.109605\ntotal feature number = 2048932\n"
    }
   ]
  },
  {
   "metadata": {
    "lang": "fr"
   },
   "cell_type": "markdown",
   "source": "VW imprime beaucoup d'informations intéressantes pendant l'entraînement (on peut les supprimer avec le paramètre `--quiet`). Vous pouvez voir la documentation de la sortie de diagnostic sur [GitHub](https://github.com/JohnLangford/vowpal_wabbit/wiki/Tutorial#vws-diagnostic-information). Notez comment la perte moyenne diminue pendant l'entraînement. Pour le calcul des pertes, VW utilise des échantillons qu'il n'a jamais vus auparavant, donc cette mesure est généralement précise. Maintenant, nous appliquons notre modèle entraîné à l'ensemble de test, en enregistrant les prédictions dans un fichier avec l'indicateur `-p`:"
  },
  {
   "metadata": {
    "_cell_guid": "17c99751-4e30-4251-b18f-fe6ed8a34e58",
    "_uuid": "276f1431b121543e67f668bb5e9d601dd882e98e",
    "trusted": false
   },
   "cell_type": "code",
   "source": [
    "!vw -i $PATH_TO_ALL_DATA/20news_model.vw -t -d $PATH_TO_ALL_DATA/20news_test.vw \\\n",
    "-p $PATH_TO_ALL_DATA/20news_test_predictions.txt"
   ],
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "only testing\r\npredictions = ../../data//20news_test_predictions.txt\r\nNum weight bits = 18\r\nlearning rate = 0.5\r\ninitial_t = 0\r\npower_t = 0.5\r\nusing no cache\r\nReading datafile = ../../data//20news_test.vw\r\nnum sources = 1\r\naverage  since         example        example  current  current  current\r\nloss     last          counter         weight    label  predict features\r\n    n.a.     n.a.            1            1.0  unknown   1.0000      349\r\n    n.a.     n.a.            2            2.0  unknown  -1.0000       50\r\n    n.a.     n.a.            4            4.0  unknown  -1.0000      251\r\n    n.a.     n.a.            8            8.0  unknown  -1.0000      237\r\n    n.a.     n.a.           16           16.0  unknown  -0.8978      106\r\n    n.a.     n.a.           32           32.0  unknown  -1.0000      964\r\n    n.a.     n.a.           64           64.0  unknown  -1.0000      261\r\n    n.a.     n.a.          128          128.0  unknown   0.4621       82\r\n    n.a.     n.a.          256          256.0  unknown  -1.0000      186\r\n    n.a.     n.a.          512          512.0  unknown  -1.0000      162\r\n    n.a.     n.a.         1024         1024.0  unknown  -1.0000      283\r\n    n.a.     n.a.         2048         2048.0  unknown  -1.0000      104\r\n\r\nfinished run\r\nnumber of examples = 2829\r\nweighted example sum = 2829.000000\r\nweighted label sum = 0.000000\r\naverage loss = n.a.\r\ntotal feature number = 642215\r\n"
    }
   ]
  },
  {
   "metadata": {
    "lang": "fr"
   },
   "cell_type": "markdown",
   "source": "Maintenant, nous chargeons nos prédictions, calculons AUC et traçons la courbe ROC:"
  },
  {
   "metadata": {
    "_cell_guid": "93d9f296-f06b-4d18-94a5-e18ccf88b094",
    "_uuid": "40b4112f1afa764db10b58b0ab05adfed48ab388",
    "trusted": false
   },
   "cell_type": "code",
   "source": [
    "with open(os.path.join(PATH_TO_ALL_DATA, \"20news_test_predictions.txt\")) as pred_file:\n",
    "    test_prediction = [float(label) for label in pred_file.readlines()]\n",
    "\n",
    "auc = roc_auc_score(test_labels, test_prediction)\n",
    "roc_curve = roc_curve(test_labels, test_prediction)\n",
    "\n",
    "with plt.xkcd():\n",
    "    plt.plot(roc_curve[0], roc_curve[1])\n",
    "    plt.plot([0, 1], [0, 1])\n",
    "    plt.xlabel(\"FPR\")\n",
    "    plt.ylabel(\"TPR\")\n",
    "    plt.title(\"test AUC = %f\" % (auc))\n",
    "    plt.axis([-0.05, 1.05, -0.05, 1.05]);"
   ],
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": "<Figure size 432x288 with 1 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ]
  },
  {
   "metadata": {
    "lang": "fr"
   },
   "cell_type": "markdown",
   "source": "La valeur AUC que nous obtenons montre que nous avons atteint une qualité de classification élevée."
  },
  {
   "metadata": {
    "lang": "fr"
   },
   "cell_type": "markdown",
   "source": "### 3.2. Articles. Classification multiclasse"
  },
  {
   "metadata": {
    "lang": "fr"
   },
   "cell_type": "markdown",
   "source": "Nous utiliserons le même jeu de données d'actualités, mais, cette fois, nous allons résoudre un problème de classification multiclasse. «Vowpal Wabbit» est un peu pointilleux - il veut des étiquettes commençant de 1 à K, où K - est le nombre de classes dans la tâche de classification (20 dans notre cas). Nous allons donc utiliser LabelEncoder et ajouter 1 par la suite (rappelez-vous que `LabelEncoder` mappe les étiquettes dans la plage de 0 à K-1)."
  },
  {
   "metadata": {
    "_cell_guid": "e94dfe85-61d6-42d2-b19e-89923b511535",
    "_uuid": "30fca7585b9d841b5925ec9b3db9b12ff1bb5142",
    "trusted": false
   },
   "cell_type": "code",
   "source": [
    "all_documents = newsgroups[\"data\"]\n",
    "topic_encoder = LabelEncoder()\n",
    "all_targets_mult = topic_encoder.fit_transform(newsgroups[\"target\"]) + 1"
   ],
   "execution_count": 32,
   "outputs": []
  },
  {
   "metadata": {
    "lang": "fr"
   },
   "cell_type": "markdown",
   "source": "**Les données sont les mêmes, mais nous avons changé les étiquettes, train_labels_mult et test_labels_mult, en vecteurs d'étiquettes de 1 à 20.**"
  },
  {
   "metadata": {
    "_cell_guid": "90e22502-efe9-4a2c-9868-fa6a18ed91b2",
    "_uuid": "f90ea2c247690e680d26f6d30992daf45ffd0315",
    "trusted": false
   },
   "cell_type": "code",
   "source": [
    "train_documents, test_documents, train_labels_mult, test_labels_mult = train_test_split(\n",
    "    all_documents, all_targets_mult, random_state=7\n",
    ")\n",
    "\n",
    "with open(os.path.join(PATH_TO_ALL_DATA, \"20news_train_mult.vw\"), \"w\") as vw_train_data:\n",
    "    for text, target in zip(train_documents, train_labels_mult):\n",
    "        vw_train_data.write(to_vw_format(text, target))\n",
    "with open(os.path.join(PATH_TO_ALL_DATA, \"20news_test_mult.vw\"), \"w\") as vw_test_data:\n",
    "    for text in test_documents:\n",
    "        vw_test_data.write(to_vw_format(text))"
   ],
   "execution_count": 33,
   "outputs": []
  },
  {
   "metadata": {
    "lang": "fr"
   },
   "cell_type": "markdown",
   "source": "Nous entraînons Vowpal Wabbit en mode de classification multiclasse, en passant le paramètre `oaa` (\" un contre tous \") avec le nombre de classes. Voyons également de quels paramètres la qualité de notre modèle dépend (plus d'informations peuvent être trouvées dans le [tutoriel officiel de Vowpal Wabbit](https://github.com/JohnLangford/vowpal_wabbit/wiki/Tutorial)):\n - learning rate (-l, 0,5 par défaut) - taux de changement de poids à chaque pas\n - learning rate decay (--power_ t, 0.5 par défaut) - il est prouvé en pratique que, si le taux d'apprentissage diminue avec le nombre de pas en descente de gradient stochastique, on approche mieux la perte minimale\n - loss function (fonction --loss _) - tout l'algorithme d'apprentissage en dépend. Voir [docs](https://github.com/JohnLangford/vowpal_wabbit/wiki/Loss-functions) pour les fonctions de perte\n - Regularization (-l1) - notez que VW calcule la régularisation pour chaque objet. C'est pourquoi nous définissons généralement les valeurs de régularisation à environ $10^{-20}.$\n \nDe plus, nous pouvons essayer le réglage automatique des paramètres Vowpal Wabbit avec [Hyperopt](https://github.com/hyperopt/hyperopt)."
  },
  {
   "metadata": {
    "_cell_guid": "80ae364e-8332-41db-bdc3-7f642bb24d7a",
    "_uuid": "97ea9ebcb6ed46b5512f5a9364680e501c2925cf",
    "trusted": false
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "!vw --oaa 20 $PATH_TO_ALL_DATA/20news_train_mult.vw -f $PATH_TO_ALL_DATA/20news_model_mult.vw \\\n",
    "--loss_function=hinge"
   ],
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "final_regressor = ../../data//20news_model_mult.vw\nNum weight bits = 18\nlearning rate = 0.5\ninitial_t = 0\npower_t = 0.5\nusing no cache\nReading datafile = ../../data//20news_train_mult.vw\nnum sources = 1\naverage  since         example        example  current  current  current\nloss     last          counter         weight    label  predict features\n1.000000 1.000000            1            1.0       15        1      157\n1.000000 1.000000            2            2.0        2       15      159\n1.000000 1.000000            4            4.0       15       10       92\n1.000000 1.000000            8            8.0       16       15      129\n1.000000 1.000000           16           16.0       13       12      108\n0.937500 0.875000           32           32.0        2        9      115\n0.906250 0.875000           64           64.0       16       16      114\n0.867188 0.828125          128          128.0        8        4      110\n0.816406 0.765625          256          256.0        7       15       44\n0.646484 0.476562          512          512.0       13        9      160\n0.502930 0.359375         1024         1024.0        3        4      194\n0.388672 0.274414         2048         2048.0        1        1      438\n0.300293 0.211914         4096         4096.0       11       11      644\n0.225098 0.149902         8192         8192.0        5        5      174\n\nfinished run\nnumber of examples = 8485\nweighted example sum = 8485.000000\nweighted label sum = 0.000000\naverage loss = 0.222392\ntotal feature number = 2048932\nCPU times: user 4.77 ms, sys: 4.45 ms, total: 9.22 ms\nWall time: 506 ms\n"
    }
   ]
  },
  {
   "metadata": {
    "_cell_guid": "4d78df8b-f6d2-477a-b5be-a5f7364c0e56",
    "_uuid": "d30d194b2be9521d609d703385f528c24a557aa0",
    "trusted": false
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "!vw -i $PATH_TO_ALL_DATA/20news_model_mult.vw -t -d $PATH_TO_ALL_DATA/20news_test_mult.vw \\\n",
    "-p $PATH_TO_ALL_DATA/20news_test_predictions_mult.txt"
   ],
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "only testing\npredictions = ../../data//20news_test_predictions_mult.txt\nNum weight bits = 18\nlearning rate = 0.5\ninitial_t = 0\npower_t = 0.5\nusing no cache\nReading datafile = ../../data//20news_test_mult.vw\nnum sources = 1\naverage  since         example        example  current  current  current\nloss     last          counter         weight    label  predict features\n    n.a.     n.a.            1            1.0  unknown        8      349\n    n.a.     n.a.            2            2.0  unknown        6       50\n    n.a.     n.a.            4            4.0  unknown       18      251\n    n.a.     n.a.            8            8.0  unknown       18      237\n    n.a.     n.a.           16           16.0  unknown        4      106\n    n.a.     n.a.           32           32.0  unknown       15      964\n    n.a.     n.a.           64           64.0  unknown        4      261\n    n.a.     n.a.          128          128.0  unknown        8       82\n    n.a.     n.a.          256          256.0  unknown       10      186\n    n.a.     n.a.          512          512.0  unknown        1      162\n    n.a.     n.a.         1024         1024.0  unknown       11      283\n    n.a.     n.a.         2048         2048.0  unknown       14      104\n\nfinished run\nnumber of examples = 2829\nweighted example sum = 2829.000000\nweighted label sum = 0.000000\naverage loss = n.a.\ntotal feature number = 642215\nCPU times: user 6.79 ms, sys: 13.6 ms, total: 20.4 ms\nWall time: 371 ms\n"
    }
   ]
  },
  {
   "metadata": {
    "_cell_guid": "bf4c66cf-3039-4ac4-a129-e52652c16d8d",
    "_uuid": "f6911717662ade8c466cc2f3681f356619d8676c",
    "trusted": false
   },
   "cell_type": "code",
   "source": [
    "with open(\n",
    "    os.path.join(PATH_TO_ALL_DATA, \"20news_test_predictions_mult.txt\")\n",
    ") as pred_file:\n",
    "    test_prediction_mult = [float(label) for label in pred_file.readlines()]"
   ],
   "execution_count": 36,
   "outputs": []
  },
  {
   "metadata": {
    "_cell_guid": "c8cd9521-6c23-412b-959d-19e9f95bd5ee",
    "_uuid": "c110cfb692d0c280009ca815efa504f5889e28a6",
    "trusted": false
   },
   "cell_type": "code",
   "source": [
    "accuracy_score(test_labels_mult, test_prediction_mult)"
   ],
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "0.8734535171438671"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "metadata": {
    "lang": "fr"
   },
   "cell_type": "markdown",
   "source": "Voici à quelle fréquence le modèle classe mal l'athéisme avec d'autres sujets:"
  },
  {
   "metadata": {
    "_cell_guid": "5b40bd39-4895-4713-be3a-2fea6fa37062",
    "_uuid": "fefe7d01f98e8cd3af7ce5a3b7d0f859755e5047",
    "trusted": false
   },
   "cell_type": "code",
   "source": [
    "M = confusion_matrix(test_labels_mult, test_prediction_mult)\n",
    "for i in np.where(M[0, :] > 0)[0][1:]:\n",
    "    print(newsgroups[\"target_names\"][i], M[0, i])"
   ],
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "rec.autos 1\nrec.sport.baseball 1\nsci.med 1\nsoc.religion.christian 3\ntalk.religion.misc 5\n"
    }
   ]
  },
  {
   "metadata": {
    "lang": "fr"
   },
   "cell_type": "markdown",
   "source": "### 3.3. Critiques de films IMDB\nDans cette partie, nous ferons la classification binaire des critiques de films [IMDB](http://www.imdb.com) (International Movie DataBase). Nous verrons à quelle vitesse Vowpal Wabbit fonctionne.\n\nEn utilisant la fonction `load_files` de` sklearn.datasets`, nous chargeons les ensembles de données des critiques de films. C'est le même jeu de données que nous avons utilisé dans le notebook topic04 part4."
  },
  {
   "metadata": {
    "_cell_guid": "a1827aa1-5bc7-4838-bb01-68792de451b6",
    "_uuid": "e719b5b6c976cf9daf10a9f3b7c35b4cde79b057",
    "trusted": false
   },
   "cell_type": "code",
   "source": [
    "import tarfile\n",
    "\n",
    "# Download the dataset if not already in place\n",
    "from io import BytesIO\n",
    "\n",
    "import requests\n",
    "\n",
    "url = \"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
    "\n",
    "\n",
    "def load_imdb_dataset(extract_path=\"../../data\", overwrite=False):\n",
    "    # check if existed already\n",
    "    if (\n",
    "        os.path.isfile(os.path.join(extract_path, \"aclImdb\", \"README\"))\n",
    "        and not overwrite\n",
    "    ):\n",
    "        print(\"IMDB dataset is already in place.\")\n",
    "        return\n",
    "\n",
    "    print(\"Downloading the dataset from:  \", url)\n",
    "    response = requests.get(url)\n",
    "\n",
    "    tar = tarfile.open(mode=\"r:gz\", fileobj=BytesIO(response.content))\n",
    "\n",
    "    data = tar.extractall(extract_path)\n",
    "\n",
    "\n",
    "load_imdb_dataset()"
   ],
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "IMDB dataset is already in place.\n"
    }
   ]
  },
  {
   "metadata": {
    "lang": "fr"
   },
   "cell_type": "markdown",
   "source": "Lire les données du train, séparer les étiquettes."
  },
  {
   "metadata": {
    "trusted": false
   },
   "cell_type": "code",
   "source": [
    "PATH_TO_IMDB = \"../../data/aclImdb\"\n",
    "\n",
    "reviews_train = load_files(\n",
    "    os.path.join(PATH_TO_IMDB, \"train\"), categories=[\"pos\", \"neg\"]\n",
    ")\n",
    "\n",
    "text_train, y_train = reviews_train.data, reviews_train.target"
   ],
   "execution_count": 40,
   "outputs": []
  },
  {
   "metadata": {
    "_cell_guid": "db550541-630a-47a5-8b98-246d94a3fb33",
    "_uuid": "593032d9be6e7aff583e0c7ba40e3e801b136edf",
    "trusted": false
   },
   "cell_type": "code",
   "source": [
    "print(\"Number of documents in training data: %d\" % len(text_train))\n",
    "print(np.bincount(y_train))"
   ],
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Number of documents in training data: 25000\n[12500 12500]\n"
    }
   ]
  },
  {
   "metadata": {
    "lang": "fr"
   },
   "cell_type": "markdown",
   "source": "Faire de même pour l'ensemble de test."
  },
  {
   "metadata": {
    "_cell_guid": "ce60fd02-e5d4-40aa-a5db-33556ef7063f",
    "_uuid": "8fea469dd838a26671f234d54cf82d6f57188e73",
    "trusted": false
   },
   "cell_type": "code",
   "source": [
    "reviews_test = load_files(os.path.join(PATH_TO_IMDB, \"test\"), categories=[\"pos\", \"neg\"])\n",
    "text_test, y_test = reviews_test.data, reviews_test.target"
   ],
   "execution_count": 42,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": false
   },
   "cell_type": "code",
   "source": [
    "print(\"Number of documents in test data: %d\" % len(text_test))\n",
    "print(np.bincount(y_test))"
   ],
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Number of documents in test data: 25000\n[12500 12500]\n"
    }
   ]
  },
  {
   "metadata": {
    "lang": "fr"
   },
   "cell_type": "markdown",
   "source": "Jetez un œil à des exemples d'avis et leurs libellés correspondants."
  },
  {
   "metadata": {
    "_cell_guid": "213017e1-25f0-4d08-8d9c-5341b449b8f6",
    "_uuid": "aea5acfcef80c4006dbcab233d237d2cd091ab48",
    "trusted": false
   },
   "cell_type": "code",
   "source": [
    "text_train[0]"
   ],
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "b\"Zero Day leads you to think, even re-think why two boys/young men would do what they did - commit mutual suicide via slaughtering their classmates. It captures what must be beyond a bizarre mode of being for two humans who have decided to withdraw from common civility in order to define their own/mutual world via coupled destruction.<br /><br />It is not a perfect movie but given what money/time the filmmaker and actors had - it is a remarkable product. In terms of explaining the motives and actions of the two young suicide/murderers it is better than 'Elephant' - in terms of being a film that gets under our 'rationalistic' skin it is a far, far better film than almost anything you are likely to see. <br /><br />Flawed but honest with a terrible honesty.\""
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "metadata": {
    "_cell_guid": "23c8ca4d-7287-406a-8381-f9c9c095f1b7",
    "_uuid": "976c29d60e5fc1da27e36b5c34dd1fa4185cd083",
    "trusted": false
   },
   "cell_type": "code",
   "source": [
    "y_train[0]  # good review"
   ],
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "metadata": {
    "_cell_guid": "b4cd5590-5952-4388-9960-37702e78be4f",
    "_uuid": "2fe24a84eb18599fb67664a63e3b2178ee29ee26",
    "trusted": false
   },
   "cell_type": "code",
   "source": [
    "text_train[1]"
   ],
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "b'Words can\\'t describe how bad this movie is. I can\\'t explain it by writing only. You have too see it for yourself to get at grip of how horrible a movie really can be. Not that I recommend you to do that. There are so many clich\\xc3\\xa9s, mistakes (and all other negative things you can imagine) here that will just make you cry. To start with the technical first, there are a LOT of mistakes regarding the airplane. I won\\'t list them here, but just mention the coloring of the plane. They didn\\'t even manage to show an airliner in the colors of a fictional airline, but instead used a 747 painted in the original Boeing livery. Very bad. The plot is stupid and has been done many times before, only much, much better. There are so many ridiculous moments here that i lost count of it really early. Also, I was on the bad guys\\' side all the time in the movie, because the good guys were so stupid. \"Executive Decision\" should without a doubt be you\\'re choice over this one, even the \"Turbulence\"-movies are better. In fact, every other movie in the world is better than this one.'"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "metadata": {
    "_cell_guid": "0faa88f7-c96d-4073-9b16-b6d68d31d354",
    "_uuid": "f64122c2e93648b75494df26b1de4bf01358df35",
    "trusted": false
   },
   "cell_type": "code",
   "source": [
    "y_train[1]  # bad review"
   ],
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "metadata": {
    "_cell_guid": "23032bfe-25d1-4f79-b24e-a4cb69f44127",
    "_uuid": "0ce9e75db41712f6f9161f9d6cd8000381a5b3ba",
    "trusted": false
   },
   "cell_type": "code",
   "source": [
    "to_vw_format(str(text_train[1]), 1 if y_train[0] == 1 else -1)"
   ],
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "'1 |text words can describe how bad this movie can explain writing only you have too see for yourself get grip how horrible movie really can not that recommend you that there are many clich xc3 xa9s mistakes and all other negative things you can imagine here that will just make you cry start with the technical first there are lot mistakes regarding the airplane won list them here but just mention the coloring the plane they didn even manage show airliner the colors fictional airline but instead used 747 painted the original boeing livery very bad the plot stupid and has been done many times before only much much better there are many ridiculous moments here that lost count really early also was the bad guys side all the time the movie because the good guys were stupid executive decision should without doubt you choice over this one even the turbulence movies are better fact every other movie the world better than this one\\n'"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "metadata": {
    "lang": "fr"
   },
   "cell_type": "markdown",
   "source": "Maintenant, nous préparons l'apprentissage (`movie _reviews_ train.vw`), la validation (` movie _reviews_ valid.vw`) et le test (`movie _reviews_ test.vw`) définit pour Vowpal Wabbit. Nous utiliserons 70% pour la formation, 30% pour le reste."
  },
  {
   "metadata": {
    "_cell_guid": "c08edd2b-7290-4e70-9072-895e33923d44",
    "_uuid": "7309769413ef059831390aea012334a5d7482817",
    "trusted": false
   },
   "cell_type": "code",
   "source": [
    "train_share = int(0.7 * len(text_train))\n",
    "train, valid = text_train[:train_share], text_train[train_share:]\n",
    "train_labels, valid_labels = y_train[:train_share], y_train[train_share:]"
   ],
   "execution_count": 49,
   "outputs": []
  },
  {
   "metadata": {
    "_cell_guid": "a30cddd4-fceb-46ca-87a8-1b7b7d3b36d1",
    "_uuid": "9154377a268f463e98c17432a84a77d03e68052e",
    "trusted": false
   },
   "cell_type": "code",
   "source": [
    "len(train_labels), len(valid_labels)"
   ],
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "(17500, 7500)"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "metadata": {
    "_cell_guid": "6d25382f-b135-47f8-a82c-2568ad02f9ff",
    "_uuid": "cce438177377598771a890dc94651de5a6a8495e",
    "trusted": false
   },
   "cell_type": "code",
   "source": [
    "with open(\n",
    "    os.path.join(PATH_TO_ALL_DATA, \"movie_reviews_train.vw\"), \"w\"\n",
    ") as vw_train_data:\n",
    "    for text, target in zip(train, train_labels):\n",
    "        vw_train_data.write(to_vw_format(str(text), 1 if target == 1 else -1))\n",
    "with open(\n",
    "    os.path.join(PATH_TO_ALL_DATA, \"movie_reviews_valid.vw\"), \"w\"\n",
    ") as vw_train_data:\n",
    "    for text, target in zip(valid, valid_labels):\n",
    "        vw_train_data.write(to_vw_format(str(text), 1 if target == 1 else -1))\n",
    "with open(os.path.join(PATH_TO_ALL_DATA, \"movie_reviews_test.vw\"), \"w\") as vw_test_data:\n",
    "    for text in text_test:\n",
    "        vw_test_data.write(to_vw_format(str(text)))"
   ],
   "execution_count": 51,
   "outputs": []
  },
  {
   "metadata": {
    "_cell_guid": "cb999742-8ad7-428d-8f66-f015d38de4f8",
    "_uuid": "8d87247a0d044e81b545e37ffaa59a96712a252f",
    "trusted": false
   },
   "cell_type": "code",
   "source": [
    "!head -2 $PATH_TO_ALL_DATA/movie_reviews_train.vw"
   ],
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "1 |text zero day leads you think even think why two boys young men would what they did commit mutual suicide via slaughtering their classmates captures what must beyond bizarre mode being for two humans who have decided withdraw from common civility order define their own mutual world via coupled destruction not perfect movie but given what money time the filmmaker and actors had remarkable product terms explaining the motives and actions the two young suicide murderers better than elephant terms being film that gets under our rationalistic skin far far better film than almost anything you are likely see flawed but honest with terrible honesty\r\n-1 |text words can describe how bad this movie can explain writing only you have too see for yourself get grip how horrible movie really can not that recommend you that there are many clich xc3 xa9s mistakes and all other negative things you can imagine here that will just make you cry start with the technical first there are lot mistakes regarding the airplane won list them here but just mention the coloring the plane they didn even manage show airliner the colors fictional airline but instead used 747 painted the original boeing livery very bad the plot stupid and has been done many times before only much much better there are many ridiculous moments here that lost count really early also was the bad guys side all the time the movie because the good guys were stupid executive decision should without doubt you choice over this one even the turbulence movies are better fact every other movie the world better than this one\r\n"
    }
   ]
  },
  {
   "metadata": {
    "_cell_guid": "f25cd0d3-1767-41f1-b7bf-096224619bc5",
    "_uuid": "b63440f7ffebc472ecbe54d8e3aef8c3a3b75fa1",
    "trusted": false
   },
   "cell_type": "code",
   "source": [
    "!head -2 $PATH_TO_ALL_DATA/movie_reviews_valid.vw"
   ],
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "1 |text matter life and death what can you really say that would properly justice the genius and beauty this film powell and pressburger visual imagination knows bounds every frame filled with fantastically bold compositions the switches between the bold colours the real world the stark black and white heaven ingenious showing visually just how much more vibrant life the final court scene also fantastic the judge and jury descend the stairway heaven hold court over peter david niven operation all the performances are spot roger livesey being standout and the romantic energy the film beautiful never has there been more romantic film than this there has haven seen matter life and death all about the power love and just how important life and jack cardiff cinematography reason enough watch the film alone the way lights kim hunter face makes her all the more beautiful what genius can make simple things such game table tennis look exciting and the sound design also impeccable the way the sound mutes vital points was decision way ahead its time this true classic that can restore anyone faith cinema under appreciated its initial release and today audiences but one all time favourites which why give this film word beautiful\r\n1 |text while this was better movie than 101 dalmations live action not animated version think still fell little short what disney could was well filmed the music was more suited the action and the effects were better done compared 101 the acting was perhaps better but then the human characters were given far more appropriate roles this sequel and glenn close really not missed the first movie she makes shine her poor lackey and the overzealous furrier sidekicks are wonderful characters play off and they add the spectacle disney has given this great family film with little objectionable material and yet remains fun and interesting for adults and children alike bound classic many disney films are here hoping the third will even better still because you know they probably want make one\r\n"
    }
   ]
  },
  {
   "metadata": {
    "_cell_guid": "eaa1a658-e6e0-42f1-9c30-14be762fc7d9",
    "_uuid": "fd4e364bad19a64110f7ec839a56a2776222306c",
    "trusted": false
   },
   "cell_type": "code",
   "source": [
    "!head -2 $PATH_TO_ALL_DATA/movie_reviews_test.vw"
   ],
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": " |text don hate heather graham because she beautiful hate her because she fun watch this movie like the hip clothing and funky surroundings the actors this flick work well together casey affleck hysterical and heather graham literally lights the screen the minor characters goran visnjic sigh and patricia velazquez are talented they are gorgeous congratulations miramax director lisa krueger\r\n |text don know how this movie has received many positive comments one can call artistic and beautifully filmed but those things don make for the empty plot that was filled with sexual innuendos wish had not wasted time watch this movie rather than being biographical was poor excuse for promoting strange and lewd behavior was just another hollywood attempt convince that that kind life normal and from the very beginning asked self what was the point this movie and continued watching hoping that would change and was quite disappointed that continued the same vein glad did not spend the money see this theater\r\n"
    }
   ]
  },
  {
   "metadata": {
    "lang": "fr"
   },
   "cell_type": "markdown",
   "source": "**Nous lançons maintenant Vowpal Wabbit avec les arguments suivants:**\n\n - `-d`, chemin vers l'ensemble d'entraînement (fichier .vw correspondant)\n - `--loss_function` - charnière (n'hésitez pas à expérimenter ici)\n - `-f` - chemin vers le fichier de sortie (qui peut également être au format .vw)"
  },
  {
   "metadata": {
    "_cell_guid": "89094f9e-7453-4137-87b0-21df78627ae6",
    "_uuid": "4e27dea292bfde2224e802d60c00aad0fbac3274",
    "trusted": false
   },
   "cell_type": "code",
   "source": [
    "!vw -d $PATH_TO_ALL_DATA/movie_reviews_train.vw --loss_function hinge \\\n",
    "-f $PATH_TO_ALL_DATA/movie_reviews_model.vw --quiet"
   ],
   "execution_count": 55,
   "outputs": []
  },
  {
   "metadata": {
    "lang": "fr"
   },
   "cell_type": "markdown",
   "source": "Ensuite, faites la prédiction de hold-out avec les arguments VW suivants:\n - `-i` - chemin vers le modèle entraîné (fichier .vw)\n - `-d` - chemin vers le jeu d'exclusion (fichier .vw)\n - `-p` - chemin vers un fichier txt où les prédictions seront stockées\n - `-t` - dit à VW d'ignorer les étiquettes"
  },
  {
   "metadata": {
    "_cell_guid": "7fbac967-4a81-4eff-9d31-721a197ed568",
    "_uuid": "c8ae7e58aeacc3e88910b62aff684ab12fb970e1",
    "trusted": false
   },
   "cell_type": "code",
   "source": [
    "!vw -i $PATH_TO_ALL_DATA/movie_reviews_model.vw -t \\\n",
    "-d $PATH_TO_ALL_DATA/movie_reviews_valid.vw -p $PATH_TO_ALL_DATA/movie_valid_pred.txt --quiet"
   ],
   "execution_count": 56,
   "outputs": []
  },
  {
   "metadata": {
    "lang": "fr"
   },
   "cell_type": "markdown",
   "source": "Lisez les prédictions du fichier texte et estimez la précision et l'AUC ROC. Notez que VW imprime les estimations de probabilité de la classe +1. Ces estimations sont distribuées de -1 à 1, nous pouvons donc les convertir en réponses binaires, en supposant que les valeurs positives appartiennent à la classe 1."
  },
  {
   "metadata": {
    "_cell_guid": "609497c1-de20-436d-9910-018316f36e8e",
    "_uuid": "8cce125db3a615ff84b0892819f1b5f7c680a3e2",
    "trusted": false
   },
   "cell_type": "code",
   "source": [
    "with open(os.path.join(PATH_TO_ALL_DATA, \"movie_valid_pred.txt\")) as pred_file:\n",
    "    valid_prediction = [float(label) for label in pred_file.readlines()]\n",
    "print(\n",
    "    \"Accuracy: {}\".format(\n",
    "        round(\n",
    "            accuracy_score(\n",
    "                valid_labels, [int(pred_prob > 0) for pred_prob in valid_prediction]\n",
    "            ),\n",
    "            3,\n",
    "        )\n",
    "    )\n",
    ")\n",
    "print(\"AUC: {}\".format(round(roc_auc_score(valid_labels, valid_prediction), 3)))"
   ],
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Accuracy: 0.885\nAUC: 0.942\n"
    }
   ]
  },
  {
   "metadata": {
    "lang": "fr"
   },
   "cell_type": "markdown",
   "source": "Encore une fois, faites de même pour l'ensemble de test."
  },
  {
   "metadata": {
    "_cell_guid": "aaa8c5c7-aa05-4cdd-a06e-bf7325972691",
    "_uuid": "36f5d2d1336d537c95947e884207ecffe18e2d91",
    "trusted": false
   },
   "cell_type": "code",
   "source": [
    "!vw -i $PATH_TO_ALL_DATA/movie_reviews_model.vw -t \\\n",
    "-d $PATH_TO_ALL_DATA/movie_reviews_test.vw \\\n",
    "-p $PATH_TO_ALL_DATA/movie_test_pred.txt --quiet"
   ],
   "execution_count": 58,
   "outputs": []
  },
  {
   "metadata": {
    "_cell_guid": "7a61e739-89f4-44d1-a290-9ad2be4bdffd",
    "_uuid": "b3cf5f3efa4dbaf05baff4f4900c61665f2d9fee",
    "trusted": false
   },
   "cell_type": "code",
   "source": [
    "with open(os.path.join(PATH_TO_ALL_DATA, \"movie_test_pred.txt\")) as pred_file:\n",
    "    test_prediction = [float(label) for label in pred_file.readlines()]\n",
    "print(\n",
    "    \"Accuracy: {}\".format(\n",
    "        round(\n",
    "            accuracy_score(\n",
    "                y_test, [int(pred_prob > 0) for pred_prob in test_prediction]\n",
    "            ),\n",
    "            3,\n",
    "        )\n",
    "    )\n",
    ")\n",
    "print(\"AUC: {}\".format(round(roc_auc_score(y_test, test_prediction), 3)))"
   ],
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Accuracy: 0.88\nAUC: 0.94\n"
    }
   ]
  },
  {
   "metadata": {
    "lang": "fr"
   },
   "cell_type": "markdown",
   "source": "Essayons d'obtenir une plus grande précision en incorporant des bigrammes."
  },
  {
   "metadata": {
    "_cell_guid": "c5b25dce-c730-4031-8938-1b9fa64575b6",
    "_uuid": "98fbb3a6f858b362aef8f797469075eec9072aaf",
    "trusted": false
   },
   "cell_type": "code",
   "source": [
    "!vw -d $PATH_TO_ALL_DATA/movie_reviews_train.vw \\\n",
    "--loss_function hinge --ngram 2 -f $PATH_TO_ALL_DATA/movie_reviews_model2.vw --quiet"
   ],
   "execution_count": 60,
   "outputs": []
  },
  {
   "metadata": {
    "_cell_guid": "17ceb519-ab1f-4184-b9c2-9eb925b32ea8",
    "_uuid": "48aa4c0a6c58be2781ed607a2393de37083345ae",
    "trusted": false
   },
   "cell_type": "code",
   "source": [
    "!vw -i$PATH_TO_ALL_DATA/movie_reviews_model2.vw -t -d $PATH_TO_ALL_DATA/movie_reviews_valid.vw \\\n",
    "-p $PATH_TO_ALL_DATA/movie_valid_pred2.txt --quiet"
   ],
   "execution_count": 61,
   "outputs": []
  },
  {
   "metadata": {
    "_cell_guid": "d1c01554-e2b6-4a55-97b9-0d17c8b26686",
    "_uuid": "be78a33c70c03e1bc9a48a25e804248930fba2c2",
    "trusted": false
   },
   "cell_type": "code",
   "source": [
    "with open(os.path.join(PATH_TO_ALL_DATA, \"movie_valid_pred2.txt\")) as pred_file:\n",
    "    valid_prediction = [float(label) for label in pred_file.readlines()]\n",
    "print(\n",
    "    \"Accuracy: {}\".format(\n",
    "        round(\n",
    "            accuracy_score(\n",
    "                valid_labels, [int(pred_prob > 0) for pred_prob in valid_prediction]\n",
    "            ),\n",
    "            3,\n",
    "        )\n",
    "    )\n",
    ")\n",
    "print(\"AUC: {}\".format(round(roc_auc_score(valid_labels, valid_prediction), 3)))"
   ],
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Accuracy: 0.894\nAUC: 0.954\n"
    }
   ]
  },
  {
   "metadata": {
    "_cell_guid": "3015a9e6-f814-4beb-9d37-f8c6a2e2c546",
    "_uuid": "f1aa2121a7ee92577ad4058b0688f8290d24e1d5",
    "trusted": false
   },
   "cell_type": "code",
   "source": [
    "!vw -i $PATH_TO_ALL_DATA/movie_reviews_model2.vw -t -d $PATH_TO_ALL_DATA/movie_reviews_test.vw \\\n",
    "-p $PATH_TO_ALL_DATA/movie_test_pred2.txt --quiet"
   ],
   "execution_count": 63,
   "outputs": []
  },
  {
   "metadata": {
    "_cell_guid": "527e0327-b208-47a0-9853-2e1bd06beb38",
    "_uuid": "22b7b6feb376fcbd44faf942914afaade9368b30",
    "trusted": false
   },
   "cell_type": "code",
   "source": [
    "with open(os.path.join(PATH_TO_ALL_DATA, \"movie_test_pred2.txt\")) as pred_file:\n",
    "    test_prediction2 = [float(label) for label in pred_file.readlines()]\n",
    "print(\n",
    "    \"Accuracy: {}\".format(\n",
    "        round(\n",
    "            accuracy_score(\n",
    "                y_test, [int(pred_prob > 0) for pred_prob in test_prediction2]\n",
    "            ),\n",
    "            3,\n",
    "        )\n",
    "    )\n",
    ")\n",
    "print(\"AUC: {}\".format(round(roc_auc_score(y_test, test_prediction2), 3)))"
   ],
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Accuracy: 0.888\nAUC: 0.952\n"
    }
   ]
  },
  {
   "metadata": {
    "lang": "fr"
   },
   "cell_type": "markdown",
   "source": "L'ajout de bigrammes a vraiment aidé à améliorer notre modèle!"
  },
  {
   "metadata": {
    "lang": "fr"
   },
   "cell_type": "markdown",
   "source": "### 3.4. Classer des gigaoctets de questions StackOverflow"
  },
  {
   "metadata": {
    "lang": "fr"
   },
   "cell_type": "markdown",
   "source": "Cette section a été déplacée vers Kaggle, veuillez explorer [ce noyau](https://www.kaggle.com/kashnitsky/topic-8-online-learning-and-vowpal-wabbit)."
  },
  {
   "metadata": {
    "lang": "fr"
   },
   "cell_type": "markdown",
   "source": "## 4. Mission de démonstration\nPour mieux comprendre l'apprentissage stochastique, vous pouvez effectuer [cette tâche](https://www.kaggle.com/kashnitsky/assignment-8-implementing-online-regressor) où il vous sera demandé d'implémenter un régresseur de gradient stochastique à partir de zéro . La mission est juste pour que vous vous entraîniez, et va avec une [solution](https://www.kaggle.com/kashnitsky/a8-demo-implementing-online-regressor-solution).\n\n## 5. Ressources utiles\n- The same notebook as am interactive web-based [Kaggle Kernel](https://www.kaggle.com/kashnitsky/topic-8-online-learning-and-vowpal-wabbit)\n- [\"Training while reading\"](https://www.kaggle.com/kashnitsky/training-while-reading-vowpal-wabbit-starter) - an example of the Python wrapper usage\n- Main course [site](https://mlcourse.ai), [course repo](https://github.com/Yorko/mlcourse.ai), and YouTube [channel](https://www.youtube.com/watch?v=QKTuw4PNOsU&list=PLVlY_7IJCMJeRfZ68eVfEcu-UcN9BbwiX)\n- Course materials as a [Kaggle Dataset](https://www.kaggle.com/kashnitsky/mlcourse)\n- Official VW [documentation](https://github.com/JohnLangford/vowpal_wabbit/wiki) on Github\n- [\"Awesome Vowpal Wabbit\"](https://github.com/VowpalWabbit/vowpal_wabbit/wiki/Awesome-Vowpal-Wabbit) Wiki\n- [Don’t be tricked by the Hashing Trick](https://booking.ai/dont-be-tricked-by-the-hashing-trick-192a6aae3087) - analysis of hash collisions, their dependency on feature space and hashing space dimensions and affecting classification/regression performance\n- [\"Numeric Computation\" Chapter](http://www.deeplearningbook.org/contents/numerical.html) of the [Deep Learning book](http://www.deeplearningbook.org/)\n- [\"Convex Optimization\" by Stephen Boyd](https://www.amazon.com/Convex-Optimization-Stephen-Boyd/dp/0521833787)\n- \"Command-line Tools can be 235x Faster than your Hadoop Cluster\" [post](https://aadrake.com/command-line-tools-can-be-235x-faster-than-your-hadoop-cluster.html)\n- Benchmarking various ML algorithms on Criteo 1TB dataset on [GitHub](https://github.com/rambler-digital-solutions/criteo-1tb-benchmark)\n- [VW on FastML.com](http://fastml.com/blog/categories/vw/)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "mimetype": "text/x-python",
   "nbconvert_exporter": "python",
   "name": "python",
   "file_extension": ".py",
   "version": "3.5.4",
   "pygments_lexer": "ipython3",
   "codemirror_mode": {
    "version": 3,
    "name": "ipython"
   }
  },
  "hide_input": false,
  "nbTranslate": {
   "hotkey": "alt-t",
   "sourceLang": "en",
   "targetLang": "fr",
   "displayLangs": [
    "*"
   ],
   "langInMainMenu": true,
   "useGoogleTranslate": true
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "base_numbering": 1,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "window_display": false,
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "library": "var_list.py",
     "delete_cmd_prefix": "del ",
     "delete_cmd_postfix": "",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "library": "var_list.r",
     "delete_cmd_prefix": "rm(",
     "delete_cmd_postfix": ") ",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ]
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
