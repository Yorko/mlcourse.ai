{
  "cells": [
    {
      "metadata": {
        "lang": "fr"
      },
      "cell_type": "markdown",
      "source": "<center>\n<img src=\"https://habrastorage.org/files/fd4/502/43d/fd450243dd604b81b9713213a247aa20.jpg\">\n    \n## [mlcourse.ai](https://mlcourse.ai) - Open Machine Learning Course\nAuteur: [Yury Kashnitskiy](https://yorko.github.io) (@yorko). Edité et traduit par [Ousmane Cissé](https://github.com/oussou-dev.com). Ce matériel est soumis aux termes et conditions de la licence [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/). L'utilisation gratuite est autorisée à des fins non commerciales."
    },
    {
      "metadata": {
        "lang": "fr"
      },
      "cell_type": "markdown",
      "source": "## <center> Affectation 4. Détection des sarcasmes avec la régression logistique\n    \nNous utiliserons l'ensemble de données de [paper](https://arxiv.org/abs/1704.05579) \"Un grand corpus auto-annoté pour le sarcasme\" avec 1 million de commentaires provenant du site Reddit, étiquetés comme sarcastiques ou non. \n\nUne version complète peut être trouvée sur Kaggle sous la forme d'un [Jeu de données Kaggle](https://www.kaggle.com/danofer/sarcasm).\n\nLa détection des sarcasmes est facile.\n<img src=\"https://habrastorage.org/webt/1f/0d/ta/1f0dtavsd14ncf17gbsy1cvoga4.jpeg\" />"
    },
    {
      "metadata": {
        "_uuid": "23a833b42b3c214b5191dfdc2482f2f901118247",
        "trusted": false
      },
      "cell_type": "code",
      "source": "!ls ../input/sarcasm/",
      "execution_count": 1,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "test-balanced.csv  test-unbalanced.csv\ttrain-balanced-sarcasm.csv\r\n"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "ffa03aec57ab6150f9bec0fa56cd3a5791a3e6f4",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# some necessary imports\nimport os\nimport numpy as np\nimport pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nimport seaborn as sns\nfrom matplotlib import pyplot as plt",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "b23e4fc7a1973d60e0c6da8bd60f3d921542a856",
        "trusted": false
      },
      "cell_type": "code",
      "source": "train_df = pd.read_csv('../input/sarcasm/train-balanced-sarcasm.csv')",
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "4dc7b3787afa46c7eb0d0e33b0c41ab9821c4a27",
        "trusted": false
      },
      "cell_type": "code",
      "source": "train_df.head()",
      "execution_count": 4,
      "outputs": [
        {
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>comment</th>\n      <th>author</th>\n      <th>subreddit</th>\n      <th>score</th>\n      <th>ups</th>\n      <th>downs</th>\n      <th>date</th>\n      <th>created_utc</th>\n      <th>parent_comment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>NC and NH.</td>\n      <td>Trumpbart</td>\n      <td>politics</td>\n      <td>2</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>2016-10</td>\n      <td>2016-10-16 23:55:23</td>\n      <td>Yeah, I get that argument. At this point, I'd ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>You do know west teams play against west teams...</td>\n      <td>Shbshb906</td>\n      <td>nba</td>\n      <td>-4</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>2016-11</td>\n      <td>2016-11-01 00:24:10</td>\n      <td>The blazers and Mavericks (The wests 5 and 6 s...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>They were underdogs earlier today, but since G...</td>\n      <td>Creepeth</td>\n      <td>nfl</td>\n      <td>3</td>\n      <td>3</td>\n      <td>0</td>\n      <td>2016-09</td>\n      <td>2016-09-22 21:45:37</td>\n      <td>They're favored to win.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>This meme isn't funny none of the \"new york ni...</td>\n      <td>icebrotha</td>\n      <td>BlackPeopleTwitter</td>\n      <td>-8</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>2016-10</td>\n      <td>2016-10-18 21:03:47</td>\n      <td>deadass don't kill my buzz</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>I could use one of those tools.</td>\n      <td>cush2push</td>\n      <td>MaddenUltimateTeam</td>\n      <td>6</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>2016-12</td>\n      <td>2016-12-30 17:00:13</td>\n      <td>Yep can confirm I saw the tool they use for th...</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "   label                        ...                                                             parent_comment\n0      0                        ...                          Yeah, I get that argument. At this point, I'd ...\n1      0                        ...                          The blazers and Mavericks (The wests 5 and 6 s...\n2      0                        ...                                                    They're favored to win.\n3      0                        ...                                                 deadass don't kill my buzz\n4      0                        ...                          Yep can confirm I saw the tool they use for th...\n\n[5 rows x 10 columns]"
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "0a7ed9557943806c6813ad59c3d5ebdb403ffd78",
        "trusted": false
      },
      "cell_type": "code",
      "source": "train_df.info()",
      "execution_count": 5,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1010826 entries, 0 to 1010825\nData columns (total 10 columns):\nlabel             1010826 non-null int64\ncomment           1010773 non-null object\nauthor            1010826 non-null object\nsubreddit         1010826 non-null object\nscore             1010826 non-null int64\nups               1010826 non-null int64\ndowns             1010826 non-null int64\ndate              1010826 non-null object\ncreated_utc       1010826 non-null object\nparent_comment    1010826 non-null object\ndtypes: int64(4), object(6)\nmemory usage: 77.1+ MB\n"
        }
      ]
    },
    {
      "metadata": {
        "lang": "fr"
      },
      "cell_type": "markdown",
      "source": "Certains commentaires sont manquants, alors nous supprimons les lignes correspondantes."
    },
    {
      "metadata": {
        "_uuid": "97b2d85627fcde52a506dbdd55d4d6e4c87d3f08",
        "trusted": false
      },
      "cell_type": "code",
      "source": "train_df.dropna(subset=['comment'], inplace=True)",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "lang": "fr"
      },
      "cell_type": "markdown",
      "source": "Nous remarquons que le jeu de données est bien équilibré"
    },
    {
      "metadata": {
        "_uuid": "addd77c640423d30fd146c8d3a012d3c14481e11",
        "trusted": false
      },
      "cell_type": "code",
      "source": "train_df['label'].value_counts()",
      "execution_count": 7,
      "outputs": [
        {
          "data": {
            "text/plain": "0    505405\n1    505368\nName: label, dtype: int64"
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "metadata": {
        "lang": "fr"
      },
      "cell_type": "markdown",
      "source": "Nous divisons les données en données d'entraînement et données de validation."
    },
    {
      "metadata": {
        "_uuid": "c200add4e1dcbaa75164bbcc73b9c12ecb863c96",
        "trusted": false
      },
      "cell_type": "code",
      "source": "train_texts, valid_texts, y_train, y_valid = \\\n        train_test_split(train_df['comment'], train_df['label'], random_state=17)",
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "lang": "fr"
      },
      "cell_type": "markdown",
      "source": "## Les tâches:\n1. Analysez le jeu de données, faites des graphiques. Ce [kernel](https://www.kaggle.com/sudalairajkumar/simple-exploration-notebook-qiqc) pourrait servir d'exemple.\n2. Créez un Tf-Idf + un pipeline de régression logistique pour prédire le sarcasme (`label`) en fonction du texte d'un commentaire sur Reddit (` comment`).\n3. Tracer les mots/bigrammes qui sont les plus prédictifs du sarcasme (vous pouvez utiliser [eli5](https://github.com/TeamHG-Memex/eli5) pour cela)\n4. (facultatif) ajouter des sous-titres (subreddits) en tant que nouvelles caractéristiques pour améliorer les performances du modèle. Appliquez ici l’approche Sac de mots (Bag of Words), c’est-à-dire traitez chaque sous-titre comme une nouvelle caractéristique.\n\n## Liens:\n  - Bibliothèque d'apprentissage automatique [Scikit-learn](https://scikit-learn.org/stable/index.html) (a.k.a. sklearn)\n  - Kernels sur la [régression logistique](https://www.kaggle.com/kashnitsky/topic-4-linear-models-part-2-classification) et ses applications en [classification de texte](https://www.kaggle.com/kashnitsky/topic-4-linear-models-part-4-more-of-logit), également un [Kernel](https://www.kaggle.com/kashnitsky/topic-6-feature-engineering- and-feature-selection) sur l'ingénierie et la sélection des caractéristiques (feature engineering and feature selection)\n  - [Kaggle Kernel](https://www.kaggle.com/abhishek/approaching-almost-any-nlp-problem-on-kaggle) \"Approcher (presque) n'importe quel problème de NLP sur Kaggle\"\n  - [ELI5](https://github.com/TeamHG-Memex/eli5) pour expliquer les prédictions du modèle"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    },
    "hide_input": false,
    "toc": {
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "base_numbering": 1,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "nbTranslate": {
      "hotkey": "alt-t",
      "sourceLang": "en",
      "targetLang": "fr",
      "displayLangs": [
        "*"
      ],
      "langInMainMenu": true,
      "useGoogleTranslate": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}