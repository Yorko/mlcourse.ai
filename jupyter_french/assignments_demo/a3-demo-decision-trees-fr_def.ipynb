{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "fr"
   },
   "source": [
    "<center>\n",
    "<img src=\"https://habrastorage.org/files/fd4/502/43d/fd450243dd604b81b9713213a247aa20.jpg\">\n",
    "    \n",
    "\n",
    "<br>\n",
    "\n",
    "<div style=\"font-weight: 700; font-size: 25px;\"> [mlcourse.ai](https://mlcourse.ai) - Open Machine Learning Course </div>\n",
    "\n",
    "<br>\n",
    "\n",
    "Auteurs: [Maria Sumarokova](https://www.linkedin.com/in/mariya-sumarokova-230b4054/) et [Yury Kashnitsky](https://www.linkedin.com/in/festline/). Traduit et édité par Gleb Filatov, Aleksey Kiselev, [Anastasia Manokhina](https://www.linkedin.com/in/anastasiamanokhina/), [Egor Polusmak](https://www.linkedin.com/in/egor-polusmak/), [Yuanyuan Pao](https://www.linkedin.com/in/yuanyuanpao/) et [Ousmane Cissé](https://github.com/oussou-dev). Tout le contenu est distribué sous la licence [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/).</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "fr"
   },
   "source": [
    "<div style=\"font-weight: 700; font-size: 25px;\"> <center> Mission n ° 3 (démo) </center></div>\n",
    "    \n",
    "<br>    \n",
    "    \n",
    "<div style=\"font-weight: 700; font-size: 20px;\"> <center> Arbres de décision avec une \"tâche jouet\" (toy task) et le jeu de données UCI Adult </center></div>\n",
    "\n",
    "    \n",
    "\n",
    "La même mission sur [Kaggle Kernel](https://www.kaggle.com/kashnitsky/a3-demo-decision-trees) + la [solution](https://www.kaggle.com/kashnitsky/a3-demo-decision-trees-solution). Complétez les réponses dans le [formulaire Web](https://docs.google.com/forms/d/1wfWYYoqXTkZNOPy1wpewACXaj2MZjBdLOL58htGWYBA/edit)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "fr"
   },
   "source": [
    "Commençons par charger toutes les bibliothèques nécessaires:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 8)\n",
    "import collections\n",
    "from io import StringIO\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydotplus  # pip install pydotplus\n",
    "import seaborn as sns\n",
    "from ipywidgets import Image\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "fr"
   },
   "source": [
    "### Partie 1. Jeu de données de jouet \"Will They? Won't They?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "fr"
   },
   "source": [
    "Votre objectif est de comprendre le fonctionnement des arbres de décision en résolvant un problème de jouet. Bien qu'un seul arbre de décision ne donne pas de résultats remarquables, d'autres algorithmes performants, tels que le boosting de gradient et les forêts aléatoires, sont basés sur la même idée. C'est pourquoi connaître le fonctionnement des arbres de décision peut être utile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "fr"
   },
   "source": [
    "Nous allons passer à un exemple jouet de classification binaire - La personne A décide si elle ira à un deuxième rendez-vous avec la personne B. Cela dépendra de son apparence, de son éloquence, de sa consommation d’alcool (par exemple) et de combien d'argent elle a dépensé lors du premier rendez-vous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "fr"
   },
   "source": [
    "#### Création du jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe with dummy variables\n",
    "def create_df(dic, feature_list):\n",
    "    out = pd.DataFrame(dic)\n",
    "    out = pd.concat([out, pd.get_dummies(out[feature_list])], axis=1)\n",
    "    out.drop(feature_list, axis=1, inplace=True)\n",
    "    return out\n",
    "\n",
    "\n",
    "# Some feature values are present in train and absent in test and vice-versa.\n",
    "def intersect_features(train, test):\n",
    "    common_feat = list(set(train.keys()) & set(test.keys()))\n",
    "    return train[common_feat], test[common_feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"Looks\", \"Alcoholic_beverage\", \"Eloquence\", \"Money_spent\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "fr"
   },
   "source": [
    "#### Données d'entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = {}\n",
    "df_train[\"Looks\"] = [\n",
    "    \"handsome\",\n",
    "    \"handsome\",\n",
    "    \"handsome\",\n",
    "    \"repulsive\",\n",
    "    \"repulsive\",\n",
    "    \"repulsive\",\n",
    "    \"handsome\",\n",
    "]\n",
    "df_train[\"Alcoholic_beverage\"] = [\"yes\", \"yes\", \"no\", \"no\", \"yes\", \"yes\", \"yes\"]\n",
    "df_train[\"Eloquence\"] = [\"high\", \"low\", \"average\", \"average\", \"low\", \"high\", \"average\"]\n",
    "df_train[\"Money_spent\"] = [\"lots\", \"little\", \"lots\", \"little\", \"lots\", \"lots\", \"lots\"]\n",
    "df_train[\"Will_go\"] = LabelEncoder().fit_transform([\"+\", \"-\", \"+\", \"-\", \"-\", \"+\", \"+\"])\n",
    "\n",
    "df_train = create_df(df_train, features)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "fr"
   },
   "source": [
    "#### Données de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = {}\n",
    "df_test[\"Looks\"] = [\"handsome\", \"handsome\", \"repulsive\"]\n",
    "df_test[\"Alcoholic_beverage\"] = [\"no\", \"yes\", \"yes\"]\n",
    "df_test[\"Eloquence\"] = [\"average\", \"high\", \"average\"]\n",
    "df_test[\"Money_spent\"] = [\"lots\", \"little\", \"lots\"]\n",
    "df_test = create_df(df_test, features)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some feature values are present in train and absent in test and vice-versa.\n",
    "y = df_train[\"Will_go\"]\n",
    "df_train, df_test = intersect_features(train=df_train, test=df_test)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "fr"
   },
   "source": [
    "#### Dessinez un arbre de décision (à la main ou dans n’importe quel éditeur graphique) pour cet ensemble de données. Facultativement, vous pouvez également mettre en œuvre la construction de l'arbre et le dessiner ici."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "fr"
   },
   "source": [
    "1\\. Quelle est l'entropie $S_0$ du système initial? Par états du système, nous entendons les valeurs de la caractéristique binaire \"Will_go\" - 0 ou 1 - deux états au total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "fr"
   },
   "source": [
    "2 \\. Partitionnons les données par la caractéristique \"Looks_handsome\". Qu'est-ce que l'entropie $S_1$ du groupe de gauche - celle avec \"Looks_handsome\". Quelle est l'entropie $S_2$ dans le groupe opposé? Quel est le gain d’information (IG) si on considère une telle partition?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "fr"
   },
   "source": [
    "#### Entraînez un arbre de décision en utilisant sklearn sur les données d'apprentissage. Vous pouvez choisir n'importe quelle profondeur pour l'arbre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "fr"
   },
   "source": [
    "#### Supplément : affichez l'arbre résultant en utilisant graphviz. Vous pouvez utiliser pydot ou le [service Web](https://www.coolutils.com/ru/online/DOT-to-PNG) dot2png."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "fr"
   },
   "source": [
    "### Partie 2. Fonctions de calcul d'entropie et de gain d'information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "fr"
   },
   "source": [
    "Prenons l'exemple d'échauffement suivant: nous avons 9 balles bleues et 11 balles jaunes. Laissez la balle avoir l'étiquette **1** si elle est bleue, **0** sinon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balls = [1 for i in range(9)] + [0 for i in range(11)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://habrastorage.org/webt/mu/vl/mt/muvlmtd2njeqf18trbldenpqvnm.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "fr"
   },
   "source": [
    "Ensuite, divisez les balles en deux groupes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://habrastorage.org/webt/bd/aq/5w/bdaq5wi3c4feezaexponvin8wmo.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two groups\n",
    "balls_left = [1 for i in range(8)] + [0 for i in range(5)]  # 8 blue and 5 yellow\n",
    "balls_right = [1 for i in range(1)] + [0 for i in range(6)]  # 1 blue and 6 yellow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "fr"
   },
   "source": [
    "#### Implémenter une fonction pour calculer l'entropie de Shannon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(a_list):\n",
    "    # you code here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "fr"
   },
   "source": [
    "Quelques tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(entropy(balls))  # 9 blue и 11 yellow\n",
    "print(entropy(balls_left))  # 8 blue и 5 yellow\n",
    "print(entropy(balls_right))  # 1 blue и 6 yellow\n",
    "print(entropy([1, 2, 3, 4, 5, 6]))  # entropy of a fair 6-sided die"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "fr"
   },
   "source": [
    "3 \\. Quelle est l'entropie de l'état donné par la liste **balls_left**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "fr"
   },
   "source": [
    "4 \\. Quelle est l'entropie d'un dé non pipé? (où nous considérons un dé comme un système à 6 états également probables)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcul du gain d'information\n",
    "def information_gain(root, left, right):\n",
    "    \"\"\" root - initial data, left and right - two partitions of initial data\"\"\"\n",
    "\n",
    "    # you code here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "fr"
   },
   "source": [
    "5 \\. Quel est l’information que procure le fractionnement de l’ensemble de données initial en **balls_left** et **balls_right**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_feature_to_split(X, y):\n",
    "    \"\"\"Outputs information gain when splitting on best feature\"\"\"\n",
    "\n",
    "    # you code here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "fr"
   },
   "source": [
    "#### Optionnel:\n",
    "- Implémenter un algorithme de construction d'arbre de décision en appelant **best_feature_to_split** de manière récursive\n",
    "- Tracer l'arbre résultant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "fr"
   },
   "source": [
    "### Part 3. Le jeu de données \"Adult\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "fr"
   },
   "source": [
    "**Description du jeu de données:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "fr"
   },
   "source": [
    "[Jeu de données](http://archive.ics.uci.edu/ml/machine-learning-databases/adult) UCI Adulte (inutile de le télécharger, nous en avons une copie dans le référentiel des cours): classifiez les personnes qui utilisent des données démographiques - qu’ils gagnent plus de 50 000 dollars par an ou non."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "fr"
   },
   "source": [
    "Description des caractéristiques :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "fr"
   },
   "source": [
    "- **Age** - caractéristique continue\n",
    "- **Workclass** - caractéristique continue\n",
    "- **fnlwgt** - poids final de l'objet, caractéristique continue\n",
    "- **Education** - caractéristique catégorielle\n",
    "- **Education_Num** - nombre d'années d'études, caractéristique continue\n",
    "- **Martial_Status** - caractéristique catégorielle\n",
    "- **Profession** - caractéristique catégorielle\n",
    "- **Relation** - caractéristique catégorielle\n",
    "- **Race** - caractéristique catégorielle\n",
    "- **Sexe** - caractéristique catégorielle\n",
    "- **Capital_Gain** - caractéristique continue\n",
    "- **Capital_Loss** - caractéristique continue\n",
    "- **Hours_per_week** - caractéristique continue\n",
    "- **Pays** - caractéristique catégorielle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "fr"
   },
   "source": [
    "**Target** - Niveau de revenus, caractéristique catégorielle (binaire)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "fr"
   },
   "source": [
    "**Lecture des données d'entraînement et de test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(\"../input/adult_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv(\"../input/adult_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nécessaire pour supprimer les lignes avec des étiquettes incorrectes dans l'ensemble de données de test\n",
    "data_test = data_test[\n",
    "    (data_test[\"Target\"] == \" >50K.\") | (data_test[\"Target\"] == \" <=50K.\")\n",
    "]\n",
    "\n",
    "# encoder la variable cible en entier\n",
    "data_train.loc[data_train[\"Target\"] == \" <=50K\", \"Target\"] = 0\n",
    "data_train.loc[data_train[\"Target\"] == \" >50K\", \"Target\"] = 1\n",
    "\n",
    "data_test.loc[data_test[\"Target\"] == \" <=50K.\", \"Target\"] = 0\n",
    "data_test.loc[data_test[\"Target\"] == \" >50K.\", \"Target\"] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "fr"
   },
   "source": [
    "**Analyse \"primaire\" des données**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test.describe(include=\"all\").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train[\"Target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(25, 15))\n",
    "cols = 5\n",
    "rows = np.ceil(float(data_train.shape[1]) / cols)\n",
    "for i, column in enumerate(data_train.columns):\n",
    "    ax = fig.add_subplot(rows, cols, i + 1)\n",
    "    ax.set_title(column)\n",
    "    if data_train.dtypes[column] == np.object:\n",
    "        data_train[column].value_counts().plot(kind=\"bar\", axes=ax)\n",
    "    else:\n",
    "        data_train[column].hist(axes=ax)\n",
    "        plt.xticks(rotation=\"vertical\")\n",
    "plt.subplots_adjust(hspace=0.7, wspace=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "fr"
   },
   "source": [
    "**Vérification des types de données**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "fr"
   },
   "source": [
    "Comme nous le voyons, dans les données de test, l’âge est traité comme un type **objet**. Nous devons résoudre ce problème."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test[\"Age\"] = data_test[\"Age\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "fr"
   },
   "source": [
    "Nous allons également transtyper (convertir) tous les éléments **float** en types **int** pour que les types restent cohérents entre nos données d'entraînement et de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test[\"fnlwgt\"] = data_test[\"fnlwgt\"].astype(int)\n",
    "data_test[\"Education_Num\"] = data_test[\"Education_Num\"].astype(int)\n",
    "data_test[\"Capital_Gain\"] = data_test[\"Capital_Gain\"].astype(int)\n",
    "data_test[\"Capital_Loss\"] = data_test[\"Capital_Loss\"].astype(int)\n",
    "data_test[\"Hours_per_week\"] = data_test[\"Hours_per_week\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "fr"
   },
   "source": [
    "**Complétez les données manquantes pour les caractéristiques continues avec leurs valeurs médianes, pour les caractéristiques catégorielles avec leur mode.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choisir des caractéristiques catégorielles et continues à partir des données\n",
    "\n",
    "categorical_columns = [\n",
    "    c for c in data_train.columns if data_train[c].dtype.name == \"object\"\n",
    "]\n",
    "numerical_columns = [\n",
    "    c for c in data_train.columns if data_train[c].dtype.name != \"object\"\n",
    "]\n",
    "\n",
    "print(\"categorical_columns:\", categorical_columns)\n",
    "print(\"numerical_columns:\", numerical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nous voyons quelques valeurs manquantes\n",
    "data_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compléter (remplacer) les données manquantes\n",
    "\n",
    "for c in categorical_columns:\n",
    "    data_train[c].fillna(data_train[c].mode()[0], inplace=True)\n",
    "    data_test[c].fillna(data_train[c].mode()[0], inplace=True)\n",
    "\n",
    "for c in numerical_columns:\n",
    "    data_train[c].fillna(data_train[c].median(), inplace=True)\n",
    "    data_test[c].fillna(data_train[c].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plus de valeurs manquantes\n",
    "data_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "fr"
   },
   "source": [
    "Nous allons coder des données factices pour certaines caractéristiques catégorielles: **Workclass**, **Education**, **Martial_Status**, **Profession**, **Relationship**, **Race**, **Sex**, **Country**. Cela peut être fait via la méthode pandas **get_dummies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.concat(\n",
    "    [data_train[numerical_columns], pd.get_dummies(data_train[categorical_columns])],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "data_test = pd.concat(\n",
    "    [data_test[numerical_columns], pd.get_dummies(data_test[categorical_columns])],\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(data_train.columns) - set(data_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.shape, data_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "fr"
   },
   "source": [
    "**Il n'y a pas Holland (Hollande, Pays-bas) dans les données de test. Créer une nouvelle caractéristique de valeur zéro.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test[\"Country_ Holand-Netherlands\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(data_train.columns) - set(data_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data_train.drop([\"Target\"], axis=1)\n",
    "y_train = data_train[\"Target\"]\n",
    "\n",
    "X_test = data_test.drop([\"Target\"], axis=1)\n",
    "y_test = data_test[\"Target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "fr"
   },
   "source": [
    "#### 3.1 Arbre de décision sans réglage des paramètres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "fr"
   },
   "source": [
    "Entraînez un arbre de décision **(DecisionTreeClassifier) ​​** avec une profondeur maximale de 3, et évaluez la métrique de précision des données de test. Utilisez le paramètre **random_state = 17** pour la reproductibilité des résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you code here\n",
    "# tree =\n",
    "# tree.fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "fr"
   },
   "source": [
    "Faites une prédiction avec le modèle formé sur les données de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you code here\n",
    "# tree_predictions = tree.predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you code here\n",
    "# accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "fr"
   },
   "source": [
    "6 \\. Quelle est la précision des données de test d'un arbre de décision avec une profondeur d'arbre maximale de 3 et **random_state = 17**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "fr"
   },
   "source": [
    "#### 3.2 Arbre de décision avec réglage des paramètres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "fr"
   },
   "source": [
    "Entraînez un arbre de décision **(DecisionTreeClassifier, random_state = 17).** Recherchez la profondeur maximale optimale à l'aide de la validation croisée par 5-fold **(GridSearchCV)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_params = {\"max_depth\": range(2, 11)}\n",
    "\n",
    "locally_best_tree = GridSearchCV  # you code here\n",
    "\n",
    "locally_best_tree.fit\n",
    "# you code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "fr"
   },
   "source": [
    "Entraînez un arbre de décision avec une profondeur maximale de 9 (il s'agit du meilleur **max_depth** dans mon cas) et calculez la précision des données de tests. Utilisez le paramètre **random_state = 17** pour la reproductibilité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you code here\n",
    "# tuned_tree =\n",
    "# tuned_tree.fit\n",
    "# tuned_tree_predictions = tuned_tree.predict\n",
    "# accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "fr"
   },
   "source": [
    "7\\. Quelle est la précision de l'ensemble des données de tests d'un arbre de décision avec une profondeur maximale de 9 et **random_state = 17**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "fr"
   },
   "source": [
    "#### 3.3 (Facultatif) Forêt aléatoire sans réglage de paramètre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "fr"
   },
   "source": [
    "Jetons un coup d'œil aux conférences à venir et essayons d'utiliser une forêt aléatoire pour notre tâche. Pour le moment, vous pouvez imaginer une forêt aléatoire comme un groupe d’arbres de décision formés sur des sous-ensembles légèrement différents des données d’entraînement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "fr"
   },
   "source": [
    "Entraîner une forêt aléatoire **(RandomForestClassifier)**. Définissez le nombre d'arbres sur 100 et utilisez **random_state = 17**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you code here\n",
    "# rf =\n",
    "# rf.fit # you code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "fr"
   },
   "source": [
    "Faites des prévisions pour les données de test et évaluez leur précision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "fr"
   },
   "source": [
    "#### 3.4 (Facultatif) Forêt aléatoire avec réglage des paramètres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "fr"
   },
   "source": [
    "Entraîner une forêt aléatoire **(RandomForestClassifier)**. Réglez la profondeur maximale et le nombre maximal de caractéristiques pour chaque arbre à l’aide de **GridSearchCV**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forest_params = {'max_depth': range(10, 21),\n",
    "#                 'max_features': range(5, 105, 20)}\n",
    "\n",
    "# locally_best_forest = GridSearchCV # you code here\n",
    "\n",
    "# locally_best_forest.fit # you code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "fr"
   },
   "source": [
    "Faites des prévisions pour les données de test et évaluez leur précision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you code here"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
