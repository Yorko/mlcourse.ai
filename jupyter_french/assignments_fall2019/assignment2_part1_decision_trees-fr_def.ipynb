{
  "cells": [
    {
      "metadata": {
        "lang": "fr"
      },
      "cell_type": "markdown",
      "source": "<center>\n<img src=\"https://github.com/Yorko/mlcourse.ai/blob/master/img/ods_stickers.jpg?raw=true\" />\n    \n## [mlcourse.ai](https://mlcourse.ai) - Open Machine Learning Course\nAuteur: [Yury Kashnitsky](https://yorko.github.io) (@yorko). Édité par Anna Tarelina (@feuerengel), Mikhail Korshchikov (@ MS4) et [Ousmane Cissé](https://github.com/oussou-dev). Ce matériel est soumis aux termes et conditions de la licence [Creative Commons CC BY-NC-SA 4.0] (https://creativecommons.org/licenses/by-nc-sa/4.0/). L'utilisation gratuite est autorisée à des fins non commerciales."
    },
    {
      "metadata": {
        "lang": "fr"
      },
      "cell_type": "markdown",
      "source": "# <center>Mission # 2. Automne 2019\n## <center> Partie 1. Les arbres de décision pour la classification et la régression"
    },
    {
      "metadata": {
        "lang": "fr"
      },
      "cell_type": "markdown",
      "source": "**Dans cette mission, nous allons découvrir le fonctionnement d'un arbre de décision dans une tâche de régression, puis construire et ajuster des arbres de décision de classification pour l'identification des maladies du cœur.**\n\nAvant d'entamer la mission, nous vous conseillons de consulter le matériel de cours correspondant:\n 1. [Classification, arbres-de-décision et k-plus-proches-voisins](https://nbviewer.jupyter.org/github/Yorko/mlcourse_open/blob/master/jupyter_english/topic03_decision_trees_kNN/topic3_decision_trees_kNN.ipynb?flush_cache=true), version interactive sur [Kaggle](https://www.kaggle.com/kashnitsky/topic-3-decision-trees-and-knn)\n 2. Ensembles:\n  - [Bagging](https://nbviewer.jupyter.org/github/Yorko/mlcourse_open/blob/master/jupyter_english/topic05_ensembles_random_forests/topic5_part1_bagging.ipynb?flush_cache=true), version interactive sur [Kaggle](https://www.kaggle.com/kashnitsky/topic-5-ensembles-part-1-bagging)\n  - [Forêt aléatoire](https://nbviewer.jupyter.org/github/Yorko/mlcourse_open/blob/master/jupyter_english/topic05_ensembles_random_forests/topic5_part2_random_forest.ipynb?flush_cache=true), version intercative sur [Kaggle](https://www.kaggle.com/kashnitsky/topic-5-ensembles-part-2-random-forest)\n  - [Feature Importance](https://nbviewer.jupyter.org/github/Yorko/mlcourse_open/blob/master/jupyter_english/topic05_ensembles_random_forests/topic5_part3_feature_importance.ipynb?flush_cache=true), version interactive sur [Kaggle](https://www.kaggle.com/kashnitsky/topic-5- ensembles-part-3-feature-importance)\n 3. - [Gradient boosting](https://nbviewer.jupyter.org/github/Yorko/mlcourse_open/blob/master/jupyter_english/topic10_boosting/topic10_gradient_boosting.ipynb?flush_cache=true), version interactive sur [Kaggle](https://www.kaggle.com/kashnitsky/topic-10-gradient-boosting)\n   - Régression logistique, forêt aléatoire et LightGBM dans le cadre de la compétition \"Kaggle Forest Cover Type Prediction\": [Kernel](https://www.kaggle.com/kashnitsky/topic-10-practice-with-logit-rf-and-lightgbm) \n 4. Vous pouvez également vous exercer avec des missions de démonstration, plus simples et déjà partagées avec des solutions:\n     - \"Decision trees with a toy task and the UCI Adult dataset\": [mission](https://www.kaggle.com/kashnitsky/a3-demo-decision-trees) + [solution](https://www.kaggle.com/kashnitsky/a3-demo-decision-trees-solution)\n     - \"Logistic Regression and Random Forest in the credit scoring problem\": [mission](https://www.kaggle.com/kashnitsky/assignment-5-logit-and-rf-for-credit-scoring) + [solution](https://www.kaggle.com/kashnitsky/a5-demo-logit-and-rf-for-credit-scoring-sol)\n 5. Il y a également 7 conférences vidéo sur les arbres, les forêts, la stimulation et leurs applications : [mlcourse.ai/lectures](https://mlcourse.ai/lectures)  \n \n\n### Votre travail consiste à:\n 1. écrire du code et effectuer des calculs dans les cellules ci-dessous\n 2. Choisir les réponses dans le [formulaire](https://docs.google.com/forms/d/1-xvxl0xVVvoDYIbcCxxpAc_ pjcWEpnLQ9kaKLHwXsA). Les solutions seront partagées uniquement avec ceux qui ont rempli ce formulaire\n \n### <center> Date limite pour A2 : le 6 octobre 2019 à 20h59 (heure de Londres)"
    },
    {
      "metadata": {
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "import numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.tree import DecisionTreeClassifier, export_graphviz",
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {
        "lang": "fr"
      },
      "cell_type": "markdown",
      "source": "## 1. Arbres de décision pour la régression : un exemple basé sur un jeu"
    },
    {
      "metadata": {
        "lang": "fr"
      },
      "cell_type": "markdown",
      "source": "Considérons le problème de régression unidimensionnel suivant. Nous devons créer une fonction $\\large a(x)$ pour approximer la dépendance $\\large y = f(x)$ en utilisant le critère d'erreur quadratique moyen: $\\large \\min \\sum_i {(a(x_i) - f(x_i))}^2$."
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "X = np.linspace(-2, 2, 7)\ny = X ** 3 # original dependecy \n\nplt.scatter(X, y)\nplt.xlabel(r'$x$')\nplt.ylabel(r'$y$');",
      "execution_count": 2,
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": "<Figure size 432x288 with 1 Axes>"
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "metadata": {
        "lang": "fr"
      },
      "cell_type": "markdown",
      "source": "Faisons plusieurs étapes pour construire un arbre de décision. Dans le cas d'une tâche **de régression**, au moment de la prédiction, la \"feuille\" renvoie la valeur moyenne pour toutes les observations de cette \"feuille.  \n\nCommençons par un arbre de profondeur 0, c’est-à-dire toutes les observations placées dans une seule \"feuille\".\n\n<br>Vous devrez construire un arbre avec un seul nœud (également appelé **root**) contenant toutes les observations d'entraînement (instances).\n<br>Comment les prédictions de cet arbre vont-elles ressembler pour $x \\in [-2, 2]$? <br> Créez un tracé approprié en utilisant un stylo, du papier et Python si nécessaire (mais vous n'avez pas encore besoin de `sklearn`)."
    },
    {
      "metadata": {
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# You code here",
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "lang": "fr"
      },
      "cell_type": "markdown",
      "source": "**Premières divisions ou partitions.**\n<br>Divisons les données en fonction de la condition suivante $[x < 0]$. Il nous donne l’arbre de profondeur 1 à deux feuilles. Pour clarifier, pour toutes les instances avec $x \\geqslant 0$, l’arbre renverra une valeur, pour toutes les instances avec $x < 0$, il retournera une autre valeur. Créons un graphique similaire pour les prédictions de cet arbre."
    },
    {
      "metadata": {
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# You code here",
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "lang": "fr"
      },
      "cell_type": "markdown",
      "source": "Dans l'algorithme d'arbre de décision, la caractéristique et le seuil de partitonnement choisis en fonction de certains critères. Le critère de régression couramment utilisé est basé sur la variance: $$\\large Q(X, y, j, t) = D(X, y) - \\dfrac{|X_l|}{|X|} D(X_l, y_l) - \\dfrac{|X_r|}{|X|} D(X_r, y_r),$$\noù $\\large X$ et $\\large y$ sont une matrice de caractéristiques et un vecteur cible (en conséquence) pour l'apprentissage d'instances dans un nœud actuel, $\\large X_l, y_l$ et $\\large X_r, y_r$ sont des divisions d'échantillons $\\large X, y$ en deux parties w.r.t. $\\large [x_j < t]$ (par $\\large j$-ème caractéristique et seuil $\\large t$), $\\large |X|$, $\\large |X_l|$, $\\large |X_r|$ (ou identique, $\\large |y|$, $\\large |y_l|$, $\\large |y_r|$) sont des tailles d'échantillons appropriés, et $\\large D(X, y)$ est une variance des réponses $\\large y$ pour toutes les instances de $\\large X$:\n$$\\large D(X, y) = \\dfrac{1}{|X|} \\sum_{j=1}^{|X|}(y_j – \\dfrac{1}{|X|}\\sum_{i = 1}^{|X|}y_i)^2$$\nIci $\\large y_i = y(x_i)$ est la réponse pour l'instance $\\large x_i$. Les indices $\\large j$ et seuil $\\large t$ sont choisis pour maximiser la valeur du critère $\\large Q(X, y, j, t)$ pour chaque division.\n\nDans notre cas 1D, il n'y a qu'une seule caractéristique, si bien que $\\large Q$ ne dépend que du seuil $\\large t$ et des données d'apprentissage $\\large X$ et $\\large y$. Désignons $\\large Q_{1d}(X, y, t)$, ce qui signifie que le critère ne dépend plus de l'indice de la caractéristique $\\large j$, c'est-à-dire dans le cas 1D $\\large j = 1$."
    },
    {
      "metadata": {
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "def regression_var_criterion(X, y, t):\n    pass\n    # You code here",
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "lang": "fr"
      },
      "cell_type": "markdown",
      "source": "Créez le tracé du critère $\\large Q_{1d}(X, y, t)$ en fonction de la valeur de seuil $t$ sur l'intervalle $\\large [-1.9, 1.9]$."
    },
    {
      "metadata": {
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# You code here",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "lang": "fr"
      },
      "cell_type": "markdown",
      "source": "**<font color='red'>Question 1.</font> Quelle est la valeur de seuil la plus défavorable (pour effectuer une partition) en fonction du critère de variance?**\n\n<font color = 'red'> **Options de réponse:** </font>\n- -1,9\n- -1,3\n- 0\n- 1,3\n- 1,9\n\n*Pour les discussions, merci de vous en tenir à [ODS Slack](https://opendatascience.slack.com/), channel __#mlcourse_ai_news__, fil épinglé __#a2_part1_fall2019__*"
    },
    {
      "metadata": {
        "lang": "fr"
      },
      "cell_type": "markdown",
      "source": "Faisons ensuite la partition en chacun des noeuds feuilles.\n<br> Prenez votre arbre avec le premier seuil [$x<0$].\n<br> Maintenant, ajoutez une partition dans la branche de gauche (où la division précédente était $x < 0$) en utilisant le critère $[x < -1.5]$, dans la branche de droite (où la division précédente était $x \\geqslant 0$) avec le critère suivant $[x < 1.5]$.\n<br>Nous obtenons un arbre de profondeur 2 avec 7 nœuds et 4 feuilles. Créez un graphique de cet arbre pour les prédictions de $x \\in [-2, 2]$."
    },
    {
      "metadata": {
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# You code here",
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "lang": "fr"
      },
      "cell_type": "markdown",
      "source": "**<font color='red'>Question 2.</font> Les prédictions de l'arbre sont une fonction constante par morceaux, n'est-ce pas ? Combien de \"morceaux\" (segments horizontaux dans le tracé que vous venez de construire) existe-t-il dans l'intervalle [-2, 2]?**\n\n<font color = 'red'> **Options de réponse:** </font>\n- 2\n- 4\n- 6\n- 8\n\n*Pour les discussions, merci de vous en tenir à [ODS Slack](https://opendatascience.slack.com/), channel __#mlcourse_ai_news__, fil épinglé __#a2_part1_fall2019__*"
    },
    {
      "metadata": {
        "lang": "fr"
      },
      "cell_type": "markdown",
      "source": "## 2. Construire un arbre de décision pour prédire les maladies cardiaques\nLisons les données sur les maladies cardiaques. Le jeu de données peut être téléchargé à partir du référentiel de cours [ici](https://github.com/Yorko/mlcourse.ai/blob/master/data/mlbootcamp5_train.csv) en cliquant sur `Download` puis en sélectionnant l'option `Save As`. Si vous travaillez avec Git, alors le jeu de données est déjà présent dans `data/mlbootcamp5_train.csv`.\n\n**Problème**\n\nPrédisez la présence ou l'absence de maladie cardiovasculaire (CVD) à l'aide des résultats de l'examen du patient.\n\n**Description des données**\n\nIl existe 3 types de caractéristiques d'entrée:\n\n- *Objective*: information factuelle;\n- *Examination*: résultats de l'examen médical;\n- *Subjective*: informations données par le patient.\n\n| Feature | Variable Type | Variable      | Value Type |\n|---------|--------------|---------------|------------|\n| Age | Objective Feature | age | int (days) |\n| Height | Objective Feature | height | int (cm) |\n| Weight | Objective Feature | weight | float (kg) |\n| Gender | Objective Feature | gender | categorical code |\n| Systolic blood pressure | Examination Feature | ap_hi | int |\n| Diastolic blood pressure | Examination Feature | ap_lo | int |\n| Cholesterol | Examination Feature | cholesterol | 1: normal, 2: above normal, 3: well above normal |\n| Glucose | Examination Feature | gluc | 1: normal, 2: above normal, 3: well above normal |\n| Smoking | Subjective Feature | smoke | binary |\n| Alcohol intake | Subjective Feature | alco | binary |\n| Physical activity | Subjective Feature | active | binary |\n| Presence or absence of cardiovascular disease | Target Variable | cardio | binary |\n\nToutes les valeurs du jeu de données ont été collectées au moment de l'examen médical."
    },
    {
      "metadata": {
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "df = pd.read_csv('../../data/mlbootcamp5_train.csv', \n                 index_col='id', sep=';')",
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "df.head()",
      "execution_count": 9,
      "outputs": [
        {
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>gender</th>\n      <th>height</th>\n      <th>weight</th>\n      <th>ap_hi</th>\n      <th>ap_lo</th>\n      <th>cholesterol</th>\n      <th>gluc</th>\n      <th>smoke</th>\n      <th>alco</th>\n      <th>active</th>\n      <th>cardio</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>18393</td>\n      <td>2</td>\n      <td>168</td>\n      <td>62.0</td>\n      <td>110</td>\n      <td>80</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20228</td>\n      <td>1</td>\n      <td>156</td>\n      <td>85.0</td>\n      <td>140</td>\n      <td>90</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>18857</td>\n      <td>1</td>\n      <td>165</td>\n      <td>64.0</td>\n      <td>130</td>\n      <td>70</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>17623</td>\n      <td>2</td>\n      <td>169</td>\n      <td>82.0</td>\n      <td>150</td>\n      <td>100</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>17474</td>\n      <td>1</td>\n      <td>156</td>\n      <td>56.0</td>\n      <td>100</td>\n      <td>60</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "      age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\nid                                                                          \n0   18393       2     168    62.0    110     80            1     1      0   \n1   20228       1     156    85.0    140     90            3     1      0   \n2   18857       1     165    64.0    130     70            3     1      0   \n3   17623       2     169    82.0    150    100            1     1      0   \n4   17474       1     156    56.0    100     60            1     1      0   \n\n    alco  active  cardio  \nid                        \n0      0       1       0  \n1      0       1       1  \n2      0       0       1  \n3      0       1       1  \n4      0       0       0  "
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "metadata": {
        "lang": "fr"
      },
      "cell_type": "markdown",
      "source": "Transformer les caractéristiques :\n- crée \"age in years\" en divisant l'âge par 365,25 et en prenant le seuil ($\\lfloor{x}\\rfloor$ est le plus grand entier inférieur ou égal à $x$)\n- créer 3 caractéristiques binaires basées sur `cholesterol`.\n- créer 3 caractéristiques binaires basées sur `gluc`.\n<br> Caractéristiques binaires égales à 1, 2 ou 3. Cette méthode est appelée codage factice ou codage à chaud -One Hot Encoding- (OHE). Il est plus pratique d'utiliser `pandas.get_dummies`. Il n’est pas nécessaire d’utiliser les caractéristiques originales `cholestérol` et` gluc` après l’encodage."
    },
    {
      "metadata": {
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# You code here",
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {
        "lang": "fr"
      },
      "cell_type": "markdown",
      "source": "Divisez les données en parties d'entraînement et de test dans la proportion de 7/3 en utilisant `sklearn.model_selection.train_test_split` avec` random_state = 17`."
    },
    {
      "metadata": {
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# You code here\n# X_train, X_valid, y_train, y_valid = ...",
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {
        "lang": "fr"
      },
      "cell_type": "markdown",
      "source": "Entraînez un arbre de décision sur le jeu de données `(X _train, y_ train)` avec **max_depth égale à 3** et `random _state = 17`. Tracez cet arbre avec `sklearn.tree.export_graphviz` et Graphviz. Nous devons mentionner ici que `sklearn` ne dessine pas seul les arbres de décision, mais est capable de générer un arbre au format `.dot` qui peut être utilisé par Graphviz pour la visualisation.\n\nComment tracer un arbre de décision, alternatives:\n 1. Installez vous-même Graphviz et pydotpus (voir ci-dessous)\n 2. Utilisez notre image docker avec tous les paquets nécessaires déjà installés\n 3. Moyen facile: exécutez `print(dot _data.getvalue())` avec `dot_data` défini ci-dessous (vous pouvez le faire sans pydotplus et Graphviz), allez à http://www.webgraphviz.com, collez la chaîne de caractère de code graphique (digraph Tree {...) et générez une belle image"
    },
    {
      "metadata": {
        "lang": "fr"
      },
      "cell_type": "markdown",
      "source": "Il y a peut-être des problèmes avec graphviz pour les utilisateurs Windows.\nL'erreur est \"GraphViz's executables not found\".\n<br>Pour résoudre ce problème - installez Graphviz à partir d'[ici](https://graphviz.gitlab.io/_pages/Download/Download_ windows.html).\n<br>Puis ajouter graphviz path à votre variable système PATH. Vous pouvez le faire manuellement, mais n'oubliez pas de redémarrer\n<br>Ou juste exécuter ce code:"
    },
    {
      "metadata": {
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "import os\npath_to_graphviz = '' # your path to graphviz (C:\\\\Program Files (x86)\\\\Graphviz2.38\\\\bin\\\\ for example) \nos.environ[\"PATH\"] += os.pathsep + path_to_graphviz",
      "execution_count": 12,
      "outputs": []
    },
    {
      "metadata": {
        "lang": "fr"
      },
      "cell_type": "markdown",
      "source": "Regardez comment les arbres sont visualisés dans la [3ème partie](https://nbviewer.jupyter.org/github/Yorko/mlcourse_open/blob/master/jupyter_english/topic03_decision_trees_kNN/topic3_decision_trees_kNN.ipynb?flush_cache=true) du matériel de cours."
    },
    {
      "metadata": {
        "lang": "fr"
      },
      "cell_type": "markdown",
      "source": "**<font color='red'>Question 3.</font> Quelles sont les 3 caractéristiques utilisées pour effectuer des prédictions dans l'arbre de décision créé?**\n\n<font color = 'red'> **Options de réponse:** </font>\n- age, ap_lo, chol=1\n- age, ap_hi, chol=3\n- smoke, age, gender\n- alco, weight, gluc=3\n\n*Pour les discussions, merci de vous en tenir à [ODS Slack](https://opendatascience.slack.com/), channel __#mlcourse_ai_news__, fil épinglé __ #a2_part1_fall2019__*"
    },
    {
      "metadata": {
        "lang": "fr"
      },
      "cell_type": "markdown",
      "source": "Faites des prédictions pour les données de validation `(X_valid, y_valid)` avec l'arbre de décision formé. Calculer la précision."
    },
    {
      "metadata": {
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# You code here",
      "execution_count": 13,
      "outputs": []
    },
    {
      "metadata": {
        "lang": "fr"
      },
      "cell_type": "markdown",
      "source": "Définissez la profondeur (depth) de l’arbre à l’aide de la validation croisée sur le jeu de données `(X _train, y_ train)` afin d’améliorer la qualité du modèle. Utilisez `GridSearchCV` avec 5 folds. Fixez `random_state = 17` et changez` max_depth` de 2 à 10."
    },
    {
      "metadata": {
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "tree_params = {'max_depth': list(range(2, 11))}\n\ntree_grid = GridSearchCV # You code here",
      "execution_count": 14,
      "outputs": []
    },
    {
      "metadata": {
        "lang": "fr"
      },
      "cell_type": "markdown",
      "source": "Tracez le graphique pour montrer comment la précision moyenne change par rapport à la valeur `max_depth` lors de la validation croisée."
    },
    {
      "metadata": {
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# You code here",
      "execution_count": 15,
      "outputs": []
    },
    {
      "metadata": {
        "lang": "fr"
      },
      "cell_type": "markdown",
      "source": "Affichez la meilleure valeur de `max_depth` où la valeur moyenne de la métrique de qualité de validation croisée atteint son maximum. Calculez également la précision des données de test. Cela peut être fait avec l'instance entraînée de la classe `GridSearchCV`."
    },
    {
      "metadata": {
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# You code here",
      "execution_count": 16,
      "outputs": []
    },
    {
      "metadata": {
        "lang": "fr"
      },
      "cell_type": "markdown",
      "source": "Calculez l'effet de `GridSearchCV`: vérifiez l'expression (acc2-acc1)/acc1 * 100%, où acc1 et acc2 sont des précisions sur les données de test avant et après le réglage de max_depth avec GridSearchCV, respectivement."
    },
    {
      "metadata": {
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# You code here",
      "execution_count": 17,
      "outputs": []
    },
    {
      "metadata": {
        "lang": "fr"
      },
      "cell_type": "markdown",
      "source": "**<font color='red'>Question 4.</font> Choisissez toutes les instructions correctes.**\n\n<font color = 'red'> **Options de réponse:** </font>\n\n- Il existe un maximum local de précision sur la courbe de validation construite\n- `GridSearchCV` a augmenté la précision sur les données de test de **plus** de 1%\n- Il y a **pas** de maximum de précision local sur la courbe de validation construite\n- `GridSearchCV` a augmenté la précision sur les données de test de **moins** que 1%\n\n*Pour les discussions, merci de vous en tenir à [ODS Slack](https://opendatascience.slack.com/), channel __#mlcourse_ai_news__, fil épinglé __#a2_part1_fall2019__*"
    },
    {
      "metadata": {
        "lang": "fr"
      },
      "cell_type": "markdown",
      "source": "Consultez le tableau SCORE pour évaluer le risque de maladie cardiovasculaire mortelle sur dix ans en Europe. [source](https://academic.oup.com/eurheartj/article/24/11/987/427645).\n\n<img src='https://github.com/Yorko/mlcourse.ai/blob/master/img/SCORE2007-eng.png?raw=true' width=70%>\n\nCréons de nouvelles caractéristiques en fonction de cette image:\n- $age \\in [40,50), age \\in [50,55), age \\in [55,60), age \\in [60,65) $ (4 caractéristiques)\n- systolic blood pressure (tension artérielle systolique) : $ap\\_hi \\in [120,140), ap\\_hi \\in [140,160), ap\\_hi \\in [160,180),$ (3 caractéristiques)\n\nSi les valeurs d'âge ou de pression artérielle ne tombent dans aucun des intervalles, toutes les caractéristiques binaires seront égales à zéro.\n\n<br>Ajout d'une caractéristique ``smoke``.\n<br>Build les caractéristiques ``cholesterol`` et ``gender``. Transformer le ``cholestérol`` en 3 fonctions binaires en fonction de ses 3 valeurs uniques (``cholestérol`` = 1, ``cholestérol`` = 2 et ``cholestérol`` = 3). Transformez le ``sexe`` de 1 et 2 en 0 et 1. Il vaut mieux le renommer en ``male`` (0 - woman, 1 - man). En général, cela se fait généralement avec ``sklearn.preprocessing.LabelEncoder`` mais ici, dans le cas de 2 valeurs uniques, ce n'est pas nécessaire.\n\nEnfin, l'arbre de décision est construit à l'aide de ces 12 caractéristiques binaires (à l'exclusion de toutes les caractéristiques d'origine dont nous disposions avant cette partie ingénierie des caractéristiques).\n\nCréez un arbre de décision avec la limitation `max_depth = 3` et entraînez-le sur l'ensemble des données d'entraînement. Utilisez la classe `DecisionTreeClassifier` avec` random_ state = 17` fixe, mais tous les autres arguments (à l'exception de `max_depth` et` random_state`) doivent être conservés avec leurs valeurs par défaut.\n\n**<font color='red'>Question 5.</font> Quelle caractéristique binaire est la plus importante pour la détection des maladies cardiaques (c’est-à-dire celle est placée à la racine (root) de l’arbre)?**\n\n<font color = 'red'> **Options de réponse:** </font>\n\n- Systolic blood pressure from 160 to 180 (mmHg)\n- Cholesterol level == 3\n- Systolic blood pressure from 140 to 160 (mmHg)\n- Age from 50 to 55 (years)\n- Smokes / doesn't smoke\n- Age from 60 to 65 (years)\n\n*Pour les discussions, merci de vous en tenir à [ODS Slack](https://opendatascience.slack.com/), channel __#mlcourse_ai_news__, fil épinglé __#a2_part1_fall2019_*"
    },
    {
      "metadata": {
        "trusted": true,
        "ExecuteTime": {
          "start_time": "2019-09-27T18:33:43.198713Z",
          "end_time": "2019-09-27T18:33:43.204994Z"
        }
      },
      "cell_type": "code",
      "source": "# You code here",
      "execution_count": 1,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "file_extension": ".py",
      "version": "3.5.4",
      "pygments_lexer": "ipython3",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    },
    "name": "lesson4_part2_Decision_trees.ipynb",
    "hide_input": false,
    "nbTranslate": {
      "hotkey": "alt-t",
      "sourceLang": "en",
      "targetLang": "fr",
      "displayLangs": [
        "*"
      ],
      "langInMainMenu": true,
      "useGoogleTranslate": true
    },
    "toc": {
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "base_numbering": 1,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}