
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Topic 5. Ensembles and random forest. Part 1. Bagging &#8212; mlcourse.ai</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet">
  <link href="../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://c6.patreon.com/becomePatronButton.bundle.js"></script>
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Topic 5. Ensembles and random forest. Part 2. Random Forest" href="topic5_part2_random_forest.html" />
    <link rel="prev" title="Topic 5. Bagging and Random Forest" href="topic05_intro.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
<script async="" src="https://www.google-analytics.com/analytics.js"></script>
<script>
                        window.ga = window.ga || function () {
                            (ga.q = ga.q || []).push(arguments) };
                        ga.l = +new Date;
                        ga('create', 'UA-125504619-1', 'auto');
                        ga('set', 'anonymizeIp', true);
                        ga('send', 'pageview');
                    </script>

  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/mlcourse_ai_logo.jpg" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">mlcourse.ai</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../index.html">
   Intro
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Topic 1
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../topic01/topic01_intro.html">
   Topic 1 Intro
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../topic01/topic01_pandas_data_analysis.html">
   Exploratory data analysis with Pandas
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../topic01/videolecture01.html">
   Videolecture 1
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../topic01/assignment01_pandas_uci_adult.html">
   Demo Assignment 1 Task
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../topic01/assignment01_pandas_uci_adult_solution.html">
   Demo Assignment 1 Solution
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../topic01/bonus_assignment01_pandas_olympics.html">
   Bonus Assignment 1
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Topic 2
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../topic02/topic02_intro.html">
   Topic 2 Intro
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../topic02/topic02_visual_data_analysis.html">
   Visual Data Analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../topic02/topic02_additional_seaborn_matplotlib_plotly.html">
   Seaborn, Matplotlib, Plotly
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../topic02/videolecture02.html">
   Videolecture 2
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../topic02/assignment02_analyzing_cardiovascular_desease_data.html">
   Demo Assignment 2 Task
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../topic02/assignment02_analyzing_cardiovascular_desease_data_solution.html">
   Demo Assignment 2 Solution
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../topic02/bonus_assignment02_visual_analysis.html">
   Bonus Assignment 2
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Topic 3
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../topic03/topic03_intro.html">
   Topic 3 Intro
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../topic03/topic03_decision_trees_kNN.html">
   Classification, Decision Trees &amp; k Nearest Neighbors
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../topic03/videolecture03.html">
   Videolecture 3
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../topic03/assignment03_decision_trees.html">
   Demo Assignment 3 Task
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../topic03/assignment03_decision_trees_solution.html">
   Demo Assignment 3 Solution
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../topic03/bonus_assignment03_decision_trees.html">
   Bonus Assignment 3
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Topic 4
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../topic04/topic04_intro.html">
   Topic 4 Intro
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../topic04/topic4_linear_models_part1_mse_likelihood_bias_variance.html">
   Ordinary Least Squares
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../topic04/topic4_linear_models_part2_logit_likelihood_learning.html">
   Linear classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../topic04/topic4_linear_models_part3_regul_example.html">
   An illustrative example of logistic regression regularization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../topic04/topic4_linear_models_part4_good_bad_logit_movie_reviews_XOR.html">
   When logistic regression is good and when it is not
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../topic04/topic4_linear_models_part5_valid_learning_curves.html">
   Validation and learning curves
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../topic04/videolecture04.html">
   Videolecture 4
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../topic04/assignment04_regression_wine.html">
   Demo Assignment 4 Task
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../topic04/assignment04_regression_wine_solution.html">
   Demo Assignment 4 Solution
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../topic04/bonus_assignment04_alice_baselines.html">
   Bonus Assignment 4
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Topic 5
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="topic05_intro.html">
   Topic 5 Intro
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Bagging
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="topic5_part2_random_forest.html">
   Random Forest
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="topic5_part3_feature_importance.html">
   Feature importance
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="videolecture05.html">
   Videolecture 5
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="assignment05_logit_rf_credit_scoring.html">
   Demo Assignment 5
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="assignment05_logit_rf_credit_scoring_solution.html">
   Demo Assignment 5 Solution
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bonus_assignment05_logreg_rf.html">
   Bonus Assignment 5
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Topic 6
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../topic06/topic06_intro.html">
   Topic 6 Intro
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../topic06/topic6_feature_engineering_feature_selection.html">
   Feature engineering &amp; feature selection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../topic06/demo_assignment06.html">
   Demo Assignment 6 Task
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../topic06/bonus_assignment06.html">
   Bonus Assignment 6
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Topic 7
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../topic07/topic07_intro.html">
   Topic 7 Intro
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../topic07/topic7_pca_clustering.html">
   Unsupervised learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../topic07/videolecture07.html">
   Videolecture 7
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../topic07/assignment07_unsupervised_learning.html">
   Demo Assignment 7
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../topic07/assignment07_unsupervised_learning_solution.html">
   Demo Assignment 7 Solution
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../topic07/bonus_assignment07.html">
   Bonus Assignment 7
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Topic 8
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../topic08/topic08_intro.html">
   Topic 8 Intro
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../topic08/topic08_sgd_hashing_vowpal_wabbit.html">
   Vowpal Wabbit: Learning with Gigabytes of Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../topic08/videolecture08.html">
   Videolecture 8
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../topic08/assignment08_implement_sgd_regressor.html">
   Demo Assignment 8
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../topic08/assignment08_implement_sgd_regressor_solution.html">
   Demo Assignment 8 Solution
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../topic08/bonus_assignment08.html">
   Bonus Assignment 8
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Topic 9
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../topic09/topic09_intro.html">
   Topic 9 Intro
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../topic09/topic9_part1_time_series_python.html">
   Topic 9. Time series analysis in Python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../topic09/topic9_part2_facebook_prophet.html">
   Predicting the future with Facebook Prophet
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../topic09/videolecture09.html">
   Videolecture 9
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../topic09/assignment09_time_series.html">
   Demo Assignment 9
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../topic09/assignment09_time_series_solution.html">
   Demo Assignment 9 Solution
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../topic09/bonus_assignment09.html">
   Bonus Assignment 9
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Topic 10
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../topic10/topic10_intro.html">
   Topic 10 Intro
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../topic10/topic10_gradient_boosting.html">
   Gradient boosting
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../topic10/videolecture10.html">
   Videolecture 10
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../topic10/assignment10_flight_delays_kaggle.html">
   Demo Assignment 10
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../topic10/bonus_assignment10.html">
   Bonus Assignment 10
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        <a class="dropdown-buttons"
            href="../../_sources/book/topic05/topic5_part1_bagging.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download notebook file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/book/topic05/topic5_part1_bagging.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/Yorko/mlcourse.ai/"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/Yorko/mlcourse.ai//issues/new?title=Issue%20on%20page%20%2Fbook/topic05/topic5_part1_bagging.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        <a class="edit-button" href="https://github.com/Yorko/mlcourse.ai/edit/main/mlcourse_ai_jupyter_book/book/topic05/topic5_part1_bagging.md"><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Edit this page"><i class="fas fa-pencil-alt"></i>suggest edit</button></a>
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/Yorko/mlcourse.ai/main?urlpath=tree/mlcourse_ai_jupyter_book/book/topic05/topic5_part1_bagging.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#article-outline">
   Article outline
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#ensembles">
   1. Ensembles
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#bootstrapping">
   2. Bootstrapping
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#bagging">
   3. Bagging
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#out-of-bag-error">
   4. Out-of-bag error
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#useful-resources">
   5. Useful resources
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="topic-5-ensembles-and-random-forest-part-1-bagging">
<span id="topic05-part1"></span><h1>Topic 5. Ensembles and random forest. Part 1. Bagging<a class="headerlink" href="#topic-5-ensembles-and-random-forest-part-1-bagging" title="Permalink to this headline">¶</a></h1>
<img src="https://habrastorage.org/webt/ia/m9/zk/iam9zkyzqebnf_okxipihkgjwnw.jpeg" />
<p><strong><center><a class="reference external" href="https://mlcourse.ai">mlcourse.ai</a> – Open Machine Learning Course</strong> </center><br></p>
<p>Authors: <a class="reference external" href="https://www.linkedin.com/in/vitaliyradchenk0/">Vitaliy Radchenko</a>, and <a class="reference external" href="https://yorko.github.io">Yury Kashnitsky</a>. Translated and edited by <a class="reference external" href="https://www.linkedin.com/in/christinabutsko/">Christina Butsko</a>, <a class="reference external" href="https://www.linkedin.com/in/egor-polusmak/">Egor Polusmak</a>, <a class="reference external" href="https://www.linkedin.com/in/anastasiamanokhina/">Anastasia Manokhina</a>, <a class="reference external" href="http://linkedin.com/in/anna-shirshova-b908458b">Anna Shirshova</a>, and <a class="reference external" href="https://www.linkedin.com/in/yuanyuanpao/">Yuanyuan Pao</a>. This material is subject to the terms and conditions of the <a class="reference external" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons CC BY-NC-SA 4.0</a> license. Free use is permitted for any non-commercial purpose.</p>
<div class="section" id="article-outline">
<h2>Article outline<a class="headerlink" href="#article-outline" title="Permalink to this headline">¶</a></h2>
<ol class="simple">
<li><p><a class="reference external" href="#ensembles">Ensembles</a></p></li>
<li><p><a class="reference external" href="#bootstrapping">Bootstrapping</a></p></li>
<li><p><a class="reference external" href="#bagging">Bagging</a></p></li>
<li><p><a class="reference external" href="#out-of-bag-error">Out-of-bag error</a></p></li>
<li><p><a class="reference external" href="#useful-resources">Useful resources</a></p></li>
</ol>
<p><span class="math notranslate nohighlight">\(\DeclareMathOperator{\Var}{Var}\)</span>
<span class="math notranslate nohighlight">\(\DeclareMathOperator{\Cov}{Cov}\)</span>
<span class="math notranslate nohighlight">\(\DeclareMathOperator{\Corr}{Corr}\)</span>
<span class="math notranslate nohighlight">\(\DeclareMathOperator{\Err}{Err}\)</span>
<span class="math notranslate nohighlight">\(\DeclareMathOperator{\Bias}{Bias}\)</span>
<span class="math notranslate nohighlight">\(\DeclareMathOperator{\E}{\mathbb{E}}\)</span></p>
<p>In previous articles, you explored different classification algorithms as well as techniques that can be used to properly validate and evaluate the quality of your models.</p>
<p>Now, suppose that you have chosen the best possible model for a particular problem and are struggling to further improve its accuracy. In this case, you would need to apply some more advanced machine learning techniques that are collectively referred to as <em>ensembles</em>.</p>
<p>An <em>ensemble</em> is a set of elements that collectively contribute to a whole. A familiar example is a musical ensemble, which blends the sounds of several musical instruments to create harmony, or architectural ensembles, which are a set of buildings designed as a unit. In ensembles, the (whole) harmonious outcome is more important than the performance of any individual part.</p>
</div>
<div class="section" id="ensembles">
<h2>1. Ensembles<a class="headerlink" href="#ensembles" title="Permalink to this headline">¶</a></h2>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Condorcet%27s_jury_theorem">Condorcet’s jury theorem</a> (1784) is about an ensemble in some sense. It states that, if each member of the jury makes an independent judgement and the probability of the correct decision by each juror is more than 0.5, then the probability of the correct decision by the whole jury increases with the total number of jurors and tends to one. On the other hand, if the probability of being right is less than 0.5 for each juror, then the probability of the correct decision by the whole jury decreases with the number of jurors and tends to zero.</p>
<p>Let’s write an analytic expression for this theorem:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\large N\)</span> is the total number of jurors;</p></li>
<li><p><span class="math notranslate nohighlight">\(\large m\)</span> is a minimal number of jurors that would make a majority, that is <span class="math notranslate nohighlight">\(\large m = floor(N/2) + 1\)</span>;</p></li>
<li><p><span class="math notranslate nohighlight">\(\large {N \choose i}\)</span> is the number of <span class="math notranslate nohighlight">\(\large i\)</span>-combinations from a set with <span class="math notranslate nohighlight">\(\large N\)</span> elements.</p></li>
<li><p><span class="math notranslate nohighlight">\(\large p\)</span> is the probability of the correct decision by a juror;</p></li>
<li><p><span class="math notranslate nohighlight">\(\large \mu\)</span> is the probability of the correct decision by the whole jury.</p></li>
</ul>
<p>Then:</p>
<div class="math notranslate nohighlight">
\[ \large \mu = \sum_{i=m}^{N}{N\choose i}p^i(1-p)^{N-i} \]</div>
<p>It can be seen that if <span class="math notranslate nohighlight">\(\large p &gt; 0.5\)</span>, then <span class="math notranslate nohighlight">\(\large \mu &gt; p\)</span>. In addition, if <span class="math notranslate nohighlight">\(\large N \rightarrow \infty \)</span>, then <span class="math notranslate nohighlight">\(\large \mu \rightarrow 1\)</span>.</p>
<p>Let’s look at another example of ensembles: an observation known as <a class="reference external" href="https://en.wikipedia.org/wiki/Wisdom_of_the_crowd">Wisdom of the crowd</a>. <img src="../../_static/img/topic5_bull.png" align="right" width=15% height=15%> In 1906, <a class="reference external" href="https://en.wikipedia.org/wiki/Francis_Galton">Francis Galton</a> visited a country fair in Plymouth where he saw a contest being held for farmers.   800 participants tried to estimate the weight of a slaughtered bull. The real weight of the bull was 1198 pounds. Although none of the farmers could guess the exact weight of the animal, the average of their predictions was 1197 pounds.</p>
<p>A similar idea for error reduction was adopted in the field of Machine Learning.</p>
</div>
<div class="section" id="bootstrapping">
<h2>2. Bootstrapping<a class="headerlink" href="#bootstrapping" title="Permalink to this headline">¶</a></h2>
<p><em>Bagging</em> (also known as <a class="reference external" href="https://en.wikipedia.org/wiki/Bootstrap_aggregating">Bootstrap aggregation</a>) is one of the first and most basic ensemble techniques. It was proposed by <a class="reference external" href="https://en.wikipedia.org/wiki/Leo_Breiman">Leo Breiman</a> in 1994. Bagging is based on the statistical method of <a class="reference external" href="https://en.wikipedia.org/wiki/Bootstrapping_%28statistics%29">bootstrapping</a>, which makes the evaluation of many statistics of complex models feasible.</p>
<p>The bootstrap method goes as follows. Let there be a sample <span class="math notranslate nohighlight">\(\large X\)</span> of size <span class="math notranslate nohighlight">\(\large N\)</span>. We can make a new sample from the original sample by drawing <span class="math notranslate nohighlight">\(\large N\)</span> elements from the latter randomly and uniformly, with replacement. In other words, we select a random element from the original sample of size <span class="math notranslate nohighlight">\(\large N\)</span> and do this <span class="math notranslate nohighlight">\(\large N\)</span> times. All elements are equally likely to be selected, thus each element is drawn with the equal probability <span class="math notranslate nohighlight">\(\large \frac{1}{N}\)</span>.</p>
<p>Let’s say we are drawing balls from a bag one at a time. At each step, the selected ball is put back into the bag so that the next selection is made equiprobably i.e. from the same number of balls <span class="math notranslate nohighlight">\(\large N\)</span>. Note that, because we put the balls back, there may be duplicates in the new sample. Let’s call this new sample <span class="math notranslate nohighlight">\(\large X_1\)</span>.</p>
<p>By repeating this procedure <span class="math notranslate nohighlight">\(\large M\)</span> times, we create <span class="math notranslate nohighlight">\(\large M\)</span> <em>bootstrap samples</em> <span class="math notranslate nohighlight">\(\large X_1, \dots, X_M\)</span>. In the end, we have a sufficient number of samples and can compute various statistics of the original distribution.</p>
<p><img alt="image" src="../../_images/topic5_bootstrap_eng.png" /></p>
<p>For our example, we’ll use the familiar <code class="docutils literal notranslate"><span class="pre">telecom_churn</span></code> dataset. Previously, when we discussed feature importance, we saw that one of the most important features in this dataset is the number of calls to customer service. Let’s visualize the data and look at the distribution of this feature.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">()</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = &#39;retina&#39;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># for Jupyter-book, we copy data from GitHub, locally, to save Internet traffic,</span>
<span class="c1"># you can specify the data/ folder from the root of your cloned</span>
<span class="c1"># https://github.com/Yorko/mlcourse.ai repo, to save Internet traffic</span>
<span class="n">DATA_PATH</span> <span class="o">=</span> <span class="s2">&quot;https://raw.githubusercontent.com/Yorko/mlcourse.ai/master/data/&quot;</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">telecom_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">DATA_PATH</span> <span class="o">+</span> <span class="s2">&quot;telecom_churn.csv&quot;</span><span class="p">)</span>

<span class="n">telecom_data</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">telecom_data</span><span class="p">[</span><span class="s2">&quot;Churn&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="kc">False</span><span class="p">,</span> <span class="s2">&quot;Customer service calls&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span>
    <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Loyal&quot;</span>
<span class="p">)</span>
<span class="n">telecom_data</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">telecom_data</span><span class="p">[</span><span class="s2">&quot;Churn&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="kc">True</span><span class="p">,</span> <span class="s2">&quot;Customer service calls&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span>
    <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Churn&quot;</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Number of calls&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Density&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/topic5_part1_bagging_3_0.png" src="../../_images/topic5_part1_bagging_3_0.png" />
</div>
</div>
<p>Looks like loyal customers make fewer calls to customer service than those who eventually leave. Now, it might be a good idea to estimate the average number of customer service calls in each group. Since our dataset is small, we would not get a good estimate by simply calculating the mean of the original sample. We will be better off applying the bootstrap method. Let’s generate 1000 new bootstrap samples from our original population and produce an interval estimate of the mean.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_bootstrap_samples</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Generate bootstrap samples using the bootstrap method.&quot;&quot;&quot;</span>
    <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)))</span>
    <span class="n">samples</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">samples</span>


<span class="k">def</span> <span class="nf">stat_intervals</span><span class="p">(</span><span class="n">stat</span><span class="p">,</span> <span class="n">alpha</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Produce an interval estimate.&quot;&quot;&quot;</span>
    <span class="n">boundaries</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">stat</span><span class="p">,</span> <span class="p">[</span><span class="mi">100</span> <span class="o">*</span> <span class="n">alpha</span> <span class="o">/</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mi">100</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span> <span class="o">/</span> <span class="mf">2.0</span><span class="p">)])</span>
    <span class="k">return</span> <span class="n">boundaries</span>


<span class="c1"># Save the data about the loyal and former customers to split the dataset</span>
<span class="n">loyal_calls</span> <span class="o">=</span> <span class="n">telecom_data</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span>
    <span class="n">telecom_data</span><span class="p">[</span><span class="s2">&quot;Churn&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="kc">False</span><span class="p">,</span> <span class="s2">&quot;Customer service calls&quot;</span>
<span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="n">churn_calls</span> <span class="o">=</span> <span class="n">telecom_data</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span>
    <span class="n">telecom_data</span><span class="p">[</span><span class="s2">&quot;Churn&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="kc">True</span><span class="p">,</span> <span class="s2">&quot;Customer service calls&quot;</span>
<span class="p">]</span><span class="o">.</span><span class="n">values</span>

<span class="c1"># Set the seed for reproducibility of the results</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Generate the samples using bootstrapping and calculate the mean for each of them</span>
<span class="n">loyal_mean_scores</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span> <span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="n">get_bootstrap_samples</span><span class="p">(</span><span class="n">loyal_calls</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
<span class="p">]</span>
<span class="n">churn_mean_scores</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span> <span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="n">get_bootstrap_samples</span><span class="p">(</span><span class="n">churn_calls</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
<span class="p">]</span>

<span class="c1"># Print the resulting interval estimates</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;Service calls from loyal: mean interval&quot;</span><span class="p">,</span> <span class="n">stat_intervals</span><span class="p">(</span><span class="n">loyal_mean_scores</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">)</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;Service calls from churn: mean interval&quot;</span><span class="p">,</span> <span class="n">stat_intervals</span><span class="p">(</span><span class="n">churn_mean_scores</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Service calls from loyal: mean interval [1.4077193  1.49473684]
Service calls from churn: mean interval [2.0621118  2.39761905]
</pre></div>
</div>
</div>
</div>
<p>For the interpretation of confidence intervals, you can address <a class="reference external" href="https://www.graphpad.com/guides/prism/7/statistics/stat_more_about_confidence_interval.htm?toc=0&amp;printWindow">this</a> concise note or any course on statistics. It’s not correct to say that a confidence interval contains 95% of values. Note that the interval for the loyal customers is narrower, which is reasonable since they make fewer calls (0, 1 or 2) in comparison with the churned clients who call until they are fed up and decide to switch providers.</p>
</div>
<div class="section" id="bagging">
<h2>3. Bagging<a class="headerlink" href="#bagging" title="Permalink to this headline">¶</a></h2>
<p>Now that you’ve grasped the idea of bootstrapping, we can move on to <em>bagging</em>.</p>
<p>Suppose that we have a training set <span class="math notranslate nohighlight">\(\large X\)</span>. Using bootstrapping, we generate samples <span class="math notranslate nohighlight">\(\large X_1, \dots, X_M\)</span>. Now, for each bootstrap sample, we train its own classifier <span class="math notranslate nohighlight">\(\large a_i(x)\)</span>. The final classifier will average the outputs from all these individual classifiers. In the case of classification, this technique corresponds to voting:
$<span class="math notranslate nohighlight">\(\large a(x) = \frac{1}{M}\sum_{i = 1}^M a_i(x).\)</span>$</p>
<p>The picture below illustrates this algorithm:</p>
<img src="../../_static/img/topic5_bagging.png" alt="image"/>
<p>Let’s consider a regression problem with base algorithms <span class="math notranslate nohighlight">\(\large b_1(x), \dots , b_n(x)\)</span>. Assume that there exists an ideal target function of true answers <span class="math notranslate nohighlight">\(\large y(x)\)</span> defined for all inputs and that the distribution <span class="math notranslate nohighlight">\(\large p(x)\)</span> is defined. We can then express the error for each regression function as follows:</p>
<div class="math notranslate nohighlight">
\[\large \varepsilon_i(x) = b_i(x) - y(x), \quad i = 1, \dots, n\]</div>
<p>And the expected value of the mean squared error:</p>
<div class="math notranslate nohighlight">
\[\large \E_x\left[\left(b_i(x) - y(x)\right)^{2}\right] = \E_x\left[\varepsilon_i^{2}(x)\right].\]</div>
<p>Then, the mean error over all regression functions will look as follows:<br />
$<span class="math notranslate nohighlight">\( \large \E_1 = \frac{1}{n} \E_x\left[ \sum_i^n \varepsilon_i^{2}(x)\right]\)</span>$</p>
<p>We’ll assume that the errors are unbiased and uncorrelated, that is:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\large \begin{array}{rcl} \E_x\left[\varepsilon_i(x)\right] &amp;=&amp; 0, \\
\E_x\left[\varepsilon_i(x)\varepsilon_j(x)\right] &amp;=&amp; 0, \quad i \neq j. \end{array}\end{split}\]</div>
<p>Now, let’s construct a new regression function that will average the values from the individual functions:</p>
<div class="math notranslate nohighlight">
\[\large a(x) = \frac{1}{n}\sum_{i=1}^{n}b_i(x)\]</div>
<p>Let’s find its mean squared error:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\large \begin{array}{rcl}\E_n &amp;=&amp; \E_x\left[\frac{1}{n}\sum_{i=1}^{n}b_i(x)-y(x)\right]^2 \\
&amp;=&amp; \E_x\left[\frac{1}{n}\sum_{i=1}^{n}\varepsilon_i\right]^2 \\
&amp;=&amp; \frac{1}{n^2}\E_x\left[\sum_{i=1}^{n}\varepsilon_i^2(x) + \sum_{i \neq j}\varepsilon_i(x)\varepsilon_j(x)\right] \\
&amp;=&amp; \frac{1}{n}\E_1\end{array}\end{split}\]</div>
<p>Thus, by averaging the individual answers, we reduced the mean squared error by a factor of <span class="math notranslate nohighlight">\(\large n\)</span>.</p>
<p>From our previous lesson, let’s recall the components that make up the total out-of-sample error:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\large \begin{array}{rcl}
\Err\left(\vec{x}\right) &amp;=&amp; \E\left[\left(y - \hat{f}\left(\vec{x}\right)\right)^2\right] \\
&amp;=&amp; \sigma^2 + f^2 + \Var\left(\hat{f}\right) + \E\left[\hat{f}\right]^2 - 2f\E\left[\hat{f}\right] \\
&amp;=&amp; \left(f - \E\left[\hat{f}\right]\right)^2 + \Var\left(\hat{f}\right) + \sigma^2 \\
&amp;=&amp; \Bias\left(\hat{f}\right)^2 + \Var\left(\hat{f}\right) + \sigma^2
\end{array}\end{split}\]</div>
<p>Bagging reduces the variance of a classifier by decreasing the difference in error when we train the model on different datasets. In other words, bagging prevents overfitting. The efficiency of bagging comes from the fact that the individual models are quite different due to the different training data and their errors cancel each other out during voting. Additionally, outliers are likely omitted in some of the training bootstrap samples.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> library supports bagging with meta-estimators <code class="docutils literal notranslate"><span class="pre">BaggingRegressor</span></code> and <code class="docutils literal notranslate"><span class="pre">BaggingClassifier</span></code>. You can use most of the algorithms as a base.</p>
<p>Let’s examine how bagging works in practice and compare it with a decision tree. For this, we will use an example from <a class="reference external" href="http://scikit-learn.org/stable/auto_examples/ensemble/plot_bias_variance.html#sphx-glr-auto-examples-ensemble-plot-bias-variance-py">sklearn’s documentation</a>.</p>
<p><img alt="image" src="../../_images/topic5_tree_vs_bagging_eng.png" /></p>
<p>The error for the decision tree:
$<span class="math notranslate nohighlight">\( \large 0.0255 \, (\Err) = 0.0003 \, (\Bias^2)  + 0.0152 \, (\Var) + 0.0098 \, (\sigma^2) \)</span>$</p>
<p>The error when using bagging:
$<span class="math notranslate nohighlight">\( \large 0.0196 \, (\Err) = 0.0004 \, (\Bias^2)  + 0.0092 \, (\Var) + 0.0098 \, (\sigma^2) \)</span>$</p>
<p>As you can see from the graph above, the variance in the error is much lower for bagging. Remember that we have already proved this theoretically.</p>
<p>Bagging is effective on small datasets. Dropping even a small part of training data leads to constructing substantially different base classifiers. If you have a large dataset, you would generate bootstrap samples of a much smaller size.</p>
<p>The example above is unlikely to be applicable to any real work. This is because we made a strong assumption that our individual errors are uncorrelated. More often than not, this is way too optimistic for real-world applications. When this assumption is false, the reduction in error will not be as significant. In the following lectures, we will discuss some more sophisticated ensemble methods, which enable more accurate predictions in real-world problems.</p>
</div>
<div class="section" id="out-of-bag-error">
<h2>4. Out-of-bag error<a class="headerlink" href="#out-of-bag-error" title="Permalink to this headline">¶</a></h2>
<p>Looking ahead, in case of Random Forest, there is no need to use cross-validation or hold-out samples in order to get an unbiased error estimation. Why? Because, in ensemble techniques, the error estimation takes place internally.</p>
<p>Random trees are constructed using different bootstrap samples of the original dataset. Approximately 37% of inputs are left out of a particular bootstrap sample and are not used in the construction of the <span class="math notranslate nohighlight">\(\large k\)</span>-th tree.</p>
<p>This is easy to prove. Suppose there are <span class="math notranslate nohighlight">\(\large \ell\)</span> examples in our dataset. At each step, each data point has equal probability of ending up in a bootstrap sample with replacement, probability <span class="math notranslate nohighlight">\(\large\frac{1}{\ell}.\)</span> The probability that there is no such bootstrap sample that contains a particular dataset element (i.e. it has been omitted <span class="math notranslate nohighlight">\(\large \ell\)</span> times) equals <span class="math notranslate nohighlight">\(\large (1 - \frac{1}{\ell})^\ell\)</span>. When <span class="math notranslate nohighlight">\(\large \ell \rightarrow +\infty\)</span>, it becomes equal to the <a class="reference external" href="https://en.wikipedia.org/wiki/List_of_limits">Second Remarkable Limit</a> <span class="math notranslate nohighlight">\(\large \frac{1}{e}\)</span>. Then, the probability of selecting a specific example is <span class="math notranslate nohighlight">\(\large \approx  1 - \frac{1}{e} \approx 63\%\)</span>.</p>
<p>Let’s visualize how Out-of-Bag Error (or OOBE) estimation works:</p>
<p><img alt="image" src="../../_images/topic5_oob.png" /></p>
<p>The top part of the figure above represents our original dataset. We split it into the training (left) and test (right) sets. In the left image, we draw a grid that perfectly divides our dataset according to classes. Now, we use the same grid to estimate the share of the correct answers on our test set. We can see that our classifier gave incorrect answers in those 4 cases that have not been used during training (on the left). Hence, the accuracy of our classifier is <span class="math notranslate nohighlight">\(\large \frac{11}{15}*100\% = 73.33\%\)</span>.</p>
<p>To sum up, each base algorithm is trained on <span class="math notranslate nohighlight">\(\large \approx 63\%\)</span> of the original examples. It can be validated on the remaining <span class="math notranslate nohighlight">\(\large \approx 37\%\)</span>. The Out-of-Bag estimate is nothing more than the mean estimate of the base algorithms on those <span class="math notranslate nohighlight">\(\large \approx 37\%\)</span> of inputs that were left out of training.</p>
</div>
<div class="section" id="useful-resources">
<h2>5. Useful resources<a class="headerlink" href="#useful-resources" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Main course <a class="reference external" href="https://mlcourse.ai">site</a>, <a class="reference external" href="https://github.com/Yorko/mlcourse.ai">course repo</a>, and YouTube <a class="reference external" href="https://www.youtube.com/watch?v=QKTuw4PNOsU&amp;list=PLVlY_7IJCMJeRfZ68eVfEcu-UcN9BbwiX">channel</a></p></li>
<li><p><a class="reference external" href="http://mlcourse.ai">mlcourse.ai</a> <a class="reference external" href="https://www.youtube.com/watch?v=neXJL-AqI_c">lecture</a> on Random Forest</p></li>
<li><p>Medium <a class="reference external" href="https://medium.com/open-machine-learning-course/open-machine-learning-course-topic-5-ensembles-of-algorithms-and-random-forest-8e05246cbba7">“story”</a> based on this notebook</p></li>
<li><p>Course materials as a <a class="reference external" href="https://www.kaggle.com/kashnitsky/mlcourse">Kaggle Dataset</a></p></li>
<li><p>If you read Russian: an <a class="reference external" href="https://habr.com/ru/company/ods/blog/324402/">article</a> on <a class="reference external" href="http://Habr.com">Habr.com</a> with ~ the same material. And a <a class="reference external" href="https://youtu.be/G0DmuuFeC30">lecture</a> on YouTube</p></li>
<li><p>Chapter 15 of the book “<a class="reference external" href="https://statweb.stanford.edu/~tibs/ElemStatLearn/">Elements of Statistical Learning</a>” by Jerome H. Friedman, Robert Tibshirani, and Trevor Hastie.</p></li>
<li><p>More about practical applications of random forests and other algorithms can be found in the <a class="reference external" href="http://scikit-learn.org/stable/modules/ensemble.html">official documentation</a> of <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code>.</p></li>
<li><p>For a more in-depth discussion of variance and decorrelation of random forests, see the <a class="reference external" href="https://www.stat.berkeley.edu/~breiman/randomforest2001.pdf">original paper</a>.</p></li>
</ul>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./book/topic05"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="topic05_intro.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Topic 5. Bagging and Random Forest</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="topic5_part2_random_forest.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Topic 5. Ensembles and random forest. Part 2. Random Forest</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By Yury Kashnitsky (yorko)<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>