{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://habrastorage.org/webt/ia/m9/zk/iam9zkyzqebnf_okxipihkgjwnw.jpeg\" />\n",
    "    \n",
    "**<center>[mlcourse.ai](https://mlcourse.ai) – Open Machine Learning Course** </center><br>\n",
    "Author: [Yury Kashnitskiy](https://yorko.github.io) (@yorko). [mlcourse.ai](https://mlcourse.ai) is powered by [OpenDataScience (ods.ai)](https://ods.ai/) © 2017—2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Assignment #6. Solution</center><a class=\"tocSkip\">\n",
    "## <center> Beating benchmarks in \"How good is your Medium article?\"</center><a class=\"tocSkip\">\n",
    "    \n",
    "[Competition](https://www.kaggle.com/c/how-good-is-your-medium-article). The task is to beat \"Assignment 6 baseline\". You can refer to [this simple Ridge baseline](https://www.kaggle.com/kashnitsky/ridge-countvectorizer-baseline?rvi=1).\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import Lasso, Ridge, RidgeCV, SGDRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will help to throw away all HTML tags from an article content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from html.parser import HTMLParser\n",
    "\n",
    "\n",
    "class MLStripper(HTMLParser):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        self.strict = False\n",
    "        self.convert_charrefs = True\n",
    "        self.fed = []\n",
    "\n",
    "    def handle_data(self, d):\n",
    "        self.fed.append(d)\n",
    "\n",
    "    def get_data(self):\n",
    "        return \"\".join(self.fed)\n",
    "\n",
    "\n",
    "def strip_tags(html):\n",
    "    s = MLStripper()\n",
    "    s.feed(html)\n",
    "    return s.get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supplementary function to read a JSON line without crashing on escape characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_line(line=None):\n",
    "    result = None\n",
    "    try:\n",
    "        result = json.loads(line)\n",
    "    except Exception as e:\n",
    "        # Find the offending character index:\n",
    "        idx_to_replace = int(str(e).split(\" \")[-1].replace(\")\", \"\"))\n",
    "        # Remove the offending character:\n",
    "        new_line = list(line)\n",
    "        new_line[idx_to_replace] = \" \"\n",
    "        new_line = \"\".join(new_line)\n",
    "        return read_json_line(line=new_line)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse JSON and extract some features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_and_write(path_to_data, inp_filename, is_train=True):\n",
    "\n",
    "    features = [\"content\", \"published\", \"title\", \"author\"]\n",
    "    prefix = \"train\" if is_train else \"test\"\n",
    "    feature_files = [\n",
    "        open(\n",
    "            os.path.join(path_to_data, \"{}_{}.txt\".format(prefix, feat)),\n",
    "            \"w\",\n",
    "            encoding=\"utf-8\",\n",
    "        )\n",
    "        for feat in features\n",
    "    ]\n",
    "\n",
    "    with open(\n",
    "        os.path.join(path_to_data, inp_filename), encoding=\"utf-8\"\n",
    "    ) as inp_json_file:\n",
    "\n",
    "        for line in tqdm(inp_json_file):\n",
    "            json_data = read_json_line(line)\n",
    "            for i, feat in enumerate(features):\n",
    "                if feat == \"published\":\n",
    "                    info = json_data[feat][\"$date\"]\n",
    "                elif feat == \"author\":\n",
    "                    info = json_data[feat][\"twitter\"]\n",
    "                    if info:\n",
    "                        info = info.replace(\"\\n\", \" \").replace(\"@\", \" \")\n",
    "                    else:\n",
    "                        info = \"\"\n",
    "                elif feat == \"content\" or feat == \"title\":\n",
    "                    info = json_data[feat].replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "                    info = strip_tags(info)\n",
    "                feature_files[i].write(info + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the [competition data](https://www.kaggle.com/c/how-good-is-your-medium-article/data) and place it where it's convenient for you. You can modify the path to data below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATA = \"../../_static/data/assignment6/\"  # modify this if you need to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92aa229b9d6c47cf9c8cebe6f6d7200f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 18s, sys: 6.53 s, total: 3min 25s\n",
      "Wall time: 3min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "extract_features_and_write(PATH_TO_DATA, \"train.json\", is_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4cad75138474ade8c9b187d9b399d3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 36s, sys: 2.83 s, total: 1min 39s\n",
      "Wall time: 1min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "extract_features_and_write(PATH_TO_DATA, \"test.json\", is_train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tf-Idf with article content.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 53s, sys: 12.2 s, total: 6min 5s\n",
      "Wall time: 6min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with open(\n",
    "    os.path.join(PATH_TO_DATA, \"train_content.txt\"), encoding=\"utf-8\"\n",
    ") as input_train_file:\n",
    "    X_train_content_sparse = tfidf_vectorizer.fit_transform(input_train_file)\n",
    "\n",
    "with open(\n",
    "    os.path.join(PATH_TO_DATA, \"test_content.txt\"), encoding=\"utf-8\"\n",
    ") as input_test_file:\n",
    "    X_test_content_sparse = tfidf_vectorizer.transform(input_test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((62313, 100000), (34645, 100000))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_content_sparse.shape, X_test_content_sparse.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tf-Idf with titles.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.77 s, sys: 132 ms, total: 4.9 s\n",
      "Wall time: 4.93 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tfidf_vectorizer_title = TfidfVectorizer(ngram_range=(1, 3), max_features=100000)\n",
    "\n",
    "with open(\n",
    "    os.path.join(PATH_TO_DATA, \"train_title.txt\"), encoding=\"utf-8\"\n",
    ") as input_train_file:\n",
    "    X_train_title_sparse = tfidf_vectorizer_title.fit_transform(input_train_file)\n",
    "\n",
    "with open(\n",
    "    os.path.join(PATH_TO_DATA, \"test_title.txt\"), encoding=\"utf-8\"\n",
    ") as input_test_file:\n",
    "    X_test_title_sparse = tfidf_vectorizer_title.transform(input_test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((62313, 100000), (34645, 100000))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_title_sparse.shape, X_test_title_sparse.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add time features.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_time_features(path_to_publication_time_file):\n",
    "\n",
    "    df = pd.read_csv(path_to_publication_time_file, names=[\"time\"])\n",
    "    df[\"time\"] = df[\"time\"].apply(\n",
    "        lambda t: pd.to_datetime(t.replace(\"T\", \" \").replace(\"Z\", \"\"))\n",
    "    )\n",
    "    df[\"hour\"] = df[\"time\"].apply(lambda ts: ts.hour)\n",
    "    df[\"month\"] = df[\"time\"].apply(lambda ts: ts.month)\n",
    "\n",
    "    df[\"weekend\"] = (\n",
    "        df[\"time\"]\n",
    "        .apply(lambda ts: ts.weekday() == 5 or ts.weekday() == 6)\n",
    "        .astype(\"int\")\n",
    "    )\n",
    "\n",
    "    df[\"day\"] = ((df[\"hour\"] >= 12) & (df[\"hour\"] <= 18)).astype(\"int\")\n",
    "    df[\"morning\"] = ((df[\"hour\"] >= 7) & (df[\"hour\"] <= 11)).astype(\"int\")\n",
    "    df[\"night\"] = ((df[\"hour\"] >= 0) & (df[\"hour\"] <= 5)).astype(\"int\")\n",
    "\n",
    "    cols = [\"day\", \"morning\", \"night\", \"month\", \"weekend\"]\n",
    "    X_time_features_sparse = csr_matrix(df[cols].values)\n",
    "\n",
    "    return X_time_features_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.4 s, sys: 1.19 s, total: 16.6 s\n",
      "Wall time: 17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_time_features_sparse = add_time_features(\n",
    "    os.path.join(PATH_TO_DATA, \"train_published.txt\")\n",
    ")\n",
    "X_test_time_features_sparse = add_time_features(\n",
    "    os.path.join(PATH_TO_DATA, \"test_published.txt\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((62313, 5), (34645, 5))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_time_features_sparse.shape, X_test_time_features_sparse.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add authors.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.8 s, sys: 2.3 s, total: 19.1 s\n",
      "Wall time: 19.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "author_train = pd.read_csv(\n",
    "    os.path.join(PATH_TO_DATA, \"train_author.txt\"),\n",
    "    names=[\"author\"],\n",
    "    skip_blank_lines=False,\n",
    ")\n",
    "author_train = pd.get_dummies(author_train)\n",
    "\n",
    "author_test = pd.read_csv(\n",
    "    os.path.join(PATH_TO_DATA, \"test_author.txt\"),\n",
    "    names=[\"author\"],\n",
    "    skip_blank_lines=False,\n",
    ")\n",
    "author_test = pd.get_dummies(author_test)\n",
    "\n",
    "unique_authors_train = list(set(author_train.columns) - set(author_test.columns))\n",
    "unique_authors_test = list(set(author_test.columns) - set(author_train.columns))\n",
    "\n",
    "author_test = author_test.drop(unique_authors_test, axis=1)\n",
    "author_train = author_train.drop(unique_authors_train, axis=1)\n",
    "\n",
    "X_train_author_sparse = csr_matrix(author_train.values)\n",
    "X_test_author_sparse = csr_matrix(author_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((62313, 4587), (34645, 4587))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_author_sparse.shape, X_test_author_sparse.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Join all sparse matrices.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sparse = hstack(\n",
    "    [\n",
    "        X_train_content_sparse,\n",
    "        X_train_title_sparse,\n",
    "        X_train_author_sparse,\n",
    "        X_train_time_features_sparse,\n",
    "    ]\n",
    ").tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_sparse = hstack(\n",
    "    [\n",
    "        X_test_content_sparse,\n",
    "        X_test_title_sparse,\n",
    "        X_test_author_sparse,\n",
    "        X_test_time_features_sparse,\n",
    "    ]\n",
    ").tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((62313, 204592), (34645, 204592))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sparse.shape, X_test_sparse.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read train target and split data for validation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target = pd.read_csv(\n",
    "    os.path.join(PATH_TO_DATA, \"train_log1p_recommends.csv\"), index_col=\"id\"\n",
    ")\n",
    "y_train = train_target[\"log_recommends\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_part_size = int(0.7 * train_target.shape[0])\n",
    "X_train_part_sparse = X_train_sparse[:train_part_size, :]\n",
    "y_train_part = y_train[:train_part_size]\n",
    "X_valid_sparse = X_train_sparse[train_part_size:, :]\n",
    "y_valid = y_train[train_part_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train a simple Ridge model and check MAE on the validation set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1032660402384815\n",
      "CPU times: user 2min 27s, sys: 42.7 s, total: 3min 10s\n",
      "Wall time: 27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ridge_reg = Ridge(random_state=17)\n",
    "ridge_reg.fit(X_train_part_sparse, y_train_part)\n",
    "ridge_valid_pred = ridge_reg.predict(X_valid_sparse)\n",
    "print(mean_absolute_error(y_valid, ridge_valid_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot distributions of tagets and predictions for the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_valid, bins=30, alpha=0.5, color=\"red\", label=\"true\", range=(0, 10))\n",
    "plt.hist(\n",
    "    ridge_valid_pred, bins=30, alpha=0.5, color=\"green\", label=\"pred\", range=(0, 10)\n",
    ")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train the same Ridge with all available data, make predictions for the test set and form a submission file.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 16s, sys: 1min 1s, total: 4min 17s\n",
      "Wall time: 46.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ridge_reg.fit(X_train_sparse, y_train)\n",
    "ridge_test_pred = ridge_reg.predict(X_test_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_submission_file(\n",
    "    prediction,\n",
    "    filename,\n",
    "    path_to_sample=os.path.join(PATH_TO_DATA, \"sample_submission.csv\"),\n",
    "):\n",
    "    submission = pd.read_csv(path_to_sample, index_col=\"id\")\n",
    "\n",
    "    submission[\"log_recommends\"] = prediction\n",
    "    submission.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../_static/data/assignment6/sample_submission.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mwrite_submission_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mridge_test_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPATH_TO_DATA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43massignment6_medium_submission.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [28]\u001b[0m, in \u001b[0;36mwrite_submission_file\u001b[0;34m(prediction, filename, path_to_sample)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrite_submission_file\u001b[39m(\n\u001b[1;32m      2\u001b[0m     prediction,\n\u001b[1;32m      3\u001b[0m     filename,\n\u001b[1;32m      4\u001b[0m     path_to_sample\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(PATH_TO_DATA, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_submission.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      5\u001b[0m ):\n\u001b[0;32m----> 6\u001b[0m     submission \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_to_sample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     submission[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlog_recommends\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m prediction\n\u001b[1;32m      9\u001b[0m     submission\u001b[38;5;241m.\u001b[39mto_csv(filename)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:586\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    571\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    572\u001b[0m     dialect,\n\u001b[1;32m    573\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    582\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    583\u001b[0m )\n\u001b[1;32m    584\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 586\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:482\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    479\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    481\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 482\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    485\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:811\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwds:\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 811\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1040\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1036\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1037\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown engine: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mengine\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (valid options are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmapping\u001b[38;5;241m.\u001b[39mkeys()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1038\u001b[0m     )\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;66;03m# error: Too many arguments for \"ParserBase\"\u001b[39;00m\n\u001b[0;32m-> 1040\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py:51\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     48\u001b[0m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musecols\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39musecols\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# open handles\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open_handles\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# Have to pass int, would break tests using TextReader directly otherwise :(\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/base_parser.py:222\u001b[0m, in \u001b[0;36mParserBase._open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_handles\u001b[39m(\u001b[38;5;28mself\u001b[39m, src: FilePathOrBuffer, kwds: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;124;03m    Let the readers open IOHandles after they are done with their potential raises.\u001b[39;00m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 222\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m        \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/common.py:702\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    697\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    698\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    701\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 702\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    709\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    710\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    711\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../_static/data/assignment6/sample_submission.csv'"
     ]
    }
   ],
   "source": [
    "write_submission_file(\n",
    "    ridge_test_pred, os.path.join(PATH_TO_DATA, \"assignment6_medium_submission.csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With this you get ~ 1.73877 on public leaderboard.**\n",
    "\n",
    "**Now's the time for dirty Kaggle hacks. Form a submission file with all zeroes. Make a submission. What do you get if you think about? How is it going to help you with modifying your predictions?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission_file(\n",
    "    np.zeros_like(ridge_test_pred),\n",
    "    os.path.join(PATH_TO_DATA, \"medium_all_zeros_submission.csv\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_test_target = 4.33328"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate mean target for the test set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now we now that we need to add the difference between test and train mean targets.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_test_pred_modif = ridge_test_pred + mean_test_target - y_train.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission_file(\n",
    "    ridge_test_pred_modif,\n",
    "    os.path.join(PATH_TO_DATA, \"assignment6_medium_submission_with_hack.csv\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it for the assignment. In case you'd like to try some more ideas for improvement:\n",
    "\n",
    "- Engineer good features, this is the key to success. Some simple features will be based on publication time, authors, content length and so on\n",
    "- You may not ignore HTML and extract some features from there\n",
    "- You'd better experiment with your validation scheme. You should see a correlation between your local improvements and LB score\n",
    "- Try TF-IDF, ngrams, Word2Vec and GloVe embeddings\n",
    "- Try various NLP techniques like stemming and lemmatization\n",
    "- Tune hyperparameters. In our example, we've left only 50k features and used C=1 as a regularization parameter, this can be changed\n",
    "- SGD and Vowpal Wabbit will train much faster\n",
    "- Play around with blending and/or stacking. An intro is given in [this Kernel](https://www.kaggle.com/kashnitsky/ridge-and-lightgbm-simple-blending) by @yorko \n",
    "- And neural nets of course. We don't cover them in this course byt still transformer-based architectures will likely perform well in such types of tasks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
